\input texinfo  @c                                     -*- Texinfo -*-
@c %**start of header
@settitle Scsh Reference Manual
@setfilename scsh.info

@ifinfo
@dircategory The Algorithmic Language Scheme
@direntry
* Scsh: (scsh.info).    A UNIX shell embedded within Scheme.
@end direntry
@end ifinfo

@c VR and FN below correspond to VINDEX and FINDEX, which stand for
@c variable and function indices, respectively. See the end of this
@c file for their use.
@synindex vr fn
@c %**end of header

@c Part 2: Summary Description and Copyright
@c -----------------------------------------

@copying
This manual is for scsh, release 0.6.7.

Copyright @copyright{} 2006 Olin Shivers, Brian D. Carlstrom, Martin Gasbichler, and Mike Sperber
@end copying


@c Part 3: Titlepage, Contents, Copyright
@c --------------------------------------

@titlepage
@title Scsh Reference Manual
@subtitle For scsh release 0.6.7

@author Olin Shivers
@author Brian D. Carlstrom
@author Martin Gasbichler
@author Mike Sperber
@author Rich Loveland (Texinfo conversion, copyediting)

@c The following two commands start the copyright page.
@page
@vskip 0pt plus 1filll
@insertcopying
@end titlepage

@c Output the table of contents at the beginning.
@contents

@c Part 4: `Top' Node and Master Menu
@c ----------------------------------

@ifnottex
@node Top
@top Scsh Reference Manual

For scsh release 0.6.7

Olin Shivers, Brian D. Carlstrom, Martin Gasbichler, and Mike Sperber
(Texinfo conversion and some copyediting by Rich Loveland)
@end ifnottex

@menu
* Introduction::
* Process notation::
* System calls::
* Networking::
* Strings and characters::
* Pattern-matching strings with regular expressions::
* Reading delimited strings::
* Awk record I/O and field parsing::
* Concurrent system programming::
* Miscellaneous routines::
* Running scsh::
* Index::

@detailmenu
--- The Detailed Node Listing ---

Introduction

* Copyright & source-code license::
* Obtaining scsh::
* Building scsh::
* Caveats::
* Naming conventions::
* Lexical issues::
* Record types and the define-record form::
* A word about UNIX standards::

Process notation

* Extended process forms and I/O redirections::
* Process forms::
* Using extended process forms in Scheme::
* More complex process operations::
* Conditional process sequencing forms::
* Process filters::

System calls

* Errors::
* I/O::
* File system::
* Processes::
* Process state::
* User and group database access::
* Accessing command-line arguments::
* System parameters::
* Signal system::
* Time::
* Environment variables::
* Terminal device control::

Networking

* High-level interface::
* Sockets::
* Socket addresses::
* Socket primitives::
* Performing input and output on sockets::
* Socket options::
* Database-information entries::

Strings and characters

* Manipulating file names::
* Other string manipulation facilities::
* ASCII encoding::
* Character predicates::
* Deprecated character-set procedures::

Pattern-matching strings with regular expressions

* Summary SRE syntax::
* Examples::
* A short tutorial::
* Regexp functions::
* The regexp @acronym{ADT}::
* Syntax-hacking tools::

Reading delimited strings

Awk record I/O and field parsing

* Record I/O and field parsing::
* Awk::
* Backwards compatibility::

Concurrent system programming

* Threads::
* Locks::
* Placeholders::
* The event interface to interrupts::
* Interaction between threads and process state::

Miscellaneous routines

* Integer bitwise ops::
* Password encryption::
* Dot-Locking::
* Syslog facility::
* MD5 interface::
* Configuration variables::

Running scsh

* Scsh command-line switches::
* The scsh virtual machine::
* Compiling scsh programs::
* Standard file locations::
@end detailmenu

@end menu


@c Part 5: The Body of the Document
@c --------------------------------

@unnumbered Acknowledgements

Who should I thank? My so-called ``colleagues'', who laugh at me
behind my back, all the while becoming famous on @emph{my} work? My
worthless graduate students, whose computer skills appear to be
limited to downloading bitmaps off of netnews? My parents, who are
still waiting for me to quit ``fooling around with computers'', go to
med school, and become a radiologist? My department chairman, a
manager who gives one new insight into and sympathy for disgruntled
postal workers?

My God, no one could blame me--no one!--if I went off the edge and
just lost it completely one day. I couldn't get through the day as it is
without the Prozac and Jack Daniels I keep on the shelf, behind my
Tops-20 JSYS manuals. I start getting the shakes real bad around 10am,
right before my advisor meetings. A 10 oz. Jack 'n Zac helps me get
through the meetings without one of my students winding up with his
severed head in a bowling-ball bag. They look at me funny; they think I
twitch a lot. I'm not twitching. I'm controlling my impulse to snag my
9mm Sig-Sauer out from my day-pack and make a few strong points about
the quality of undergraduate education in Amerika.

If I thought anyone cared, if I thought anyone would even be reading
this, I'd probably make an effort to keep up appearances until the last
possible moment. But no one does, and no one will. So I can pretty much
say exactly what I think.

Oh, yes, the @emph{acknowledgements}. I think not. I did it. I did it
all, by myself.

@flushright
Olin Shivers
Cambridge
September 4, 1994
@end flushright

@node Introduction, Process notation, Top, Top
@chapter Introduction

This is the reference manual for scsh, a UNIX shell that is embedded
within Scheme. Scsh is a Scheme system designed for writing useful
standalone UNIX programs and shell scripts---it spans a wide range of
application, from ``script'' applications usually handled with perl or
sh, to more standard systems applications usually written in C.

Scsh comes built on top of Scheme 48, and has two components: a
process notation for running programs and setting up pipelines and
redirections, and a complete syscall library for low-level access to the
operating system. This manual gives a complete description of scsh. A
general discussion of the design principles behind scsh can be found in
a companion paper, ``A Scheme Shell''.

@anchor{Copyright & source-code license}
@section Copyright & source-code license

Scsh is open source. The complete sources come with the standard
distribution, which can be downloaded off the net. Scsh has an
ideologically hip, BSD-style license.

We note that the code is a rich source for other Scheme implementations
to mine. Not only the @emph{code}, but the @emph{APIs} are available for
implementors working on Scheme environments for systems
programming. These APIs represent years of work, and should provide a
big head-start on any related effort. (Just don't call it ``scsh'',
unless it's @emph{exactly} compliant with the scsh interfaces.)

Take all the code you like; we'll just write more.

@anchor{Obtaining scsh}
@section Obtaining scsh

Scsh is distributed via net publication. We place new releases at
well-known network sites, and allow them to propagate from there. We
currently release scsh to the following sites:

@flushleft
@url{http://www.scsh.net/download}
@url{http://sourceforge.net/projects/scsh}
@end flushleft

Each should have a compressed tar file of the entire scsh release, which
includes all the source code and the manual, and a separate file
containing just this manual in Postscript form, for those who simply
wish to read about the system.

However, nothing is certain for long on the Net. Probably the best way
to get a copy of scsh is to use a network resource-discovery tool, such
as archie, to find ftp servers storing scsh tar files. Take the set of
sites storing the most recent release of scsh, choose one close to your
site, and download the tar file.

@anchor{Building scsh}
@section Building scsh

Scsh currently runs on a fairly large set of UNIX systems, including
Linux, FreeBSD, OpenBSD, NetBSD, MacOS X, SunOS, Solaris, AIX, NeXTSTEP,
Irix, and HP-UX. We use the Gnu project's autoconfig tool to generate
self-configuring shell scripts that customise the scsh Makefile for
different OS variants. This means that if you use one of the common UNIX
implementations, building scsh should require exactly the following
steps:

@example
gunzip scsh.tar.gz      # Uncompress the release tar file.
untar xfv scsh.tar      # Unpack the source code.
cd scsh-0.6.x           # Move to the source directory.
./configure             # Examine host; build Makefile.
make                    # Build system.
@end example

When you are done, you should have a virtual machine compiled in file
`scshvm', and a heap image in file `scsh/scsh.image'. Typing

@example
make install
@end example

will install these programs in your installation directory (by default,
@code{/usr/local}), along with a small stub startup binary, @code{scsh}.

If you don't have the patience to do this, you can start up a Scheme
shell immediately after the initial make by simply saying

@example
./scshvm -o ./scshvm -i scsh/scsh.image
@end example

See @ref{Running scsh} for full details on installation locations and
startup options.

It is not too difficult to port scsh to another UNIX platform if your OS
is not supported by the current release. See the release notes for more
details on how to do this.

@anchor{Caveats}
@section Caveats

It is important to note what scsh is not, as well as what it is. Scsh,
in the current release, is primarily designed for the writing of shell
scripts---programming.  It is not a very comfortable system for
interactive command use: the current release lacks job control,
command-line editing, a terse, convenient command syntax, and it does
not read in an initialisation file analogous to @code{.login} or
@code{.profile}. We hope to address all of these issues in future
releases; we even have designs for several of these features; but the
system as-released does not currently provide these features.

@anchor{Naming conventions}
@section Naming conventions

Scsh follows a general naming scheme that consistently employs a set of
abbreviations. This is intended to make it easier to remember the names
of things.  Some of the common ones are:

@table @code
@item fdes
Means ``file descriptor'', a small integer used in UNIX to represent I/O
channels.

@item ...*
A given bit of functionality sometimes comes in two related forms,
the first being a special form that contains a body of Scheme code to be
executed in some context, and the other being a procedure that takes a
procedural argument (a ``thunk'') to be called in the same context. The
procedure variant is named by taking the name of the special form, and
appending an asterisk. For example:

@example
;;; Special form:
(with-cwd "/etc"
  (for-each print-file (directory-files))
  (display "All done"))

;;; Procedure:
(with-cwd* "/etc"
  (lambda ()
    (for-each print-file (directory-files))
    (display "All done")))
@end example

@item action/modifier
The infix ``/'' is pronounced ``with'', as in @code{exec/env}---
``exec with environment''.

@item call/...
Procedures that call their argument on some computed value are usually
named @code{call/@dots{}}, e.g., @code{(call/fdes @var{port} @var{proc})}, which
calls @var{proc} on @var{port}'s file descriptor, returning whatever
@var{proc} returns. The abbreviated name means ``call with file
descriptor''.

@item with-...
Procedures that call their argument, and special forms that execute
their bodies in some special dynamic context frequently have names of
the form @code{with-@dots{}}. For example, @code{(with-env @var{env}
@math{body_1} @dots{})} and @code{(with-env* @var{env}
@var{thunk})}. These forms set the process environment body, execute
their body or thunk, and then return after resetting the environment
to its original state.

@item create-...
Procedures that create objects in the file system (files,
directories,temp files, fifos, etc.), begin with
@code{create-@dots{}}.

@item delete-...
Procedures that delete objects from the file system (files,
directories,temp files, fifos, etc.), begin with
@code{delete-@dots{}}.

@item record:field
Procedures that access fields of a record are usually written with a
colon between the name of the record and the name of the field, as in
@code{user-info:home-dir}.

@item %...
A percent sign is used to prefix lower-level scsh primitives that are
not commonly used.

@item ...-info
Data structures packaging up information about various OS entities
frequently end in @dots{}@code{-info}. Examples: @code{user-info},
@code{file-info}, @code{group-info}, and @code{host-info}.
@end table

Enumerated constants from some set @emph{s} are usually named
@code{s/@math{const_1}}, @code{s/@math{const_2}}, @dots{}. For
example, the various UNIX signal integers have the names
@code{signal/cont}, @code{signal/kill}, @code{signal/int},
@code{signal/hup}, and so forth.

@anchor{Lexical issues}
@section Lexical issues

Scsh's lexical syntax is just @acronym{R5RS} Scheme, with the following exceptions.

@anchor{Extended symbol syntax}
@subsection Extended symbol syntax

Scsh's symbol syntax differs from @acronym{R5RS} Scheme in the following ways:

@itemize @bullet
@item
In scsh, symbol case is preserved by @code{read} and is significant on
symbol comparison. This means

@example
(run (less Readme))
@end example

displays the right file.

@item
``-'' and ``+'' are allowed to begin symbols. So the following are
legitimate symbols:

@example
-O2 -geometry +Wn
@end example

@item
``|'' and ``.'' are symbol constituents. This allows @code{|} for the
pipe symbol, and @code{..} for the parent-directory symbol. (Of course,
``.'' alone is not a symbol, but a dotted-pair marker.)

@item
A symbol may begin with a digit. So the following are legitimate symbols:

@example
9x15 80x36-3+440
@end example
@end itemize

@anchor{Extended string syntax}
@subsection Extended string syntax

Scsh strings are allowed to contain the @acronym{ANSI} C escape sequences such as
@code{\n} and @code{\161}.

@anchor{Block comments and executable interpreter-triggers}
@subsection Block comments and executable interpreter-triggers

Scsh allows source files to begin with a header of the form

@example
#!/usr/local/bin/scsh -s
@end example

The UNIX operating system treats source files beginning with the headers
of this form specially; they can be directly executed by the operating
system (see @ref{Running scsh} for information on how to use this
feature). The scsh interpreter ignores this special header by treating
@code{#!} as a comment marker similar to @code{;}. When the scsh reader
encounters @code{#!}, it skips characters until it finds the closing
sequence newline/exclamation-point/sharp-sign/newline.

Although the form of the @code{#!} read-macro was chosen to support
interpreter-triggers for executable UNIX scripts, it is a general
block-comment sequence and can be used as such anywhere in a scsh
program.

@anchor{Here-strings}
@subsection Here-strings

The read macro @code{#<} is used to introduce ``here-strings'' in
programs, similar to the @code{<<} ``here document'' redirections
provided by sh and csh. There are two kinds of here-string,
character-delimited and line-delimited; they are both introduced by the
@code{#<} sequence.

@subsubsection Character-delimited here-strings
A character-delimited here-string has the form

@example
#<x ... stuff ... x
@end example

where @emph{x} is any single character (except @code{<}, see below),
which is used to delimit the string bounds. Some examples of
here-strings and their Scheme equivalents:

@table @code
@item #<|Hello, world.|
@code{"Hello, world."}
@item #<!"Ouch," he said.!
@code{"\"Ouch,\" he said."}
@end table

There is no interpretation of characters within the here-string; the
characters are all copied verbatim.

@subsubsection Line-delimited here-strings
If the sequence begins ``@code{#<<}'' then it introduces a line-delimited
here-string. These are similar to the ``here documents'' of @code{sh} and
@code{csh}. Line-delimited here-strings are delimited by the rest of the text
line that follows the @code{#<<} sequence. For example:

@example
#<<FOO
Hello, there.
This is read by Scheme as a string,
terminated by the first occurrence
of newline-F-O-O-newline or newline-F-O-O-@acronym{eof}.
FOO
@end example

Thus,

@example
#<<foo
Hello, world.
foo
@end example

is the same thing as

@example
"Hello, world."
@end example

Line-delimited here-strings are useful for writing down long, constant
strings---such as long, multi-line @code{format} strings, or arguments
to UNIX programs, e.g.,

@example
;; Free up some disk space for my netnews files.
(run (csh -c #<<EOF
cd /urops
rm -rf *
echo All done.

EOF
))
@end example

The advantage they have over the double-quote syntax (e.g.,
@code{"Hello, world."}) is that there is no need to backslash-quote
special characters internal to the string, such as the double-quote or
backslash characters.

The detailed syntax of line-delimited here-strings is as follows. The
characters ``@code{#<<}'' begin the here-string. The characters
between the ``@code{#<<} '' and the next newline are the delimiter
line. All characters between the ``@code{#<<}'' and the next newline
comprise the delimiter line---including any white space. The body of
the string begins on the following line, and is terminated by a line
of text which exactly matches the delimiter line. This terminating
line can be ended by either a newline or end-of-file. Absolutely no
interpretation is done on the input string. Control characters, white
space, quotes, backslash---everything is copied as-is. The newline
immediately preceding the terminating delimiter line is not included
in the result string (leave an extra blank line if you need to put a
final newline in the here-string---see the example above). If @acronym{eof} is
encountered before reading the end of the here-string, an error is
signalled.

@anchor{Dot}
@subsection Dot

It is unfortunate that the single-dot token, ``.'', is both a
fundamental UNIX filename and a deep, primitive syntactic token in
Scheme -- it means the following will not parse correctly in scsh:

@example
(run/strings (find . -name *.c -print))
@end example

You must instead quote the dot:

@example
(run/strings (find "." -name *.c -print))
@end example

When you write shell scripts that manipulate the file system, keep in
mind the special status of the dot token.

@anchor{Record types and the define-record form}
@section Record types and the define-record form

@cindex define-record

Scsh's interfaces occasionally provide data in structured record types;
an example is the @code{file-info} record whose various fields describe
the size, protection, last date of modification, and other pertinent
data for a particular file. These record types are described in this
manual using the @code{define-record} notation, which looks like the
following:

@example
(define-record ship
  x
  y
  (size 100))
@end example

This form defines a @var{ship} record, with three fields: its x and y
coordinates, and its size. The values of the @var{x} and @var{y}
fields are specified as parameters to the ship-building procedure,
@code{(make-ship @var{x} @var{y})}, and the @var{size} field is
initialised to 100. All told, the @code{define-record} form above
defines the following procedures:

@table @code
@item (make-ship @var{x} @var{y})
Create a new @var{ship} record.
@item (ship:x @var{ship})
Retrieve the @var{x} field.
@item (ship:y @var{ship})
Retrieve the @var{y} field.
@item (ship:size @var{ship})
Retrieve the @var{size} field.
@item (set-ship:x @var{ship} @var{new-x})
Assign the @var{x} field.
@item (set-ship:y @var{ship} @var{new-y})
Assign the @var{y} field.
@item (set-ship:size @var{ship} @var{new-size})
Assign the @var{size} field.
@item (modify-ship:x @var{ship} @var{xfun})
Modify @var{x} field with @var{xfun}.
@item (modify-ship:y @var{ship} @var{yfun})
Modify @var{y} field with @var{yfun}.
@item (modify-ship:size @var{ship} @var{sizefun})
Modify @var{size} field with @var{sizefun}.
@item (ship? @var{object})
Type predicate.
@item (copy-ship @var{ship})
Shallow-copy of the record.
@end table

An implementation of @code{define-record} is available as a macro for
Scheme programmers to define their own record types; the syntax is
accessed by opening the package @code{defrec-package}, which exports the
single syntax form @code{define-record}. See the source code for the
@code{defrec-package} module for further details of the macro.

You must open this package to access the form. Scsh does not export a
record-definition package by default as there are several from which to
choose. Besides the @code{define-record} macro, which Shivers
prefers @footnote{He wrote it.}, you might instead wish to employ the
notationally-distinct @code{define-record-type} macro that Jonathan Rees
prefers @footnote{He wrote it.}. It can be found in the
@code{define-record-types} structure.

Alternatively, you may define your own, of course.

@anchor{A word about UNIX standards}
@section A word about UNIX standards

``The wonderful thing about UNIX standards is that there are so many to
choose from''. You may be totally bewildered about the multitude of
various standards that exist. Rest assured that nowhere in this manual
will you encounter an attempt to spell it all out for you; you could not
read and internalise such a twisted account without bleeding from the
nose and ears.

However, you might keep in mind the following simple fact: of all the
standards, @acronym{POSIX} is the least common denominator. So when
this manual repeatedly refers to @acronym{POSIX}, the point is ``the
thing we are describing should be portable just about anywhere''. Scsh
sticks to @acronym{POSIX} when at all possible; its major departure is
symbolic links, which aren't in @acronym{POSIX} (see---it really
@emph{is} a least common denominator).

@node Process notation, System calls, Introduction, Top
@chapter Process notation

Scsh has a notation for controlling UNIX processes that takes the form
of s-expressions; this notation can then be embedded inside of
standard Scheme code. The basic elements of this notation are
@emph{process forms}, @emph{extended process forms}, and
@emph{redirections}.

@anchor{Extended process forms and I/O redirections}
@section Extended process forms and I/O redirections

An extended process form is a specification of a UNIX process to run,
in a particular I/O environment:

@example
@var{epf} ::= (@var{pf} @math{redir_1 ... redir_n})
@end example

where @var{pf} is a process form and the @math{redir_i} are
redirection specs. A @emph{redirection spec} is one of:

@table @code
@item (< [@var{fdes}] @var{file-name})
Open file for read.
@item (> [@var{fdes}] @var{file-name})
Open file create/truncate.
@item (<< [@var{fdes}] @var{object})
Use @var{object}'s printed representation.
@item (>> [@var{fdes}] @var{file-name})
Open file for append.
@item (= @var{fdes} @var{fdes/port})
Dup2
@item (- fdes/port)
Close @var{fdes/port}.
@item stdports
0,1,2 dup'd from standard ports.
@end table

The input redirections default to file descriptor 0; the output
redirections default to file descriptor 1.

The subforms of a redirection are implicitly backquoted, and symbols
stand for their print-names. So @code{(> ,x)} means ``output to the
file named by Scheme variable @var{x}'', and @code{(<
/usr/shivers/.login)} means ``read from @code{/usr/shivers/.login}''.

Here are two more examples of I/O redirection:

@example
(< ,(vector-ref fv i))
(>> 2 /tmp/buf)
@end example

These two redirections cause the file @code{fv[i]} to be opened on
stdin, and @code{/tmp/buf} to be opened for append writes on stderr.

The redirection @code{(<< @var{object})} causes input to come from
the printed representation of @var{object}. For example,

@example
(<< "The quick brown fox jumped over the lazy dog.")
@end example

causes reads from stdin to produce the characters of the above
string. The object is converted to its printed representation using
the @code{display} procedure, so

@example
(<< (A five element list))
@end example

is the same as

@example
(<< "(A five element list)")
@end example

is the same as

@example
(<< ,(reverse '(list element five A))).
@end example

(Here we use the implicit backquoting feature to compute the list to
be printed.)

The redirection @code{(= @var{fdes} @var{fdes/port})} causes
@var{fdes/port} to be dup'd into file descriptor @var{fdes}. For
example, the redirection

@example
(= 2 1)
@end example

causes stderr to be the same as stdout. @var{Fdes/port} can also be a
port, for example:

@example
(= 2 ,(current-output-port))
@end example

causes stderr to be @code{dup}'d from the current output port. In this
case, it is an error if the port is not a file port (e.g., a string
port). More complex redirections can be accomplished using the
@code{begin} process form, discussed below, which gives the programmer
full control of I/O redirection from Scheme.

@anchor{Port and file descriptor sync}
@subsection Port and file descriptor sync

It's important to remember that rebinding Scheme's current I/O ports
(e.g.,using @code{call-with-input-file} to rebind the value of
@code{(current-input-port)}) does @emph{not} automatically ``rebind''
the file referenced by the UNIX stdio file descriptors 0, 1, and
2. This is impossible to do in general, since some Scheme ports are
not representable as UNIX file descriptors. For example, many Scheme
implementations provide ``string ports'', that is, ports that collect
characters sent to them into memory buffers. The accumulated string
can later be retrieved from the port as a string. If a user were to
bind @code{(current-output-port)} to such a port, it would be
impossible to associate file descriptor 1 with this port, as it cannot
be represented in UNIX. So, if the user subsequently forked off some
other program as a subprocess, that program would of course not see
the Scheme string port as its standard output.

To keep stdio synced with the values of Scheme's current I/O ports,
use the special redirection @code{stdports}. This causes 0, 1, 2 to be
redirected from the current Scheme standard ports. It is equivalent to
the three redirections:

@example
(= 0 ,(current-input-port))
(= 1 ,(current-output-port))
(= 2 ,(error-output-port))
@end example

The redirections are done in the indicated order. This will cause an
error if one of the current I/O ports isn't a UNIX port (e.g., if one is
a string port). This Scheme/UNIX I/O synchronisation can also be had in
Scheme code (as opposed to a redirection spec) with the
@code{(stdports->stdio)} procedure.

@anchor{Process forms}
@section Process forms

A @emph{process form} specifies a computation to perform as an
independent UNIX process. It can be one of the following:

@table @code 
@item (begin . @var{scheme-code})
Run @var{scheme-code} in a fork.
@item (| @math{pf_1} @dots{} @math{pf_n})
Simple pipeline.
@item (|+ @var{connect-list} @math{pf_1} @dots{} @math{pf_n})
Complex pipeline.
@item (epf . @var{epf})
An extended process form.
@item (prog @math{arg_1} @dots{} @math{arg_n})
Default: exec the program.
@end table

The default case @code{(@var{prog} @math{arg_1} @dots{}
@math{arg_n})} is also implicitly backquoted. That is, it is
equivalent to:

@example
(begin (apply exec-path `(@var{prog} @math{arg_1} @dots{} @math{arg_n})))
@end example

@code{Exec-path} is the version of the @code{exec(3)} system call that
uses scsh's path list to search for an executable. The program and the
arguments must be either strings, symbols, or integers. Symbols and
integers are coerced to strings. A symbol's print-name is
used. Integers are converted to strings in base 10. Using symbols
instead of strings is convenient, since it suppresses the clutter of
the surrounding ``@dots{}''  quotation marks. To aid this purpose,
scsh reads symbols in a case-sensitive manner, so that you can say

@example
(more Readme)
@end example

and get the right file.

A @emph{connect-list} is a specification of how two processes are to
be wired together by pipes. It has the form @code{((@math{from_1}
@math{from_2} @dots{} @var{to}) @dots{})} and is implicitly
backquoted. For example,

@example
(|+ ((1 2 0) (3 1)) @math{pf_1} @math{pf_2})
@end example

runs @math{pf_1} and @math{pf_2}. The first clause @code{(1 2 0)}
causes @math{pf_1}'s stdout (1) and stderr (2) to be connected via
pipe to @math{pf_2}'s stdin (0). The second clause @code{(3 1)} causes
@math{pf_1}'s file descriptor 3 to be connected to @math{pf_2}'s file
descriptor 1.The @code{begin} process form does a
@code{stdio->stdports} synchronisation in the child process before
executing the body of the form. This guarantees that the @code{begin}
form, like all other process forms, ``sees'' the effects of any
associated I/O redirections.

Note that @acronym{R5RS} does not specify whether or not @code{|} and @code{|+}
are readable symbols. Scsh does.

@anchor{Using extended process forms in Scheme}
@section Using extended process forms in Scheme

Process forms and extended process forms are not Scheme. They are a
different notation for expressing computation that, like Scheme, is
based upon s-expressions. Extended process forms are used in Scheme
programs by embedding them inside special Scheme forms. There are
three basic Scheme forms that use extended process forms:
@code{exec-epf}, @code{&}, and @code{run}.

@deffn Syntax exec-epf . @var{epf}
The @code{(exec-epf . @var{epf})} form nukes the current process: it
establishes the I/O redirections and then overlays the current process
with the requested computation.
@end deffn

@deffn Syntax & . @var{epf}
The @code{(& . @var{epf})} form is similar to @code{exec-epf}, except
that the process is forked off in background. The form returns the
subprocess' process object.
@end deffn

@deffn Syntax run . @var{epf}
The @code{(run . @var{epf})} form runs the process in foreground:
after forking off the computation, it waits for the subprocess to
exit, and returns its exit status.
@end deffn

These special forms are macros that expand into the equivalent series
of system calls. The definition of the @code{exec-epf} macro is
non-trivial, as it produces the code to handle I/O redirections and
set up pipelines. However, the definitions of the @code{&} and
@code{run} macros are very simple:

@table @code
@item (& . @var{epf})
@equiv{} @code{(fork (lambda () (exec-epf . @var{epf})))}
@item (run . @var{epf})
@equiv{} @code{(wait (& . @var{epf}))}
@end table

@anchor{Procedures and special forms}
@subsection Procedures and special forms

It is a general design principle in scsh that all functionality made
available through special syntax is also available in a
straightforward procedural form.  So there are procedural equivalents
for all of the process notation. In this way, the programmer is not
restricted by the particular details of the syntax. Here are some of
the syntax/procedure equivalents:

@table @code
@item |
@code{fork/pipe}
@item |+
@code{fork/pipe+}
@item exec-epf
@code{exec-path}
@item <, =, >
Redirection specs use @code{open} and @code{dup}.
@item &
@code{fork}
@item run
@code{wait} + @code{fork}
@end table

Having a solid procedural foundation also allows for general
notational experimentation using Scheme's macros. For example, the
programmer can build his own pipeline notation on top of the
@code{fork} and @code{fork/pipe} procedures. @ref{System calls} for
the full story on all the procedures in the syscall library.

@anchor{Interfacing process output to Scheme}
@subsection Interfacing process output to Scheme

There is a family of procedures and special forms that can be used to
capture the output of processes as Scheme data.

@anchor{run/port}
@deffn Syntax run/port . @var{epf}
Value is a port open on process' stdout. Returns immediately after
forking child.
@end deffn

@anchor{run/file}
@deffn Syntax run/file . @var{epf}
Value is name of a temp file containing process' output. Returns when
process exits.
@end deffn

@anchor{run/string}
@deffn Syntax run/string . @var{epf}
Value is a string containing process' output. Returns when
@acronym{eof} read.
@end deffn

@anchor{run/strings}
@deffn Syntax run/strings . @var{epf}
Splits process' output into a list of newline-delimited
strings. Returns when @acronym{eof} read.
@end deffn

@anchor{run/sexp}
@deffn Syntax run/sexp . @var{epf}
Reads a single object from process' stdout with @code{read}. Returns
as soon as the read completes.
@end deffn

@anchor{run/sexps}
@deffn Syntax run/sexps . @var{epf}
Repeatedly reads objects from process' stdout with
@code{read}. Returns accumulated list upon @acronym{eof}.
@end deffn

These forms all fork off subprocesses, collecting the process' output
to stdout in some form or another. The subprocess runs with file
descriptor 1 and the current output port bound to a pipe.

The delimiting newlines are not included in the strings returned by
@code{run/strings}.

The above special forms just expand into calls to analogous
procedures. For example, @code{(run/port . @var{epf})} expands into

@example
(run/port* (lambda () (exec-epf . @var{epf}))).
@end example

The following procedures are also of utility for generally parsing
input streams in scsh:

@deffn Procedure port->string @var{port}
@code{Port->string} reads the port until @acronym{eof}, then returns
the accumulated string.
@end deffn

@deffn Procedure port->sexp-list @var{port}
@code{Port->sexp-list} repeatedly reads data from the port until
@acronym{eof}, then returns the accumulated list of items.
@end deffn

@deffn Procedure port->string-list @var{port}
@code{Port->string-list} repeatedly reads newline-terminated strings
from the port until @acronym{eof}, then returns the accumulated list
of strings. The delimiting newlines are not part of the returned
strings.
@end deffn

@deffn Procedure port->list @var{reader} @var{port}
@code{Port->list} generalises these two procedures. It uses
@emph{reader} to repeatedly read objects from a port. It accumulates
these objects into a list, which is returned upon @acronym{eof}.
@end deffn

The @code{port->string-list} and @code{port->sexp-list} procedures are
trivial to define, being merely @code{port->list} curried with the
appropriate parsers:

@example
(port->string-list @var{port}) @equiv{} (port->list read-line @var{port})
(port->sexp-list @var{port})   @equiv{} (port->list read @var{port})
@end example

The following compositions also hold:

@example
run/string*     @equiv{} port->string        @bullet{}    run/port*
run/strings*    @equiv{} port->string-list   @bullet{}    run/port*
run/sexp*       @equiv{} read                @bullet{}    run/port*
run/sexps*      @equiv{} port->sexp-list     @bullet{}    run/port*
@end example

@deffn Procedure port-fold @var{port} @var{reader} @var{op} . @var{seeds}
This procedure can be used to perform a variety of iterative
operations over an input stream.  It repeatedly uses @var{reader} to
read an object from @var{port}.  If the first read returns
@acronym{eof}, then the entire @code{port-fold} operation returns the
seeds as multiple values.  If the first read operation returns some
other value @var{v}, then @var{op} is applied to @var{v} and the
seeds: @code{(@var{op} @var{v} . @var{seeds})}.  This should return a
new set of seed values, and the reduction then loops, reading a new
value from the port, and so forth.  (If multiple seed values are used,
then @var{op} must return multiple values.)

For example, @code{(port->list @var{reader} @var{port})} could be
defined as

@example
(reverse (port-fold @var{port} @var{reader} cons '()))
@end example

An imperative way to look at @code{port-fold} is to say that it
abstracts the idea of a loop over a stream of values read from some
port, where the seed values express the loop state.

@flushright
@emph{Remark}: This procedure was formerly named @code{reduce-port}. The old binding is still provided, but is deprecated and will probably vanish in a future release.
@end flushright
@end deffn

@anchor{More complex process operations}
@section More complex process operations

The procedures and special forms in the previous section provide for
the common case, where the programmer is only interested in the output
of the process. These special forms and procedures provide more
complicated facilities for manipulating processes.

@anchor{PIDs and ports together}
@subsection PIDs and ports together

@deffn Syntax run/port+proc . @var{epf}
@deffnx Procedure run/port+proc* @var{thunk}
This special form and its analogous procedure can be used if the
programmer also wishes access to the process' pid, exit status, or
other information. They both fork off a subprocess, returning two
values: a port open on the process' stdout (and current output port),
and the subprocess's process object. A process object encapsulates the
subprocess' process id and exit code; it is the value passed to the
@code{wait} system call.

For example, to uncompress a tech report, reading the uncompressed
data into scsh, and also be able to track the exit status of the
decompression process, use the following:

@example
(receive (port child) (run/port+proc (zcat tr91-145.tex.Z))
  (let* ((paper (port->string port))
    (status (wait child)))
      @dots{} @emph{use paper, status, and child here} @dots{} ))
@end example

Note that you must @emph{first} do the @code{port->string} and
@emph{then} do the @code{wait} -- the other way around may lock up
when the @code{zcat} fills up its output pipe buffer.
@end deffn

@anchor{Multiple stream capture}
@subsection Multiple stream capture

Occasionally, the programmer may want to capture multiple distinct
output streams from a process. For instance, he may wish to read the
stdout and stderr streams into two distinct strings. This is
accomplished with the @code{run/collecting} form and its analogous
procedure, @code{run/collecting*}.

@deffn Syntax run/collecting @var{fds} . @var{epf}
@deffnx Procedure run/collecting* @var{fds} @var{thunk}
@code{Run/collecting} runs processes that
produce multiple output streams and return ports open on these
streams. To avoid issues of deadlock, @code{run/collecting} doesn't use
pipes. Instead, it first runs the process with output to temp files,
then returns ports open on the temp files. For example,

@example
(run/collecting (1 2) (ls))
@end example

runs @code{ls} with stdout (fd 1) and stderr (fd 2)
redirected to temporary files. When the @code{ls} is done,
@code{run/collecting} returns three values: the @code{ls} process' exit
status, and two ports open on the temporary files. The files are deleted
before @code{run/collecting} returns, so when the ports are closed, they
vanish. The @var{fds} list of file descriptors is implicitly backquoted
by the special-form version.

For example, if Kaiming has his mailbox protected, then

@example
(receive (status out err)
         (run/collecting (1 2) (cat /usr/kmshea/mbox))
   (list status (port->string out) (port->string err)))
@end example

might produce the list

@example
(256 "" "cat: /usr/kmshea/mbox: Permission denied").
@end example

What is the deadlock hazard that causes @code{run/collecting} to use
tempfiles? Processes with multiple output streams can lock up if they
use pipes to communicate with Scheme I/O readers. For example, suppose
some UNIX program @code{myprog} does the following:

@enumerate
@item
First, outputs a single "(" to stderr.
@item
Then, outputs a megabyte of data to stdout.
@item
Finally, outputs a single ")" to stderr, and exits.
@end enumerate

Our scsh programmer decides to run @code{myprog} with stdout and
stderr redirected via UNIX pipes to the ports @var{port1} and
@var{port2}, respectively. He gets into trouble when he subsequently
says @code{(read @var{port2})}. The Scheme @code{read} routine reads
the open paren, and then hangs in a @code{read(2)} system call trying
to read a matching close paren. But before @code{myprog} sends the
close paren down the stderr pipe, it first tries to write a megabyte
of data to the stdout pipe. However, Scheme is not reading that pipe
-- it's stuck waiting for input on stderr. So the stdout pipe quickly
fills up, and @code{myprog} hangs, waiting for the pipe to drain. The
@code{myprog} child is stuck in a stdout/@var{port1} write; the
Scheme parent is stuck in a stderr/@var{port2} read. Deadlock.

Here's a concrete example that does exactly the above:

@example
(receive (status port1 port2)
         (run/collecting (1 2)
         (begin
                ;; Write an open paren to stderr.
                (run (echo "(") (= 1 2))
                ;; Copy a lot of stuff to stdout.
                (run (cat /usr/dict/words))
                ;; Write a close paren to stderr.
                (run (echo ")") (= 1 2))))

         ;; OK. Here, I have a port PORT1 built over a pipe
         ;; connected to the BEGIN subproc's stdout, and
         ;; PORT2 built over a pipe connected to the BEGIN
         ;; subproc's stderr.
         (read port2) ; Should return the empty list.
         (port->string port1)) ; Should return a big string.
@end example

In order to avoid this problem, @code{run/collecting} and
@code{run/collecting*} first run the child process to completion,
buffering all the output streams in temp files (using the
@code{temp-file-channel} procedure, see below). When the child process
exits, ports open on the buffered output are returned. This approach
has two disadvantages over using pipes:

@itemize @bullet
@item
The total output from the child output is temporarily written to the
disk before returning from @code{run/collecting}. If this output is
some large intermediate result, the disk could fill up.
@item
The child producer and Scheme consumer are serialised; there is no
concurrency overlap in their execution.
@end itemize

However, it remains a simple solution that avoids deadlock. More
sophisticated solutions can easily be programmed up as
needed---@code{run/collecting*} itself is only 12 lines of simple
code.

See @code{temp-file-channel} for more information on creating temp
files as communication channels.
@end deffn

@anchor{Conditional process sequencing forms}
@section Conditional process sequencing forms

These forms allow conditional execution of a sequence of processes.

@deffn Syntax || @math{pf_1} @dots{} @math{pf_n}
Run each proc until one completes successfully (i.e., exit status
zero). Return true if some proc completes successfully; otherwise
@code{#f}.
@end deffn

@deffn Syntax && @math{pf_1} @dots{} @math{pf_n}
Run each proc until one fails (i.e., exit status non-zero). Return
true if all procs complete successfully; otherwise @code{#f}.
@end deffn

@anchor{Process filters}
@section Process filters

These procedures are useful for forking off processes to filter text
streams.

@deffn Procedure make-char-port-filter @var{filter}
The @emph{filter} argument is a character->character
procedure. Returns a procedure that when called, repeatedly reads a
character from the current input port, applies @emph{filter} to the
character, and writes the result to the current output port. The
procedure returns upon reaching @acronym{eof} on the input port.  For example,
to downcase a stream of text in a spell-checking pipeline, instead of
using the UNIX @code{tr A-Z a-z} command, we can say:

@example
(run (| (delatex)
        (begin ((char-filter char-downcase))) ; tr A-Z a-z
        (spell)
        (sort)
        (uniq))
     (< scsh.tex)
     (> spell-errors.txt))
@end example
@end deffn

@deffn Procedure make-string-port-filter @var{filter} [@var{buflen}]
The @var{filter} argument is a string->string procedure. Returns a
procedure that when called, repeatedly reads a string from the current
input port, applies @var{filter} to the string, and writes the result
to the current output port.The procedure returns upon reaching @acronym{eof} on
the input port.

The optional @var{buflen} argument controls the number of characters
each internal read operation requests; this means that @var{filter}
will never be applied to a string longer than @var{buflen} chars. The
default @var{buflen} value is 1024.
@end deffn

@node System calls, Networking, Process notation, Top
@chapter System calls

Scsh provides (almost) complete access to the basic UNIX kernel
services: processes, files, signals and so forth. These procedures
comprise a Scheme binding for @acronym{POSIX}, with a few of the more
standard extensions thrown in (e.g., symbolic links, @code{fchown},
@code{fstat}, sockets).

@anchor{Errors}
@section Errors

Scsh syscalls never return error codes, and do not use a global
@code{errno} variable to report errors. Errors are consistently
reported by raising exceptions. This frees up the procedures to return
useful values, and allows the programmer to assume that @emph{if a
syscall returns, it succeeded}. This greatly simplifies the flow of
the code from the programmer's point of view.

Since Scheme does not yet have a standard exception system, the scsh
definition remains somewhat vague on the actual form of exceptions and
exception handlers. When a standard exception system is defined, scsh
will move to it. For now, scsh uses the Scheme 48 exception system,
with a simple sugaring on top to hide the details in the common case.

System call error exceptions contain the UNIX @code{errno} code
reported by the system call. Unlike C, the @code{errno} value is a
part of the exception packet, it is not accessed through a global
variable.

For reference purposes, the UNIX @code{errno} numbers are bound to the
variables @code{errno/perm}, @code{errno/noent}, etc. System calls
never return @code{error/intr}---they automatically retry.

@deffn Procedure errno-error @var{errno} @var{syscall} . @var{data}
Raises a UNIX error exception for UNIX error number @code{errno}. The
syscall and data arguments are packaged up in the exception packet
passed to the exception handler.
@end deffn

@deffn Procedure with-errno-handler* @var{handler} @var{thunk}
@deffnx Syntax with-errno-handler @var{handler-spec} . @var{body}
UNIX syscalls raise error exceptions by calling @code{errno-error}. Programs can use 
@code{with-errno-handler*} to establish handlers for these exceptions.

If a UNIX error arises while @var{thunk} is executing, @var{handler} is
called on two arguments like this:

@example
(handler errno packet).
@end example

@var{Packet} is a list of the form

@example
@var{packet} @equiv{} (@var{errno-msg} @var{syscall} . @var{data}),
@end example

where @var{errno-msg} is the standard UNIX error message for the
error, @var{syscall} is the procedure that generated the error, and @var{data} is
a list of information generated by the error, which varies from
syscall to syscall.

If @var{handler} returns, the handler search continues
upwards. @var{Handler} can acquire the exception by invoking a saved
continuation. This procedure can be sugared over with the following syntax:

@example
(with-errno-handler
    ((@var{errno} @var{packet}) @var{clause} @dots{})
    @var{body1}
    @var{body2}
    @dots{})
@end example

This form executes the body forms with a particular errno handler
installed. When an errno error is raised, the handler search machinery
will bind variable @var{errno} to the error's integer code, and variable
@var{packet} to the error's auxiliary data packet. Then, the clauses
will be checked for a match. The first clause that matches is executed,
and its value is the value of the entire @code{with-errno-handler} form.
If no clause matches, the handler search continues.

Error clauses have two forms:

@example
((errno @dots{}) @var{body} @dots{})
(else @var{body} @dots{}).
@end example

In the first type of clause, the @var{errno} forms are integer
expressions. They are evaluated and compared to the error's errno value.
An @code{else} clause matches any errno value. Note that the @var{errno}
and @var{data} variables are lexically visible to the error clauses.

Example:

@example
(with-errno-handler
    ((errno packet) ; Only handle 3 particular errors.
     ((errno/wouldblock errno/again)
      (loop))
     ((errno/acces)
      (format #t "Not allowed access!")
      #f))
  (foo frobbotz)
  (blatz garglemumph))
@end example

It is not defined what dynamic context the handler executes in, so fluid
variables cannot reliably be referenced.

Note that Scsh system calls always retry when interrupted, so that the
@code{errno/intr} exception is never raised. If the programmer wishes to
abort a system call on an interrupt, he should have the interrupt
handler explicitly raise an exception or invoke a stored continuation to
throw out of the system call.
@end deffn

@anchor{Interactive mode and error handling}
@subsection Interactive mode and error handling

Scsh runs in two modes: interactive and script mode. It starts up in
interactive mode if the scsh interpreter is started up with no script
argument. Otherwise, scsh starts up in script mode. The mode determines
whether scsh prints prompts in between reading and evaluating forms, and
it affects the default error handler. In interactive mode, the default
error handler will report the error, and generate an interactive
breakpoint so that the user can interact with the system to examine,
fix, or dismiss from the error. In script mode, the default error
handler causes the scsh process to exit.

When scsh forks a child with @code{(fork)}, the child resets to script
mode. This can be overridden if the programmer wishes.

@anchor{I/O}
@section I/O

@anchor{Standard @acronym{R5RS} I/O procedures}
@subsection Standard @acronym{R5RS} I/O procedures

In scsh, most standard @acronym{R5RS} I/O operations (such as @code{display} or
@code{read-char}) work on both integer file descriptors and Scheme
ports. When doing I/O with a file descriptor, the I/O operation is done
directly on the file, bypassing any buffered data that may have
accumulated in an associated port. Note that character-at-a-time
operations such as @code{read-char} are likely to be quite slow when
performed directly upon file descriptors.

The standard @acronym{R5RS} procedures @code{read-char}, @code{char-ready?},
@code{write}, @code{display}, @code{newline}, and @code{write-char}
are all generic, accepting integer file descriptor arguments as well
as ports. Scsh also mandates the availability of @code{format}, and
further requires @code{format} to accept file descriptor arguments as
well as ports.

The procedures @code{peek-char} and @code{read} do @emph{not} accept
file descriptor arguments, since these functions require the ability
to read ahead in the input stream, a feature not supported by UNIX
I/O.

@anchor{Port manipulation and standard ports}
@subsection Port manipulation and standard ports

@deffn Procedure close-after @var{port} @var{consumer}
Returns @code{(@var{consumer} @var{port})}, but closes the port on
return. No @code{dynamic-wind} magic.
@flushright
@emph{Remark}: Is there a less-awkward name?
@end flushright
@end deffn

@deffn Procedure error-output-port
This procedure is analogous to @code{current-output-port}, but
produces a port used for error messages---the scsh equivalent of
stderr.
@end deffn

@deffn Procedure with-current-input-port* @var{port} @var{thunk}
@deffnx Procedure with-current-output-port* @var{port} @var{thunk}
@deffnx Procedure with-error-output-port* @var{port} @var{thunk}
These procedures install @var{port} as the current input, current
output, and error output port, respectively, for the duration of a call
to @var{thunk}.
@end deffn

@deffn Syntax with-current-input-port @var{port} . @var{body}
@deffnx Syntax with-current-output-port @var{port} . @var{body}
@deffnx Syntax with-error-output-port @var{port} . @var{body}
These special forms are simply syntactic sugar for the
@code{with-current-input-port*} procedure and friends.
@end deffn

@deffn Procedure set-current-input-port! @var{port}
@deffnx Procedure set-current-output-port! @var{port}
@deffnx Procedure set-error-output-port! @var{port}
These procedures alter the dynamic binding of the current I/O
port procedures to new values.
@end deffn

@deffn Procedure close @var{fd/port}
Close the port or file descriptor.

If @var{fd/port} is a file descriptor, and it has a port allocated to
it, the port is shifted to a new file descriptor created with @code{(dup
@var{fd/port})} before closing @var{fd/port}. The port then has its
revealed count set to zero.  This reflects the design criteria that
ports are not associated with file descriptors, but with open files.

To close a file descriptor, and any associated port it might have, you
must instead say one of (as appropriate):

@example
(close (fdes->inport @var{fd}))
(close (fdes->outport @var{fd}))
@end example

The procedure returns true if it closed an open port. If the port was
already closed, it returns false; this is not an error.
@end deffn

@deffn Procedure stdports->stdio
@deffnx Procedure stdio->stdports
These two procedures are used to synchronise UNIX' standard I/O file
descriptors and Scheme's current I/O ports.

@code{Stdports->stdio} causes the standard I/O file descriptors (0, 1,
and 2) to take their values from the current I/O ports. It is exactly
equivalent to the series of redirections @footnote{Why not
@code{move->fdes}?  Because the current output port and error port might
be the same port.}:

@example
(dup (current-input-port) 0)
(dup (current-output-port) 1)
(dup (error-output-port) 2)
@end example

@code{Stdio->stdports} causes the bindings of the current I/O ports to
be changed to ports constructed over the standard I/O file descriptors.
It is exactly equivalent to the series of assignments

@example
(set-current-input-port! (fdes->inport 0))
(set-current-output-port! (fdes->outport 1))
(set-error-output-port! (fdes->outport 2))
@end example

However, you are more likely to find the dynamic-extent variant,
@code{with-stdio-ports*}, below, to be of use in general programming.
@end deffn

@deffn Procedure with-stdio-ports* @var{thunk}
@deffnx Syntax with-stdio-ports @var{body} . . . 
@code{With-stdio-ports*} binds the standard ports
@code{(current-input-port)}, @code{(current-output-port)}, and
@code{(error-output-port)} to be ports on file descriptors 0, 1, 2,
and then calls @var{thunk}. It is equivalent to:

@example
(with-current-input-port (fdes->inport 0)
  (with-current-output-port (fdes->inport 1)
    (with-error-output-port (fdes->outport 2)
      (thunk))))
@end example

The @code{with-stdio-ports} special form is merely syntactic sugar.
@end deffn

@anchor{String ports}
@subsection String ports

Scheme 48 has string ports, which you can use. Scsh has not committed
to the particular interface or names that Scheme 48 uses, so be warned
that the interface described herein may be liable to change.

@deffn Procedure make-string-input-port @var{string}
Returns a port that reads characters from the supplied string.
@end deffn

@deffn Procedure make-string-output-port
@deffnx Procedure string-output-port-output @var{port}
A string output port is a port that collects the characters given to it
into a string. The accumulated string is retrieved by applying
@code{string-output-port-output} to the port.
@end deffn

@deffn Procedure call-with-string-output-port @var{procedure}
The @var{procedure} value is called on a port. When it returns,
@code{call-with-string-output-port} returns a string containing the
characters that were written to that port during the execution of
@var{procedure}.
@end deffn

@anchor{Revealed ports and file descriptors}
@subsection Revealed ports and file descriptors

The material in this section and the following one is not critical for
most applications. You may safely skim or completely skip this section
on a first reading.

Dealing with UNIX file descriptors in a Scheme environment is
difficult. In UNIX, open files are part of the process environment,
and are referenced by small integers called @emph{file
descriptors}. Open file descriptors are the fundamental way I/O
redirections are passed to subprocesses, since file descriptors are
preserved across @code{fork}s and @code{exec}s.

Scheme, on the other hand, uses ports for specifying I/O
sources. Ports are garbage-collected Scheme objects, not
integers. Ports can be garbage collected; when a port is collected, it
is also closed. Because file descriptors are just integers, it's
impossible to garbage collect them---you wouldn't be able to close
file descriptor 3 unless there were no 3's in the system, and you
could further prove that your program would never again compute a
3. This is difficult at best.

If a Scheme program only used Scheme ports, and never actually used
file descriptors, this would not be a problem. But Scheme code must
descend to the file descriptor level in at least two circumstances:

@itemize
@item
when interfacing to foreign code
@item
when interfacing to a subprocess.
@end itemize

This causes a problem. Suppose we have a Scheme port constructed on
top of file descriptor 2. We intend to fork off a program that will
inherit this file descriptor. If we drop references to the port, the
garbage collector may prematurely close file 2 before we fork the
subprocess. The interface described below is intended to fix this and
other problems arising from the mismatch between ports and file
descriptors.

The Scheme kernel maintains a port table that maps a file descriptor
to the Scheme port allocated for it (or, @code{#f} if there is no port
allocated for this file descriptor). This is used to ensure that there
is at most one open port for each open file descriptor.

The port data structure for file ports has two fields besides the
descriptor: @var{revealed} and @var{closed?}. When a file port is
closed with @code{(close port)}, the port's file descriptor is closed,
its entry in the port table is cleared, and the port's @var{closed?}
field is set to true.

When a file descriptor is closed with @code{(close fdes)}, any
associated port is shifted to a new file descriptor created with
@code{(dup fdes)}. The port has its revealed count reset to zero (and
hence becomes eligible for closing on GC). See discussion below. To
really put a stake through a descriptor's heart without waiting for
associated ports to be GC'd, you must say one of

@example
(close (fdes->inport @var{fdes}))
(close (fdes->output @var{fdes}))
@end example

The @var{revealed} field is an aid to garbage collection. It is an
integer semaphore. If it is zero, the port's file descriptor can be
closed when the port is collected. Essentially, the @var{revealed}
field reflects whether or not the port's file descriptor has escaped
to the Scheme user. If the Scheme user doesn't know what file
descriptor is associated with a given port, then he can't possibly
retain an ``integer handle'' on the port after dropping pointers to
the port itself, so the garbage collector is free to close the file.

Ports allocated with @code{open-output-file} and
@code{open-input-file} are unrevealed ports---i.e., @var{revealed} is
initialised to 0. No one knows the port's file descriptor, so the file
descriptor can be closed when the port is collected.

The functions @code{fdes->output-port}, @code{fdes->input-port},
@code{port->fdes} are used to shift back and forth between file
descriptors and ports. When @code{port->fdes} reveals a port's file
descriptor, it increments the port's revealed field. When the user is
through with the file descriptor, he can call
@code{(release-port-handle @var{port})}, which decrements the
count. The function @code{(call/fdes fd/port @var{proc})} automates
this protocol. @code{Call/fdes} uses @code{dynamic-wind} to enforce
the protocol. If @var{proc} throws out of the call/fdes application,
the unwind handler releases the descriptor handle; if the user
subsequently tries to throw back into @var{proc}'s context, the wind
handler raises an error. When the user maps a file descriptor to a
port with @code{fdes->outport} or @code{fdes->inport}, the port has
its @var{revealed} field incremented.

Not all file descriptors are created by requests to make ports. Some
are inherited on process invocation via @code{exec(2)}, and are simply
part of the global environment. Subprocesses may depend upon them, so
if a port is later allocated for these file descriptors, it should be
considered as a revealed port. For example, when the Scheme shell's
process starts up, it opens ports on file descriptors 0, 1, and 2 for
the initial values of @code{(current-input-port)},
@code{(current-output-port)}, and @code{(error-output-port)}. These
ports are initialised with @var{revealed} set to 1, so that stdin,
stdout, and stderr are not closed even if the user drops the port.

Unrevealed file ports have the nice property that they can be closed
when all pointers to the port are dropped. This can happen during gc,
or at an @code{exec()}--since all memory is dropped at an
@code{exec()}. No one knows the file descriptor associated with the
port, so the @code{exec}'d process certainly can't refer to it.

This facility preserves the transparent close-on-collect property for
file ports that are used in straightforward ways, yet allows access to
the underlying UNIX substrate without interference from the garbage
collector. This is critical, since shell programming absolutely
requires access to the UNIX file descriptors, as their numerical
values are a critical part of the process interface.

A port's underlying file descriptor can be shifted around with @code{dup(2)}
hen convenient. That is, the actual file descriptor on top of which a
port is constructed can be shifted around underneath the port by the
scsh kernel when necessary. This is important, because when the user
is setting up file descriptors prior to an @code{exec(2)}, he may explicitly
use a file descriptor that has already been allocated to some port. In
this case, the scsh kernel just shifts the port's file descriptor to
some new location with @code{dup}, freeing up its old
descriptor. This prevents errors from happening in the following
scenario. Suppose we have a file open on port @var{f}. Now we want to run a
program that reads input on file 0, writes output to file 1, errors to
file 2, and logs execution information on file 3. We want to run this
program with input from @var{f}. So we write:

@example
(run (/usr/shivers/bin/prog)
     (> 1 output.txt)
     (> 2 error.log)
     (> 3 trace.log)
     (= 0 ,f))
@end example

Now, suppose by ill chance that, unbeknownst to us, when the operating
system opened @var{f}'s file, it allocated descriptor 3 for it. If we
blindly redirect @code{trace.log} into file descriptor 3, we'll clobber @var{f}!
However, the port-shuffling machinery saves us: when the @code{run} form
tries to @code{dup} @code{trace.log}'s file descriptor to 3, @code{dup} will notice that
file descriptor 3 is already associated with an unrevealed port
(i.e., @var{f}). So, it will first move @var{f} to some other file
descriptor. This keeps @var{f} alive and well so that it can subsequently be
@code{dup}'d into descriptor 0 for @code{prog}'s stdin.

The port-shifting machinery makes the following guarantee: a port is
only moved when the underlying file descriptor is closed, either by a
@code{close()} or a @code{dup2()} operation. Otherwise a port/file-descriptor
association is stable.

Under normal circumstances, all this machinery just works behind the
scenes to keep things straightened out. The only time the user has to
think about it is when he starts accessing file descriptors from
ports, which he should almost never have to do. If a user starts asking
what file descriptors have been allocated to what ports, he has to
take responsibility for managing this information.

@anchor{Port-mapping machinery}
@subsection Port-mapping machinery

The procedures provided in this section are almost never needed. You
may safely skim or completely skip this section on a first reading.

Here are the routines for manipulating ports in scsh. The important
points to remember are:

@itemize
@item
A file port is associated with an open file, not a particular
file descriptor.
@item
The association between a file port and a particular file descriptor
is never changed except when the file descriptor is explicitly
closed. ``Closing'' includes being used as the target of a
@code{dup2}, so the set of procedures below that close their targets
are @code{close}, two-argument @code{dup}, and @code{move->fdes}. If
the target file descriptor of one of these routines has an allocated
port, the port will be shifted to another freshly-allocated file
descriptor, and marked as unrevealed, thus preserving the port but
freeing its old file descriptor.
@end itemize

These rules are what is necessary to ``make things work out'' with no
surprises in the general case.

@deffn Procedure fdes->inport @var{fd}
@deffnx Procedure fdes->outport @var{fd}
@deffnx Procedure port->fdes @var{port}
These increment the port's revealed count.
@end deffn

@deffn Procedure port-revealed @var{port}
Return the port's revealed count if positive, otherwise @code{#f}.
@end deffn

@deffn Procedure release-port-handle @var{port}
Decrement the port's revealed count.
@end deffn

@deffn Procedure call/fdes @var{fd/port} @var{consumer}
Calls @var{consumer} on a file descriptor; takes care of revealed
bookkeeping. If @var{fd/port} is a file descriptor, this is just
@code{(@var{consumer} @var{fd/port})}. If @var{fd/port} is a port,
calls @var{consumer} on its underlying file descriptor. While
@var{consumer} is running, the port's revealed count is incremented.

When @code{call/fdes} is called with port argument, you are not
allowed to throw into @var{consumer} with a stored continuation, as
that would violate the revealed-count bookkeeping.
@end deffn

@deffn Procedure move->fdes @var{fd/port} @var{target-fd}
Maps fd->fd and port->port.

If @var{fd/port} is a file descriptor not equal to @var{target-fd},
@code{dup} it to @var{target-fd} and close it. Returns
@var{target-fd}.

If @var{fd/port} is a port, it is shifted to @var{target-fd}, by
@code{dup}ing its underlying file descriptor if
necessary. @var{Fd/port}'s original file descriptor is closed (if it
was different from @var{target-fd}). Returns the port. This operation
resets @var{fd/port}'s revealed count to 1.

In all cases when @var{fd/port} is actually shifted, if there is a
port already using @var{target-fd}, it is first relocated to some
other file descriptor.
@end deffn

@anchor{UNIX I/O}
@subsection UNIX I/O

@deffn Procedure dup @var{fd/port} [@var{newfd}]
@deffnx Procedure dup->inport @var{fd/port} [@var{newfd}]
@deffnx Procedure dup->outport @var{fd/port} [@var{newfd}]
@deffnx Procedure dup->fdes @var{fd/port} [@var{newfd}]
These procedures provide the functionality of C's @code{dup()} and
@code{dup2()}. @code{Dup}'s return value depends on on the type of
@var{fd/port}--it maps fd->fd and port->port.

These procedures use the UNIX @code{dup()} syscall to replicate the file
descriptor or file port @var{fd/port}. If a @var{newfd} file descriptor
is given, it is used as the target of the @code{dup} operation, i.e.,
the operation is a @code{dup2()}. In this case, procedures that return a
port (such as @code{dup->inport}) will return one with the revealed
count set to one. For example, @code{(dup (current-input-port) 5)}
produces a new port with underlying file descriptor 5, whose revealed
count is 1. If @var{newfd} is not specified, then the operating system
chooses the file descriptor, and any returned port is marked as
unrevealed.

If the @var{newfd} target is given, and some port is already using that
file descriptor, the port is first quietly shifted (with another
@code{dup}) to some other file descriptor (zeroing its revealed count).

Since Scheme doesn't provide read/write ports, @code{dup->inport} and
@code{dup->outport} can be useful for getting an output version of an
input port, or vice versa. For example, if @var{p} is an input port open
on a tty, and we would like to do output to that tty, we can simply use
@code{(dup->outport @var{p})} to produce an equivalent output port for
the tty. Be sure to open the file with the @code{open/read+write} flag
for this.
@end deffn

@deffn Procedure seek @var{fd/port} @var{offset} [@var{whence}]
Reposition the I/O cursor for a file descriptor or port. @var{whence} is
one of @code{seek/set}, @code{seek/delta}, or @code{seek/end}, and
defaults to @code{seek/set}. If @code{seek/set}, then @var{offset} is an
absolute index into the file; if @code{seek/delta}, then @var{offset} is
a relative offset from the current I/O cursor; if @code{seek/end}, then
@var{offset} is a relative offset from the end of file. The
@var{fd/port} argument may be a port or an integer file descriptor. Not
all such values are @code{seek}able; this is dependent on the OS
implementation. The return value is the resulting position of the I/O
cursor in the I/O stream.

Oops: The current implementation doesn't handle @var{offset} arguments
that are not immediate integers (i.e., representable in 30 bits).

Oops: The current implementation doesn't handle buffered ports.
@end deffn

@deffn Procedure tell @var{fd/port}
Returns the position of the I/O cursor in the the I/O stream. Not all
file descriptors or ports support cursor-reporting; this is dependent on
the OS implementation.
@end deffn

@deffn Procedure open-file @var{fname} @var{flags} [@var{perms}]
@var{Perms} defaults to @code{#o666}. @var{Flags} is an integer bitmask,
composed by or'ing together constants listed in @ref{Table 3.1}.  You
must use exactly one of the @code{open/read}, @code{open/write}, or
@code{open/read+write} flags. The returned port is an input port if the
flags permit it, otherwise an output port. @acronym{R5RS}/Scheme 48/scsh do not
have input/output ports, so it's one or the other. This should be fixed.
(You can hack simultaneous I/O on a file by opening it r/w, taking the
result input port, and duping it to an output port with
@code{dup->outport}.)
@end deffn

@deffn Procedure open-input-file @var{fname} [@var{flags}]
@deffnx Procedure open-output-file @var{fname} [@var{flags} @var{perms}]
These are equivalent to @code{open-file}, after first setting the
@code{read/write} bits of the @var{flags} argument to @code{open/read},
or @code{open/write}, respectively.  @var{Flags} defaults to zero for
open-input-file, and

@example
(bitwise-ior open/create open/truncate)
@end example

for @code{open-output-file}. These defaults make the procedures
backwards-compatible with their unary @acronym{R5RS} definitions.
@end deffn

@deffn Procedure open-fdes @var{fname} @var{flags} [@var{perms}]
Returns a file descriptor.
@end deffn

@deffn Procedure fdes-flags @var{fd/port}
@deffnx Procedure set-fdes-flags @var{fd/port} @var{integer}
These procedures allow reading and writing of an open file's flags. The
only such flag defined by @acronym{POSIX} is
@code{fdflags/close-on-exec}; your UNIX implementation may provide
others.

These procedures should not be particularly useful to the programmer, as
the scsh runtime already provides automatic control of the close-on-exec
property. Unrevealed ports always have their file descriptors marked
close-on-exec, as they can be closed when the scsh process execs a new
program. Whenever the user reveals or unreveals a port's file
descriptor, the runtime automatically sets or clears the flag for the
programmer. Programmers that manipulate this flag should be aware of
these extra, automatic operations.
@end deffn

@deffn Procedure fdes-status @var{fd/port}
@deffnx Procedure set-fdes-status @var{fd/port} @var{integer}

These procedures allow reading and writing of an open file's status
flags (@pxref{Table 3.1}).

@anchor{Table 3.1}
@multitable @columnfractions .15 .70 .15
@headitem
@tab
Allowed operations
@tab
Status flag
@item
Open + Get + Set
@tab
These flags can be used in @code{open-file}, @code{fdes-status}, and
@code{set-fdes-status} calls.
@tab 
@code{open/append}@*
@code{open/non-blocking}@*
@code{open/async} (Non-@acronym{POSIX})@*
@code{open/fsync} (Non-@acronym{POSIX})@*

@item
Open + Get
@tab
These flags can be used in @code{open-file} and @code{fdes-status}
calls, but are ignored by @code{set-fdes-status}.
@tab
@code{open/read}@*
@code{open/write}@*
@code{open/read+write}@*
@code{open/access-mask}@*

@item Open
@tab 
These flags are only relevant in @code{open-file} calls; they are
ignored by @code{fdes-status} and @code{set-fdes-status} calls.

@tab
@code{open/create}@*
@code{open/exclusive}@*
@code{open/no-control-tty}@*
@code{open/truncate}@*
@end multitable

Table 3.1: Status flags for @code{open-file}, @code{fdes-status} and
@code{set-fdes-status}. Only @acronym{POSIX} flags are guaranteed to be
present; your operating system may define others. The
@code{open/access-mask} value is not an actual flag, but a bit mask used
to select the field for the @code{open/read}, @code{open/write} and
@code{open/read+write} bits.

Note that this file-descriptor state is shared between file descriptors
created by @code{dup}---if you create port @emph{b} by applying
@code{dup} to port @emph{a}, and change @emph{b}'s status flags, you
will also have changed @emph{a}'s status flags.
@end deffn

@deffn Procedure pipe
Returns two ports, the read and write end-points of a UNIX pipe.
@end deffn

@deffn Procedure read-string @var{nbytes} [@var{fd/port}]
@deffnx Procedure read-string! @var{string} [@var{fd/port} @var{start} @var{end}]

These calls read exactly as much data as you requested, unless there
is not enough data (@acronym{eof}). They will persistently retry on
partial reads and when interrupted until (1) error, (2) @acronym{eof},
or (3) the input request is completely satisfied. Partial reads can
occur when reading from an intermittent source, such as a pipe or tty.

@code{Read-string} returns the string read, @code{read-string!} returns
the number of characters read. They both return false at @acronym{eof}.
A request to read zero bytes returns immediately, with no check.

Any partially-read data is included in the error exception packet. Error
returns on non-blocking input are considered an error.
@end deffn

@deffn Procedure read-string/partial @var{nbytes} [@var{fd/port}]
@deffnx Procedure read-string!/partial @var{str} [@var{fd/port} @var{start} @var{end}]

These are atomic best-effort/forward-progress calls. Best effort: they
may read less than you request if there is a lesser amount of data
immediately available (e.g., because you are reading from a pipe or a
tty). Forward progress: if no data is immediately available (e.g., empty
pipe), they will block. Therefore, if you request an @math{n > 0} byte
read, while you may not get everything you asked for, you will always
get something (barring @acronym{eof}).

There is one case in which the forward-progress guarantee is cancelled:
when the programmer explicitly sets the port to non-blocking I/O. In
this case, if no data is immediately available, the procedure will not
block, but will immediately return a zero-byte read.

@code{Read-string/partial} reads the data into a freshly allocated
string, which it returns as its value.

@code{Read-string!/partial} reads the data into string @var{str} at the
indices in the half-open interval [@var{start}, @var{end}]; the default
interval is the whole string: @var{start} = 0 and @var{end} =
@code{(string-length @var{str})}.The values of @var{start} and @var{end}
must specify a well-defined interval in @var{str}, i.e., @math{0 <=}
@var{start} @math{<=} @var{end} @math{<=} @code{(string-length
@var{str})}. It returns the number of bytes read.

A request to read zero bytes returns immediatedly, with no @acronym{eof}
check.

In sum, there are only three ways you can get a zero-byte read: (1) you
request one, (2) you turn on non-blocking I/O, or (3) you try to read at
@acronym{eof}. These are the routines to use for non-blocking input.
They are also useful when you wish to efficiently process data in large
blocks, and your algorithm is insensitive to the block size of any
particular read operation.
@end deffn

@deffn Procedure select @var{rvec} @var{wvec} @var{evec} [@var{timeout}]
@deffnx Procedure select! @var{rvec} @var{wvec} @var{evec} [@var{timeout}]

The @code{select} procedure allows a process to block and wait for
events on multiple I/O channels. The @var{rvec} and @var{evec} arguments
are vectors of input ports and integer file descriptors; @var{wvec} is a
vector of output ports and integer file descriptors. The procedure
returns three vectors whose elements are subsets of the corresponding
arguments. Every element of @var{rvec'} is ready for input; every
element of @var{wvec'} is ready for output; every element of @var{evec'}
has an exceptional condition pending.

The select call will block until at least one of the I/O channels passed
to it is ready for operation. For an input port this means that it
either has data sitting its buffer or that the underlying file
descriptor has data waiting. For an output port this means that it
either has space available in the associated buffer or that the
underlying file descriptor can accept output. For file descriptors, no
buffers are checked, even if they have associated ports.

The @var{timeout} value can be used to force the call to time-out after
a given number of seconds. It defaults to the special value @code{#f},
meaning wait indefinitely. A zero value can be used to poll the I/O
channels.

If an I/O channel appears more than once in a given vector---perhaps
occuring once as a Scheme port, and once as the port's underlying
integer file descriptor---only one of these two references may appear in
the returned vector. Buffered I/O ports are handled specially---if an
input port's buffer is not empty, or an output port's buffer is not yet
full, then these ports are immediately considered eligible for I/O
without using the actual, primitive select system call to check the
underlying file descriptor. This works pretty well for buffered input
ports, but is a little problematic for buffered output ports.

The @code{select!} procedure is similar, but indicates the subset of
active I/O channels by side-effecting the argument vectors. Non-active
I/O channels in the argument vectors are overwritten with @code{#f}
values. The call returns the number of active elements remaining in each
vector. As a convenience, the vectors passed in to @code{select!} are
allowed to contain @code{#f} values as well as integers and ports.

Remark: @code{Select} and @code{select!} do not call their
@acronym{POSIX} counterparts directly---there is a @acronym{POSIX}
@code{select} sitting at the very heart of the Scheme 48/scsh I/O
system, so all multiplexed I/O is really @code{select}-based. Therefore,
you cannot expect a performance increase from writing a single-threaded
program using @code{select} and @code{select!} instead of writing a
multi-threaded program where each thread handles one I/O connection.

The moral of this story is that @code{select} and @code{select!} make
sense in only two situations: legacy code written for an older version
of scsh, and programs which make inherent use of @code{select/select!}
which do not benefit from multiple threads. Examples are network clients
that send requests to multiple alternate servers and discard all but one
of them.  In any case, the @code{select-ports} and
@code{select-port-channels} procedures described below are usually a
preferable alternative to @code{select}/@code{select!}: they are much
simpler to use, and also have a slightly more efficient implementation.
@end deffn

@deffn Procedure select-ports @var{timeout} @var{port} @dots{}

The @code{select-ports} call will block until at least one of the ports
passed to itis ready for operation or until the timeout has expired. For
an input port this means that it either has data sitting in its buffer
or that the underlying file descriptor has data waiting. For an output
port this means that it either has space available in the associated
buffer or that the underlying file descriptor can accept output.

The @var{timeout} value can be used to force the call to time out after
a given number of seconds. A value of @code{#f} means to wait
indefinitely. A zero value can be used to poll the ports.

@code{Select-ports} returns a list of the ports ready for operation.
Note that this list may be empty if the timeout expired before any ports
became ready.
@end deffn

@deffn Procedure select-port-channels @var{timeout} @var{port} @dots{}

@code{Select-port-channels} is like @code{select-ports}, except that it
only looks at the operating system objects the ports refer to, ignoring
any buffering performed by the ports.

Remark: @code{Select-port-channels} should be used with care: for
example, if an input port has data in the buffer but no data available
on the underlying file descriptor, @code{select-port-channels} will
block, even though a read operation on the port would be able to
complete without blocking.

@code{Select-port-channels} is intended for situations where the program
is not checking for available data, but rather waiting until a port has
established a connection---for example, to a network port.
@end deffn

@deffn Procedure write-string @var{string} [@var{fd/port} @var{start} @var{end}]

This procedure writes all the data requested. If the procedure cannot
perform the write with a single kernel call (due to interrupts or
partial writes), it will perform multiple write operations until all the
data is written or an error has occurred. A non-blocking I/O error is
considered an error. (Error exception packets for this syscall include
the amount of data partially transferred before the error occurred.)

The data written are the characters of @var{string} in the half-open
interval [@var{start}, @var{end}]. The default interval is the whole
string: @var{start} = 0 and @var{end} = @code{(string-length
@var{string})}. The values of @var{start} and @var{end} must specify a
well-defined interval in @var{string}, i.e., 0 @math{<=} @var{start}
@math{<=} @var{end} @math{<=} @code{(string-length @var{string})}. A
zero-byte write returns immediately, with no error.

Output to buffered ports: write-string's efforts end as soon as all
thedata has been placed in the output buffer. Errors and true output may
not happen until a later time, of course.
@end deffn

@deffn Procedure write-string/partial @var{string} [@var{fd/port} @var{start} @var{end}]

This routine is the atomic best-effort/forward-progress analog to
@code{write-string}. It returns the number of bytes written, which may
be less than you asked for. Partial writes can occur when (1) we write
off the physical end of the media, (2) the write is interrrupted, or
(3) the filedescriptor is set for non-blocking I/O.

If the file descriptor is not set up for non-blocking I/O, then a
successful return from these procedures makes a forward progress
guarantee---that is, a partial write took place of at least one byte:

@itemize
@item
If we are at the end of physical media, and no write takes place, an
error exception is raised. So a return implies we wrote something.

@item
If the call is interrupted after a partial transfer, it returns
immediately. But if the call is interrupted before any data transfer,
then the write is retried.
@end itemize

If we request a zero-byte write, then the call immediately returns
0. If thefile descriptor is set for non-blocking I/O, then the call
may return 0 if it was unable to immediately write anything (e.g.,
full pipe). Barring thesetwo cases, a write either returns
@var{nwritten} @math{>} 0, or raises an error exception.

Non-blocking I/O is only available on file descriptors and unbuffered
ports. Doing non-blocking I/O to a buffered port is not well-defined,
and is an error (the problem is the subsequent flush operation).

Oops: @code{write-string/partial} is currently not
implemented. Consider using threads to achive the same functionality.
@end deffn

@anchor{Buffered I/O}
@subsection Buffered I/O

Scheme 48 ports use buffered I/O---data is transferred to or from the
OS in blocks. Scsh provides control of this mechanism: the programmer
may force saved-up output data to be transferred to the OS when he
chooses, and may also choose which I/O buffering policy to employ for
a given port (or turn buffering off completely).

It can be useful to turn I/O buffering off in some cases, for example
when an I/O stream is to be shared by multiple subprocesses. For this
reason, scsh allocates an unbuffered port for file descriptor 0 at
start-up time. Because shells frequently share stdin with
subprocesses, if the shell does buffered reads, it might ``steal''
input intended for a subprocess. For this reason, all shells,
including @code{sh}, @code{csh}, and @code{scsh} , read stdin
unbuffered. Applications that can tolerate buffered input on stdin can
reset @code{current-input-port} to block buffering for higher
performance.

Note: To support @code{peek-char} a Scheme implementation has to
maintain a buffer for all input ports. In scsh, for ``unbuffered''
input ports the buffer size is one. As you cannot request less then
one character there is no unrequested reading so this can still be
called ``unbuffered input''.

@deffn Procedure set-port-buffering @var{port} @var{policy} [@var{size}]

This procedure allows the programmer to assign a particular I/O
buffering policy to a port, and to choose the size of the associated
buffer. It may only be used on new ports, i.e., before I/O is
performed on the port. There are three buffering policies that may be
chosen:

@table @code
@item bufpol/block
General block buffering (general default)
@item bufpol/line
Line buffering (tty default)
@item bufpol/none
Direct I/O---no buffering
@end table

The line buffering policy flushes output whenever a newline is output;
whenever the buffer is full; or whenever an input is read from
stdin. Line buffering is the default for ports open on terminal
devices.

Oops: The current implementation doesn't support @code{bufpol/line}.

The @var{size} argument requests an I/O buffer of @var{size}
bytes. For output ports, @var{size} must be non-negative, for input
ports @var{size} must be positve. If not given, a reasonable default
is used. For output ports, if given and zero, buffering is turned off
(i.e., @var{size} @math{= 0} for any policy is equivalent to
@var{policy} @math{=} @code{bufpol/none}). For input ports, setting
the size to one corresponds to unbuffered input as defined above. If
given, @var{size} must be zero respectively one for
@code{bufpol/none}.
@end deffn

@deffn Procedure force-output [@var{fd/port}]
This procedure does nothing when applied to an integer file descriptor
or unbuffered port. It flushes buffered output when applied to a
buffered port, and raises a write-error exception on error. Returns no
value.
@end deffn

@deffn Procedure flush-all-ports
This procedure flushes all open output ports with buffered data.
@end deffn

@anchor{File locking}
@subsection File locking

Scsh provides @acronym{POSIX} advisory file locking. Advisory locks are
locks that can be checked by user code, but do not affect other I/O
operations. For example, if a process has an exclusive lock on a region
of a file, other processes will not be able to obtain locks on that
region of the file, but they will still be able to read and write the
file with no hindrance. Using advisory locks requires cooperation
amongst the agents accessing the shared resource.

@emph{Remark}: Unfortunately, @acronym{POSIX} file locks are associated
with actual files, not with associated open file descriptors. Once a
process locks a file, using some file descriptor @emph{fd}, the next
time any file descriptor referencing that file is closed, all associated
locks are released. This severely limits the utility of @acronym{POSIX}
advisory file locks, and we'd recommend caution when using them.It is
not without reason that the FreeBSD man pages refer to @acronym{POSIX}
file locking as "completely stupid."

Scsh moves Scheme ports from file descriptor to file descriptor with
@code{dup()} and @code{close()} as required by the runtime, so it is
impossible to keep file locks open across one of these shifts. Hence we
can only offer POSIX advisory file locking directly on raw integer file
descriptors; regrettably, there are no facilities for locking Scheme
ports.

Note that once a Scheme port is revealed in scsh, the runtime will not
shift the port around with @code{dup()} and @code{close()}. This means
the file-locking procedures can then be applied to the port's associated
file descriptor.

@acronym{POSIX} allows the user to lock a region of a file with either an exclusive or shared lock. Locked regions are described by the @code{lock-region} record:

@example
(define-record lock-region
  exclusive?
  start
  len
  whence
  proc)
@end example

@itemize
@item
The @code{exclusive?} field is true if the lock is exclusive; false if it is shared.
@item
The whence field is one of the values from the seek call: @code{seek/set},
@code{seek/delta}, or @code{seek/end}, and determines the interpretation of the
@code{start} field:
@itemize
@item
If @code{seek/set}, the start value is simply an absolute index into the
file.
@item
If @code{seek/delta}, the start value is an offset from the file
descriptor's current position in the file.
@item
If @code{seek/end}, the start value is an offset from the end of the
file.
@end itemize
The region of the file being locked is given by the @code{start} and
@code{len} fields; if @code{len} is zero, it means "infinity," that is,
the region extends from the starting point through the end of the file,
even as the file is extended by subsequent write operations.
@item
The @code{proc} field gives the process object for the process holding the
region lock, when relevant (see @code{get-lock-region} below).
@end itemize

@deffn Procedure make-lock-region @var{exclusive?} @var{start} @var{len} [@var{whence}]

This procedure makes a lock-region record. The @var{whence} field
defaults to @code{seek/set}.
@end deffn

@deffn Procedure lock-region @var{fdes} @var{lock}
@deffnx Procedure lock-region/no-block @var{fdes} @var{lock}

These procedures lock a region of the file referenced by file
descriptor @var{fdes}. The @code{lock-region} procedure blocks until
the lock is granted; the non-blocking variant returns a boolean
indicating whether or not the lock was granted. To take an exclusive
(write) lock, you must have the file descriptor open with write
access; to take a shared (read) lock, you must have the file
descriptor open with read access.
@end deffn

@deffn Procedure get-lock-region @var{fdes} @var{lock}

Return the first lock region on @var{fdes} that would conflict with lock
region @var{lock}. If there is no such lock region, return false. This
procedure fills out the @code{proc} field of the returned lock region,
and is the only procedure that has anything to do with this field.
(@xref{Process objects and process reaping}.) Note that if you apply
this procedure to a file system that is shared across multiple operating
systems (i.e., an NFS file system), the @code{proc} field may be
ambiguous. We note, again, that @acronym{POSIX} advisory file locking is
not a terribly useful or well-designed facility.
@end deffn

@deffn Procedure unlock-region @var{fdes} @var{lock}

Release a lock from a file.
@end deffn

@deffn Procedure with-region-lock* @var{fdes} @var{lock} @var{thunk}
@deffnx Syntax with-region-lock @var{fdes} @var{lock} @var{body} @dots{}

This procedure obtains the requested lock, and then calls
@var{thunk}. When @var{thunk} returns, the lock is released. A
non-local exit (e.g., throwing to a saved continuation or raising an
exception) also causes the lock to be released.
        
After a normal return from @var{thunk}, its return values are returned
by @code{with-region-lock*}. The @code{with-region-lock} special form
is equivalent syntactic sugar.
@end deffn

@anchor{File system}
@section File system

Besides the following procedures, which allow access to the computer's
file system, scsh also provides a set of procedures which manipulate
file @emph{names}. These string-processing procedures are documented
in section @ref{Manipulating file names}.

@deffn Procedure create-directory @var{fname} [@var{perms} @var{override?}]
@deffnx Procedure create-fifo @var{fname} [@var{perms} @var{override?}]
@deffnx Procedure create-hard-link @var{oldname} @var{newname} [@var{override?}]
@deffnx Procedure create-symlink @var{old-name} @var{new-name} [@var{override?}]

These procedures create objects of various kinds in the file system.

The @var{override?} argument controls the action if there is already
an object in the file system with the new name:

@table @asis
@item @code{#f}
Signal an error (the default).
@item @code{'query}
Prompt the user.
@item @var{other}
Delete the old object (with @code{delete-file} or
@code{delete-directory}, as appropriate) before creating the new
object.
@end table

@var{Perms} defaults to @code{#o777} (but is masked by the current umask).

@emph{Remark}: Currently, if you try to create a hard or symbolic link
from a file to itself, you will error out with @var{override?}  false,
and simply delete your file with @var{override?}  true. Catching this
will require some sort of true-name procedure, which I currently do
not have.
@end deffn

@deffn Procedure delete-directory @var{fname}
@deffnx Procedure delete-file @var{fname}
@deffnx Procedure delete-filesys-object @var{fname}

These procedures delete objects from the file system. The
@code{delete-filesys-object} procedure will delete an object of any
type from the filesystem: files, (empty) directories, symlinks, fifos,
etc.

If the object being deleted doesn't exist, @code{delete-directory} and
@code{delete-file} raise an error, while @code{delete-filesys-object}
simply returns.
@end deffn

@deffn Procedure read-symlink @var{fname}

Return the filename referenced by symbolic link @var{fname}.
@end deffn

@deffn Procedure rename-file @var{old-fname} @var{new-fname} [@var{override?}]

If you override an existing object, then @var{old-fname} and
@var{new-fname} must type-match--either both directories, or both
non-directories. This is required by the semantics of UNIX
@code{rename()}.

@emph{Remark}: There is an unfortunate atomicity problem with the
@code{rename-file} procedure: if you specify no-override, but create
file @var{new-fname} sometime between @code{rename-file} 's existence
check and the actual rename operation, your file will be clobbered
with @code{old-fname}.There is no way to fix this problem, given the
semantics of UNIX @code{rename()}; at least it is highly unlikely to
occur in practice.
@end deffn

@deffn Procedure set-file-mode @var{fname/fd/port} @var{mode}
@deffnx Procedure set-file-owner @var{fname/fd/port} @var{uid}
@deffnx Procedure set-file-group @var{fname/fd/port} @var{gid}

These procedures set the permission bits, owner id, and group id of a
file, respectively. The file can be specified by giving the filename,
or either an integer file descriptor or a port open on the
file. Setting file user ownership usually requires root privileges.
@end deffn

@deffn Procedure set-file-times @var{fname} [@var{access-time} @var{mod-time}]

This procedure sets the access and modified times for the file fname to
the supplied values. (@xref{Time}.) If neither time argument is
supplied, they are both taken to be the current time. You must provide
both times or neither. If the procedure completes successfully, the
file's time of last status-change (@code{ctime}) is set to the current
time.
@end deffn

@deffn Procedure sync-file @var{fd/port}
@deffnx Procedure sync-file-system

Calling @code{sync-file} causes UNIX to update the disk data
structures for a given file. If @var{fd/port} is a port, any buffered
data it may have is first flushed.

Calling @code{sync-file-system} synchronises the kernel's entire file
system with the disk.

These procedures are not @acronym{POSIX}. Interestingly enough,
@code{sync-filesystem} doesn't actually do what it is claimed to
do. We just threw it in for humor value. See the @code{sync(2)} man
page for UNIX enlightenment.
@end deffn

@deffn Procedure truncate-file @var{fname/fd/port} @var{len}

The specified file is truncated to @var{len} bytes in length.
@end deffn

@deffn Procedure file-info @var{fname/fd/port} [@var{chase?}]

The @var{file-info} procedure returns a record structure containing
everything there is to know about a file. If the @var{chase?} flag is
true (the default), then the procedure chases symlinks and reports on
the files to which they refer. If @var{chase?} is false, then the
procedure checks the actual file itself, even if it's a symlink. The
@var{chase?} flag is ignored if the file argument is a file descriptor
or port.

The value returned is a @emph{file-info} record, defined to have the
following structure:

@example
(define-record file-info 
    type ; block-special, char-special, directory,
         ; fifo, regular, socket, symlink
    device ; Device file resides on.
    inode ; File's inode.
    mode ; File's mode bits: permissions, setuid, setgid
    nlinks ; Number of hard links to this file.
    uid ; Owner of file.
    gid ; File's group id.
    size ; Size of file, in bytes.
    atime ; Time of last access.
    mtime ; Time of last mod.
    ctime) ; Time of last status change.
@end example

The @var{uid} field of a @emph{file-info} record is accessed with the
procedure

@example
(file-info:uid x)
@end example

and similarly for the other fields. The @var{type} field is a symbol;
all other fields are integers. A @emph{file-info} record is
discriminated with the @code{file-info?} predicate.

The following table of procedures each return selected information
about a file as shown; they are built on top of @code{file-info}, and
are called with the same arguments that are passed to it.

@table @code
@item file-type
type
@item file-inode
inode
@item file-mode
mode
@item file-nlinks
nlinks
@item file-owner
uid
@item file-group
gid
@item file-size
size
@item file-last-access
atime
@item
file-last-mod 
mtime
@item file-last-status-change 
ctime
@end table

Example:
@example
;; All my files in /usr/tmp:
(filter (lambda (f) (= (file-owner f) (user-uid)))
    (directory-files "/usr/tmp"))
@end example

@emph{Remark}: @code{file-info} was named @code{file-attributes} in
releases of scsh prior to release 0.4. We changed the name to
@code{file-info} for consistency with the other information-retrieval
procedures in scsh: @code{user-info}, @code{group-info},
@code{host-info}, @code{network-info}, @code{service-info}, and
@code{protocol-info}.

The @code{file-attributes} binding is still supported in the current
release of scsh, but is deprecated, and may go away in a future
release.
@end deffn

@deffn Procedure file-directory? @var{fname/fd/port} [@var{chase?}]
@deffnx Procedure file-fifo? @var{fname/fd/port} [@var{chase?}]
@deffnx Procedure file-regular? @var{fname/fd/port} [@var{chase?}]
@deffnx Procedure file-socket? @var{fname/fd/port} [@var{chase?}]
@deffnx Procedure file-special? @var{fname/fd/port} [@var{chase?}]
@deffnx Procedure file-symlink? @var{fname/fd/port}

These procedures are file-type predicates that test the type of a given
file. They are applied to the same arguments to which @code{file-info}
is applied; the sole exception is @code{file-symlink?}, which does not
take the optional @var{chase?} second argument.

For example,

@example
(file-directory? "/usr/dalbertz") =) #t
@end example
@end deffn

There are variants of these procedures which work directly on
@code{file-info} records:

@deffn Procedure file-info-directory? @var{file-info}
@deffnx Procedure file-info-fifo? @var{file-info}
@deffnx Procedure file-info-regular? @var{file-info}
@deffnx Procedure file-info-socket? @var{file-info}
@deffnx Procedure file-info-special? @var{file-info}
@deffnx Procedure file-info-symlink? @var{file-info}
@end deffn

The following set of procedures are a convenient means to work on the
permission bits of a file:

@deffn Procedure file-not-readable? @var{fname/fd/port}
@deffnx Procedure file-not-writable? @var{fname/fd/port}
@deffnx Procedure file-not-executable? @var{fname/fd/port}

The following table lists the possible return values, and their
meanings.

@table @code
@item #f
Access permitted.
@item 'search-denied
Can't stat--a protected directory is blocking access.
@item 'permission
Permission denied.
@item 'no-directory
Some directory doesn't exist.
@item 'nonexistent
File doesn't exist.
@end table

A file is considered writeable if either (1) it exists and is writeable
or (2) it doesn't exist and the directory is writeable. Since symlink
permission bits are ignored by the filesystem, these calls do not take a @var{chase?} flag.

Note that these procedures use the process' @emph{effective} user and
group IDs for permission checking. @acronym{POSIX} defines an
@code{access()} function that uses the process' real uid and gids. This
is handy for setuid programs that would like to find out if the actual
user has specific rights; scsh ought to provide this functionality (but
doesn't at the current time).

There are several problems with these procedures. First, there's an
atomicity issue. In between checking permissions for a file and then
trying an operation on the file, another process could change the
permissions, so a return value from these functions guarantees nothing.
Second, the code special-cases permission checking when the uid is
root---if the file exists, root is assumed to have the requested
permission. However, not even root can write a file that is on a
read-only file system, such as a CD-ROM.  In this case,
@code{file-not-writable?} will lie, saying that root has write access,
when in fact opening the file for write access will fail. Finally, write
permission confounds write access and create access. These shouldbe
disentangled.

Some of these problems could be avoided if @acronym{POSIX} had a
real-uid variant of the @code{access()} call we could use, but the
atomicity issue is still a problem. In the final analysis, the only way
to find out if you have the right to perform an operation on a file is
to try and open it for the desired operation. These permission-checking
functions are mostly intended for script-writing, where loose guarantees
are tolerated.
@end deffn

@deffn Procedure file-readable? @var{fname/fd/port}
@deffnx Procedure file-writable? @var{fname/fd/port}
@deffnx Procedure file-executable? @var{fname/fd/port}

These procedures are the logical negation of the preceding
@code{file-not-...?} procedures. Refer to them for a discussion of their
problems and limitations.
@end deffn

@deffn Procedure file-info-not-readable? @var{file-info}
@deffnx Procedure file-info-not-writable? @var{file-info}
@deffnx Procedure file-info-not-executable? @var{file-info}
@end deffn

@deffn Procedure file-info-readable? @var{file-info}
@deffnx Procedure file-info-writable? @var{file-info}
@deffnx Procedure file-info-executable? @var{file-info}
@end deffn

There are variants which work directly on @code{file-info} records.

@deffn Procedure file-not-exists? @var{fname/fd/port} [@var{chase?}]

Returns:

@table @code
@item #f
Exists.
@item #t
Doesn't exist.
@item 'search-denied
Some protected directory is blocking the search.
@end table

@end deffn

@deffn Procedure file-exists? @var{fname/fd/port} [@var{chase?}]

This is simply @code{(not (file-not-exists? fname))}.
@end deffn

@deffn Procedure directory-files [@var{dir} @var{dotfiles?}]

Return the list of files in directory @var{dir}, which defaults to the
current working directory. The @var{dotfiles?} flag (default @code{#f})
causes dotfiles to be included in the list. Regardless of the value of
@var{dotfiles?}, the two files @code{.} and @code{..} are never
returned.

The directory @var{dir} is not prepended to each filename in the result
list. That is,

@example
(directory-files "/etc")
@end example

returns

@example
("chown" "exports" "fstab" ...)
@end example

not

@example
("/etc/chown" "/etc/exports" "/etc/fstab" ...)
@end example

To use the files in the returned list, the programmer can either
manually prepend the directory:

@example
(map (lambda (f) (string-append dir "/" f)) files)
@end example

or @code{cd} to the directory before using the filenames:

@example
(with-cwd dir
  (for-each delete-file (directory-files)))
@end example

or use the @code{glob} procedure, defined below.

A directory list can be generated by @code{(run/strings (ls))}, but this
is unreliable, as filenames with whitespace in their names will be split
into separate entries. Using @code{directory-files} is reliable.
@end deffn

@deffn Procedure open-directory-stream @var{dir}
@deffnx Procedure read-directory-stream @var{directory-stream-record}
@deffnx Procedure close-directory-stream @var{directory-stream-record}

These functions implement a direct interface to the @code{opendir()}/
@code{readdir()}/ @code{closedir()} family of functions for processing
directory streams.  @code{(open-directory-stream @var{dir})} creates a
stream of files in the directory
@var{dir}. @code{(Read-directory-stream @var{directory-stream})}
returns the next file in the stream or @code{#f} if no such file
exists. Finally, @code{(close-directory-stream
@var{directory-stream})} closes the stream.
@end deffn

@deffn Procedure glob @var{pat1} @dots{}

Glob each pattern against the filesystem and return the sorted
list. Duplicates are not removed. Patterns matching nothing are not
included literally @footnote{Why bother to mention such a silly
possibility? Because that is what sh does.}. C shell @{a,b,c@}
patterns are expanded. Backslash quotes characters, turning off the
special meaning of @{, @}, *, [, ], and ?.

Note that the rules of backslash for Scheme strings and glob patterns
work together to require four backslashes in a row to specify a single
literal backslash. Fortunately, it is very rare that a backslash
occurs in a UNIX filename.

A glob subpattern will not match against dot files unless the first
character of the subpattern is a literal ".". Further, a dot
subpattern will not match the files @code{.} or @code{..} unless it is
a constant pattern, as in @code{(glob "../*/*.c")}. So a directory's
dot files can be reliably generated with the simple glob pattern
@code{".*"}.

Some examples:

@table @code
@item (glob "*.c" "*.h")

;; All the C and #include files in my directory.

@item (glob "*.c" "*/*.c")

;; All the C files in this directory and @*
;; its immediate subdirectories.

@item (glob "lexer/*.c" "parser/*.c")
@itemx (glob "@{lexer,parser@}/*.c")

;; All the C files in the lexer and parser dirs.

@item (glob "\\@{lexer,parser\\@}/*.c")

;; All the C files in the strange @*
;; directory "@{lexer,parser@}".

@item (glob "*\\*")

;; All the files ending in "*", e.g. @*
;; @code{("foo*" "bar*")}

@item (glob "*lexer*")

@code{("mylexer.c" "lexer1.notes")} @*
;; All files containing the string "lexer".

@item (glob "lexer")

;; Either ("lexer") or ().
@end table

If the first character of the pattern (after expanding braces) is a
slash, the search begins at root; otherwise, the search begins in the
current working directory.

If the last character of the pattern (after expanding braces) is a
slash, then the result matches must be directories, e.g.,

@example
(glob "/usr/man/man?/") ==>
  ("/usr/man/man1/" "/usr/man/man2/" ...)
@end example

Globbing can sometimes be useful when we need a list of a directory's
files where each element in the list includes the pathname for the
file. Compare:

@example
(directory-files "../include") ==>
  ("cig.h" "decls.h" ...)

(glob "../include/*") =>
  ("../include/cig.h" "../include/decls.h" ...)
@end example
@end deffn

@deffn Procedure glob-quote @var{str}

Returns a constant glob pattern that exactly matches @var{str}. All
wildcard characters in @var{str} are quoted with a backslash.

@example
(glob-quote "Any *.c files?") ==>
  "Any \*.c files\?"
@end example
@end deffn

@deffn Procedure file-match @var{root} @var{dot-files?} @var{@math{pat_1}} @var{@math{pat_2}} @dots{} @var{@math{pat_n}}

@emph{(Note: This procedure is deprecated, and will probably either go
away or be substantially altered in a future release. New code should
not call this procedure. The problem is that it relies upon
@acronym{POSIX}-notation regular expressions; the rest of scsh has
been converted over to the new SRE notation.)}

@code{File-match} provides a more powerful file-matching service, at
the expense of a less convenient notation. It is intermediate in power
between most shell matching machinery and recursive @code{find(1)}.

Each pattern is a regexp. The procedure searches from @var{root},
matching the first-level files against pattern @math{pat_1}, the
second-level files against @math{pat_2}, and so forth. The list of
files matching the whole path pattern is returned, in sorted
order. The matcher uses Spencer's regular expression package.

The files @code{.} and @code{..} are never matched. Other dot files
are only matched if the @var{dot-files?} argument is @code{#t}.

A given @var{@math{pat_i}} pattern is matched as a regexp, so it is
not forced to match the entire filename. E.g., pattern @code{"t"}
matches any file containing a ``t'' in its name, while pattern
@code{"^t$"} matches only a file whose entire name is ``t''.

The @var{@math{pat_i}} patterns can be more general than stated above.

@itemize @bullet
@item
A single pattern can specify multiple levels of the path by embedding
@code{/} characters within the pattern. For example, the pattern
@code{"a/b/c"} gives a match equivalent to the list of patterns
@code{"a"} @code{"b"} @code{"c"}.

@item
A @var{@math{pat_i}} pattern can be a procedure, which is used as a
match predicate. It will be repeatedly called with a candidate
filename to test. The filename will be the entire path accumulated. If
the procedure raises an error condition, @code{file-match} will catch
the error and treat it as a failed match. This keeps @code{file-match}
from being blown out of the water by applying tests to dangling
symlinks and other similar situations.
@end itemize

Some examples:

@example
(file-match "/usr/lib" #f "m$" "^tab") ==>
  ("/usr/lib/term/tab300" "/usr/lib/term/tab300-12" ...)

(file-match "." #f "^lex|parse|codegen$" "\\.c$") ==>
  ("lex/lex.c" "lex/lexinit.c" "lex/test.c"
   "parse/actions.c" "parse/error.c" parse/test.c"
   "codegen/io.c" "codegen/walk.c")

(file-match "." #f "^lex|parse|codegen$/\\.c$")
  ;; The same.

(file-match "." #f file-directory?)
  ;; Return all subdirs of the current directory.

(file-match "/" #f file-directory?) ==>
  ("/bin" "/dev" "/etc" "/tmp" "/usr")
  ;; All subdirs of root.

(file-match "." #f "\\.c")
  ;; All the C files in my directory.

(define (ext extension)
  (* (fn) (string-suffix? fn extension)))

(define (true . x) #t)

(file-match "." #f "./\\.c")
(file-match "." #f "" "\\.c")
(file-match "." #f true "\\.c")
(file-match "." #f true (ext "c"))
  ;; All the C files of all my immediate subdirs.

(file-match "." #f "lexer") ==>
  ("mylexer.c" "lexer.notes")
  ;; Compare with (glob "lexer"), above.
@end example

Note that when root is the current working directory (@code{"."}), when it is
converted to directory form, it becomes ``'', and doesn't show up in the
result filenames.

It is regrettable that the regexp wild card char, ``.'', is such an
important filename literal, as a dotfile prefix and an extension delimiter.
@end deffn

@deffn Procedure create-temp-file [@var{prefix}]

@code{Create-temp-file} creates a new temporary file and returns its
name. The optional argument specifies the filename prefix to use, and
defaults to the value of @code{"$TMPDIR/@var{pid}"} if @code{$TMPDIR} is
set and to @code{"/var/tmp/@var{pid}"} otherwise, where @var{pid} is the
current process' ID. The procedure generates a sequence of filenames
that have @var{prefix} as a common prefix, looking for a filename that
doesn't already exist in the file system. When it finds one, it creates
it with permission @code{#o600} and returns the filename. (The file
permission can be changed to a more permissive permission with
@code{set-file-mode} after being created).

This file is guaranteed to be brand new. No other process will have it
open. This procedure does not simply return a filename that is very
likely to be unused. It returns a filename that definitely did not exist
at the moment @code{create-temp-file} created it.

It is not necessary for the process' PID to be a part of the filename
for the uniqueness guarantees to hold. The PID component of the default
prefix simply serves to scatter the name searches into sparse regions,
so that collisions are less likely to occur. This speeds things up, but
does not affect correctness.

@emph{Security note}: doing I/O to files created this way in
@code{/var/tmp/} is not necessarily secure. General users have write
access to @code{/var/tmp/}, so even if an attacker cannot access the new
temp file, he can delete it and replace it with one of his own. A
subsequent open of this filename will then give you his file, to which
he has access rights. There are several ways to defeat this attack:

@enumerate
@item
Use @code{temp-file-iterate}, below, to return the file descriptor
allocated when the file is opened. This will work if the file only needs
to be opened once.
@item
If the file needs to be opened twice or more, create it in a protected
directory, e.g., @code{$HOME}.
@item
Ensure that @code{/var/tmp} has its sticky bit set. This requires system
administrator privileges.
@end enumerate

The actual default prefix used is controlled by the dynamic variable
@code{*temp-file-template*}, and can be overridden for increased
security.See @code{temp-file-iterate}.
@end deffn

@deffn Procedure temp-file-iterate @var{maker} [@var{template}]
@deffnx Variable *temp-file-template*

This procedure can be used to perform certain atomic transactions on the
file system involving filenames. Some examples:

@itemize
@item
Linking a file to a fresh backup temp name.
@item
Creating and opening an unused, secure temp file.
@item
Creating an unused temporary directory.
@end itemize

This procedure uses @var{template} to generate a series of trial file
names. Template is a format control string, and defaults to

@example
"$TMPDIR/@var{pid}.~a"
@end example

if @code{$TMPDIR} is set and

@example
"/var/tmp/@var{pid}.~a"
@end example

otherwise where @var{pid} is the current process' process ID. Filenames
are generated by calling @code{format} to instantiate the template's
@code{~a} field with a varying string.

@code{Maker} is a procedure which is serially called on each filename
generated. It must return at least one value; it may return multiple
values. If the first return value is @code{#f} or if @code{maker} raises
the @code{errno/exist} errno exception, @code{temp-file-iterate} will
loop, generating a new filename and calling @code{maker} again. If the
first return value is true, the loop is terminated, returning whatever
value(s) @code{maker} returned.

After a number of unsuccessful trials, @code{temp-file-iterate} may give
up and signal an error.

Thus, if we ignore its optional prefix argument, @code{create-temp-file}
could be defined as:

@example
(define (create-temp-file)
  (let ((flags (bitwise-ior open/create open/exclusive)))
    (temp-file-iterate
       (lambda (f)
               (close (open-output-file f flags #o600))
               f))))
@end example

To rename a file to a temporary name:

@example
(temp-file-iterate (lambda (backup)
                   (create-hard-link old-file backup)
                   backup)
                   ".#temp.~a") ; Keep link in cwd.
(delete-file old-file)
@end example

Recall that scsh reports syscall failure by raising an error exception,
not by returning an error code. This is critical to to this
example---the programmer can assume that if the @code{temp-file-iterate}
call returns, it returns successully. So the following
@code{delete-file} call can be reliably invoked, safe in the knowledge
that the backup link has definitely been established.

To create a unique temporary directory:

@example
(temp-file-iterate (lambda (dir) (create-directory dir) dir)
                   "/var/tmp/tempdir.~a")
@end example

Similar operations can be used to generate unique symlinks and fifos, or
to return values other than the new filename (e.g., an open file
descriptor or port).

The default template is in fact taken from the value of the dynamic
variable @code{*temp-file-template*}, which itself defaults to
@code{"$TMPDIR/@var{pid}.~a"} if @code{$TMPDIR} is set and
@code{"/usr/tmp/@var{pid}.~a"} otherwise, where @var{pid} is the scsh
process' PID. For increased security, a user may wish to change the
template to use a directory not allowing world write access (e.g., his
home directory).
@end deffn

@deffn Procedure temp-file-channel

This procedure can be used to provide an interprocess communications
channel with arbitrary-sized buffering. It returns two values, an input
port and an output port, both open on a new temp file.  The temp file
itself is deleted from the UNIX file tree before
@code{temp-file-channel} returns, so the file is essentially unnamed,
and its disk storage is reclaimed as soon as the two ports are closed.

@code{Temp-file-channel} is analogous to @code{port-pipe} with two exceptions:

@itemize
@item
If the writer process gets ahead of the reader process, it will not
hang waiting for some small pipe buffer to drain. It will simply buffer
the data on disk. This is good.

@item
If the reader process gets ahead of the writer process, it will also not
hang waiting for data from the writer process. It will simply see and
report an end of file. This is bad.
@end itemize

In order to ensure that an end-of-file returned to the reader is
legitimate, the reader and writer must serialise their I/O. The simplest
way to do this is for the reader to delay doing input until the writer
has completely finished doing output, or exited.
@end deffn

@anchor{Processes}
@section Processes

@deffn Procedure exec prog @math{arg_1} @dots{} @math{arg_n}
@deffnx Procedure exec-path prog @math{arg_1} @dots{} @math{arg_n}
@deffnx Procedure exec/env prog env @math{arg_1} @dots{} @math{arg_n}
@deffnx Procedure exec-path/env prog env @math{arg_1} @dots{} @math{arg_n}

The @code{.../env} variants take an environment specified as a
string->string alist. An environment of @code{#t} is taken to mean the
current process' environment (i.e., the value of the external char
@code{**environ}).

(Rationale: @code{#f} is a more convenient marker for the current
environment than @code{#t}, but would cause an ambiguity on Schemes that
identify @code{#f} and @code{()}.)

The path-searching variants search the directories in the list
@code{exec-pathlist} for the program. A path-search is not performed if
the program name contains a slash character---it is used directly. So a
program with a name like "@code{bin/prog}" always executes the program
@code{bin/prog} in the current working directory. See @code{$path} and
@code{exec-path-list}, below.

Note that there is no analog to the C function @code{execv()}. To get
the effect just do

@example
(apply exec prog arglist)
@end example

All of these procedures flush buffered output and close unrevealed ports
before executing the new binary. To avoid flushing buffered output, see
@code{%exec} below.

Note that the C @code{exec()} procedure allows the zeroth element of the
argument vector to be different from the file being executed, e.g.

@example
char *argv[] = @{"-", "-f", 0@};
exec("/bin/csh", argv, envp);
@end example

The scsh @code{exec}, @code{exec-path}, @code{exec/env}, and
@code{exec-path/env} procedures do not give this functionality---element
0 of the arg vector is always identical to the @code{prog} argument. In
the rare case the user wishes to differentiate these two items, he can
use the low-level @code{%exec} and @code{exec-path-search} procedures.
These procedures never return under any circumstances. As with any other
system call, if there is an error, they raise an exception.
@end deffn

@deffn Procedure %exec prog arglist env
@deffnx Procedure exec-path-search fname pathlist

The @code{%exec} procedure is the low-level interface to the system
call.  The @var{arglist} parameter is a list of arguments; @var{env} is
either a string->string alist or @code{#t}. The new program's
@code{argv[0]} will be taken from @code{(car @var{arglist})}, not from
@var{prog}. An environment of @code{#t} means the current process'
environment.  @code{%exec} does not flush buffered output (see
@code{flush-all-ports}).

All exec procedures, including @code{%exec}, coerce the @var{prog} and
@var{arg} values to strings using the usual conversion rules: numbers
are converted to decimal numerals, and symbols converted to their
print-names.  @code{Exec-path-search} searches the directories of
@var{pathlist} looking for an occurrence of file @var{fname}. If no
executable file is found, it returns @code{#f}. If @var{fname} contains
a slash character, the path search is short-circuited, but the procedure
still checks to ensure that the file exists and is executable---if not,
it still returns @code{#f}. Users of this procedure should be aware that
it invites a potential race condition: between checking the file with
@code{exec-path-search} and executing it with @code{%exec}, the file's
status might change. The only atomic way to do the search is to loop
over the candidate filenames, @code{exec}'ing each one and looping when the
exec operation fails.

See @code{$path} and @code{exec-path-list}, below.
@end deffn

@deffn Procedure exit [status]
@deffnx Procedure %exit [status]

These procedures terminate the current process with a given exit
status.The default exit status is 0. The low-level @code{%exit}
procedure immediately terminates the process without flushing buffered
output.
@end deffn

@deffn Procedure call-terminally thunk

@code{Call-terminally} calls its @var{thunk}. When the thunk returns,
the process exits. Although @code{call-terminally} could be implemented
as

@example
(lambda (thunk) (thunk) (exit 0))
@end example

an implementation can take advantage of the fact that this procedure
never returns. For example, the runtime can start with a fresh stack and
also start with a fresh dynamic environment, where shadowed bindings are
discarded. This can allow the old stack and dynamic environment to be
collected (assuming this data is not reachable through some live
continuation).
@end deffn

@deffn Procedure suspend
Suspend the current process with a SIGSTOP signal.
@end deffn

@deffn Procedure fork [thunk or @code{#f}] [continue-threads?]
@deffnx Procedure %fork [thunk or @code{#f}] [continue-threads?]

@code{Fork} with no arguments or @code{#f} instead of a thunk is like C
@code{fork()}. In the parent process, it returns the child's process
object (see below for more information on process objects). In the child
process, it returns @code{#f}.

@code{Fork} with an argument only returns in the parent process,
returning the child's process object. The child process calls
@var{thunk} and then exits.

@code{Fork} flushes buffered output before forking, and sets the child
process to non-interactive. @code{%fork} does not perform this
bookkeeping; it simply forks.

The optional boolean argument @var{continue-threads?} specifies whether
the currently active threads continue to run in the child or not. The
default is @code{#f}.
@end deffn

@deffn Procedure fork/pipe [thunk] [continue-threads?]
@deffnx Procedure %fork/pipe [thunk] [continue-threads?]

Like @code{fork} and @code{%fork}, but the parent and child communicate
via a pipe connecting the parent's stdin to the child's stdout. These
procedures side effect the parent by changing his stdin.  In effect,
@code{fork/pipe} splices a process into the data stream immediately
upstream of the current process. This is the basic function for creating
pipelines. Long pipelines are built by performing a sequence of
@code{fork/pipe} calls. For example, to create a background two-process
pipe @code{a | b}, we write:

@example
(fork (lambda () (fork/pipe a) (b)))
@end example

which returns the process object for @code{b}'s process.

To create a background three-process pipe @code{a | b | c}, we write:

@example
(fork (lambda () (fork/pipe a)
                 (fork/pipe b)
                 (c)))
@end example

which returns the process object for @code{c}'s process.

Note that these procedures affect file descriptors, not ports. That is,
the pipe is allocated connecting the child's file descriptor 1 to the
parent's file descriptor 0. Any previous Scheme port built over these
affected file descriptors is shifted to a new, unused file descriptor
with @code{dup} before allocating the I/O pipe. This means, for example,
that the ports bound to @code{(current-input-port)} and
@code{(current-output-port)} in either process are not affected---they
still refer to the same I/O sources and sinks as before. Remember the
simple scsh rule: Scheme ports are bound to I/O sources and sinks, not
particular file descriptors.

If the child process wishes to rebind the current output port to the
pipe on file descriptor 1, it can do this using
@code{with-current-output-port} or a related form. Similarly, if the
parent wishes to change the current input port to the pipe on file
descriptor 0, it can do this using @code{set-current-input-port!} or a
related form. Here is an example showing how to set up the I/O ports on
both sides of the pipe:

@example
(fork/pipe
  (lambda () (with-current-output-port
               (fdes->outport 1)
                 (display "Hello, world.\n"))))

(set-current-input-port! (fdes->inport 0))
(read-line) ; Read the string output by the child.
@end example

None of this is necessary when the I/O is performed by an @code{exec}'d
program in the child or parent process, only when the pipe will be
referenced by Scheme code through one of the default current I/O ports.
@end deffn

@deffn Procedure fork/pipe+ conns [thunk] [continue-threads?]
@deffnx Procedure %fork/pipe+ conns [thunk] [continue-threads?]

Like @code{fork/pipe}, but the pipe connections between the child and parent are specified by the connection list @var{conns}. See the

@example
(|+ @var{conns} @var{@math{pf_1}} @dots{} @var{@math{pf_n}})
@end example

process form for a description of connection lists.
@end deffn

@anchor{Process objects and process reaping}
@subsection Process objects and process reaping

Scsh uses process objects to represent UNIX processes. They are created
by the @code{fork} procedure, and have the following exposed structure:

@example
(define-record @var{proc} @var{pid})
@end example

The only exposed slot in a @var{proc} record is the process' pid, the
integer id assigned by UNIX to the process. The only exported primitive
procedures for manipulating process objects are @code{proc?}  and
@code{proc:pid}. Process objects are created with the @code{fork}
procedure.

@deffn Procedure pid->proc pid [probe?]

This procedure maps integer UNIX process IDs to scsh process objects. It
is intended for use in interactive and debugging code, and is deprecated
for use in production code. If there is no process object in the system
indexed by the given @var{pid}, @code{pid->proc}'s action is determined
by the @var{probe?} parameter (default @code{#f}). The following table
lists the possible values of @var{probe?} and the resulting action:

@multitable @columnfractions .50 .50
@headitem Value of @var{probe?} @tab Returns

@item @code{#f}
@tab Signal error condition.

@item 'create
@tab Create new proc object.

@item True value
@tab @code{#f}

@end multitable

Sometime after a child process terminates, scsh will perform a
@code{wait} system call on the child in background, caching the process'
exit status in the child's @var{proc} object. This is called "reaping"
the process. Once the child has been waited, the UNIX kernel can free
the storage allocated for the dead process' exit information, so process
reaping prevents the process table from becoming cluttered with
un-@code{wait}ed dead child processes (a.k.a. ``zombies''). This can be
especially severe if the scsh process never waits on child processes at
all; if the process table overflows with forgotten zombies, the OS may
be unable to fork further processes.

Reaping a child process moves its exit status information from the
kernel into the scsh process, where it is cached inside the child's
process object. If the scsh user drops all pointers to the process
object, it will simply be garbage collected. On the other hand, if the
scsh program retains a pointer to the process object, it can use scsh's
@code{wait} system call to synchronise with the child and retrieve its
exit status multiple times (this is not possible with simple UNIX
integer PIDs in C---the programmer can only wait on a pid once).

Thus, process objects allow the scsh programmer to do two things not
allowed in other programming environments:

@itemize
@item
Subprocesses that are never waited on are still removed from the
process table, and their associated exit status data is eventually
automatically garbage collected.
@item
Subprocesses can be waited on multiple times.
@end itemize

However, note that once a child has exited, if the scsh programmer drops
all pointers to the child's @var{proc} object, the child's exit status
will be reaped and thrown away. This is the intended behaviour, and it
means that integer PIDs are not enough to cause a process's exit status
to be retained by the scsh runtime.  (This is because it is clearly
impossible to GC data referenced by integers.)

As a convenience for interactive use and debugging, all procedures that
take process objects will also accept integer UNIX PIDs as arguments,
coercing them to the corresponding process objects. Since integer
process IDs are not reliable ways to keep a child's exit status from
being reaped and garbage collected, programmers are encouraged to use
process objects in production code.
@end deffn

@deffn Procedure autoreap-policy [policy]

The scsh programmer can choose different policies for automatic process
reaping. The policy is determined by applying this procedure to one of
the values @code{'early}, @code{'late}, or @code{#f} (i.e., no
autoreap).

@table @code
@item early 
The child is reaped from the UNIX kernel's process table into scsh as
soon as it dies. This is done by having a signal handler for the SIGCHLD
signal reap the process.
@item late
The child is not autoreaped until it dies and the scsh program drops all
pointers to its process object. That is, the process table is cleaned
out during garbage collection.
@item #f
If autoreaping is turned off, process reaping is completely under
control of the programmer, who can force outstanding zombies to be
reaped by manually calling the @code{reap-zombies} procedure (see
below).
@end table

Note that under any of the autoreap policies, a particular process
@var{p} can be manually reaped into scsh by simply calling @code{(wait
p)}. All zombies can be manually reaped with @code{reap-zombies}.

The @code{autoreap-policy} procedure returns the policy's previous
value. Calling @code{autoreap-policy} with no arguments returns the
current policy with no change.
@end deffn

@deffn Procedure reap-zombies

This procedure reaps all outstanding exited child processes into
scsh. It returns true if there are no more child processes to wait on,
and false if there are outstanding processes still running or suspended.
@end deffn

@subsubsection Issues with process reaping
Reaping a process does not reveal its process group at the time of
death; this information is lost when the process is reaped. This means
that a dead, reaped process is not eligible as a return value for a
future @code{wait-process-group} call. This is not likely to be a
problem for most code, as programs almost never wait on exited processes
by process group. Process group waiting is usually applied to stopped
processes, which are never reaped. So it is unlikely that this will be a
problem for most programs.

Automatic process reaping is a useful programming convenience. However,
if a program is careful to @code{wait} for all children, and does not
wish automatic reaping to happen, the programmer can simply turn process
autoreaping off.

Programs that do not wish to use automatic process reaping should
beaware that some scsh routines create subprocesses but do not return
the child's pid: @code{run/port*}, and its related procedures and
special forms (@code{run/strings}, @emph{et al.}). Automatic process
reaping will clean the child processes created by these procedures out
of the kernel's process table. If a program doesn't use process reaping,
it should either avoid these forms, or use @code{wait-any} to wait for
the children to exit.

@anchor{Process waiting}
@subsection Process waiting

@deffn Procedure wait proc/pid [flags]

This procedure waits until a child process exits, and returns its exit
code. The @var{proc/pid} argument is either a process object
@ref{Process objects and process reaping} or an integer process
id. @code{Wait} returns the child's exit status code (or suspension
code, if the @var{wait/stopped-children} option is used, see
below). Status values can be queried with the procedures in
@ref{Analysing process status codes}.

The @var{flags} argument is an integer whose bits specify additional
options. It is composed by or'ing together the following flags:

@table @code
Flag Meaning
@item wait/poll
Return @code{#f} immediately if child still active.
@item wait/stopped-children
Wait for suspend as well as exit.
@end table
@end deffn

@deffn Procedure wait-any [flags]

The optional @var{flags} argument is as for @code{wait}. This procedure
waits for any child process to exit (or stop, if the
@var{wait/stopped-children} flag is used). It returns the process'
process object and status code. If there are no children left for which
to wait, the two values @code{#f} and @code{#t} are returned. If the
@var{wait/poll} flag is used, and none of the children are immediately
eligble for waiting, then the values @code{#f} and @code{#f} are returned:

@table @code
@item #f #f
Poll, none ready
@item #f #t
No children
@end table

@code{Wait-any} will not return a process that has been previously
waited by any other process-wait procedure (@code{wait},
@code{wait-any}, or @code{wait-process-group}). It will return reaped
processes that haven't yet been waited.

The use of @code{wait-any} is deprecated.
@end deffn

@deffn Procedure wait-process-group proc/pid [flags]

This procedure waits for any child whose process group is @var{proc/pid}
(either a process object or a pid). The @var{flags} argument is as for
@code{wait}.

Note that if the programmer wishes to wait for exited processes by
process group, the program should take care not to use process reaping
@ref{Process objects and process reaping}, as this loses process group
information. However, most process-group waiting is for stopped
processes (to implement job control), so this is rarely an issue, as
stopped processes are not subject to reaping.
@end deffn

@anchor{Analysing process status codes}
@subsection Analysing process status codes

When a child process dies (or is suspended), its parent can call the
@code{wait} procedure to recover the exit (or suspension) status of the
child. The exit status is a small integer that encodes information
describing how the child terminated. The bit-level format of the exit
status is not defined by @acronym{POSIX}; you must use the following
three functions to decode one. However, if a child terminates normally
with exit code 0, @acronym{POSIX} does require @code{wait} to return an
exit status that is exactly zero. So @code{(zero? status)} is a correct
way to test for non-error, normal termination, e.g.,

@example
(if (zero? (run (rcp scsh.tar.gz lambda.csd.hku.hk:)))
    (delete-file "scsh.tar.gz"))
@end example

@deffn Procedure status:exit-val status
@deffnx Procedure status:stop-sig status
@deffnx Procedure status:term-sig status

For a given status value produced by calling @code{wait}, exactly one of
these routines will return a true value.

If the child process exited normally, @code{status:exit-val} returns the
exit code for the child process (i.e., the value the child passed to
@code{exit} or returned from @code{main}). Otherwise, this procedure
returns false.

If the child process was suspended by a signal, @code{status:stop-sig}
returns the signal that suspended the child. Otherwise, this procedure
returns false.

If the child process terminated abnormally, @code{status:term-sig}
returns the signal that terminated the child. Otherwise, this procedure
returns false.
@end deffn

@anchor{Process state}
@section Process state

@deffn Procedure umask
@deffnx Procedure set-umask perms
@deffnx Procedure with-umask* perms thunk
@deffnx Syntax with-umask perms . body

The process' current umask is retrieved with @code{umask}, and set with
@code{(set-umask perms)}. Calling @code{with-umask*} changes the umask
to @var{perms} for the duration of the call to @var{thunk}. If the
program throws out of @var{thunk} by invoking a continuation, the umask
is reset to its external value. If the program throws back into
@var{thunk} by calling a stored continuation, the umask is restored to
the @var{perms} value. The special form @code{with-umask} is equivalent
in effect to the procedure @code{with-umask*}, but does not require the
programmer to explicitly wrap a @code{(* () ...)} around the body of the
code to be executed.
@end deffn

@deffn Procedure chdir [fname]
@deffnx Procedure cwd
@deffnx Procedure with-cwd* fname thunk
@deffnx Syntax with-cwd fname . body

These forms manipulate the current working directory. The cwd can be
changed with @code{chdir} (although in most cases, @code{with-cwd} is
preferrable). If @code{chdir} is called with no arguments, it changes
the cwd to the user's home directory. The @code{with-cwd*} procedure
calls @var{thunk} with the cwd temporarily set to @var{fname}; when
@var{thunk} returns, or is exited in a non-local fashion (e.g., by
raising an exception or by invoking a continuation), the cwd is returned
to its original value. The special form @code{with-cwd} is simply
syntactic sugar for @code{with-cwd*}.
@end deffn

@deffn Procedure pid
@deffnx Procedure parent-pid
@deffnx Procedure process-group
@deffnx Procedure set-process-group [proc/pid] pgrp

@code{(Pid)} and @code{(parent-pid)} retrieve the process id for the
current process and its parent.

@code{(Process-group)} returns the process group of the current
process. A process' process-group can be set with
@code{set-process-group}; the value @var{proc/pid} specifies the
affected process. It may be either a process object or an integer
process id, and defaults to the current process.
@end deffn

@deffn Procedure set-priority which who priority
@deffnx Procedure priority which who
@deffnx Procedure nice [proc/pid delta]

These procedures set and access the priority of processes. I can't
remember how @code{set-priority} and @code{priority} work, so no
documentation, and besides, they aren't implemented yet, anyway.
@end deffn

@deffn Procedure user-login-name
@deffnx Procedure user-uid
@deffnx Procedure user-gid
@deffnx Procedure user-supplementary-gids
@deffnx Procedure set-uid uid
@deffnx Procedure set-gid gid

These routines get and set the effective and real user and group
ids. The @code{set-uid} and @code{set-gid} routines correspond to the
@acronym{POSIX} @code{setuid()} and @code{setgid()} procedures.
@end deffn

@deffn Procedure user-effective-uid
@deffnx Procedure set-user-effective-uid fixnum
@deffnx Procedure with-user-effective-uid* fixnum thunk
@deffnx Syntax with-user-effective-uid fixnum . body
@deffnx Procedure user-effective-gid
@deffnx Procedure set-user-effective-gid fixnum
@deffnx Procedure with-user-effective-gid* fixnum thunk
@deffnx Syntax with-user-effective-gid fixnum . body

These forms manipulate the effective user/group IDs. Possible values for
setting this resource are either the real user/group ID or the saved
set-user/group-ID. The @code{with-@dots{}} forms perform the usual
temporary assignment during the execution of the second argument. The
effective user and group IDs are thread-local.
@end deffn

@deffn Procedure process-times

Returns four values:

@itemize
@item user CPU time in clock-ticks
@item system CPU time in clock-ticks
@item user CPU time of all descendant processes
@item system CPU time of all descendant processes
@end itemize

Note that CPU time clock resolution is not the same as the real-time
clock resolution provided by @code{time+ticks}. That's UNIX.
@end deffn

@deffn Procedure cpu-ticks/sec

Returns the resolution of the CPU timer in clock ticks per second. This
can be used to convert the times reported by @code{process-times} to
seconds.
@end deffn

@anchor{User and group database access}
@section User and group database access

These procedures are used to access the user and group databases (e.g.,
the ones traditionally stored in @code{/etc/passwd} and
@code{/etc/group}.)

@deffn Procedure user-info uid/name

Return a @code{user-info} record giving the recorded information for a
particular user:

@example
(define-record user-info
  name uid gid home-dir shell)
@end example

The @var{uid/name} argument is either an integer uid or a string
username.
@end deffn

@deffn Procedure ->uid uid/name
@deffnx Procedure ->username uid/name

These two procedures coerce integer uid's and user names to a particularform.
@end deffn

@deffn Procedure group-info gid/name

Return a @code{group-info} record giving the recorded information for a
particular group:

@example
(define-record group-info
  name gid members)
@end example

The @var{gid/name} argument is either an integer gid or a string group-name.
@end deffn

@anchor{Accessing command-line arguments}
@section Accessing command-line arguments

@deffn Variable command-line-arguments
@deffnx Procedure command-line

The list of strings @code{command-line-arguments} contains the arguments
passed to the scsh process on the command line. Calling
@code{(command-line)} returns the complete @code{argv} string list,
including the program. So if we run a scsh program

@example
/usr/shivers/bin/myls -CF src
@end example

then @code{command-line-arguments} is

@example
("-CF" "src")
@end example

and @code{(command-line)} returns

@example
("/usr/shivers/bin/myls" "-CF" "src")
@end example

@code{command-line} returns a fresh list each time it is called. In this
way, the programmer can get a fresh copy of the original argument list
if @code{command-line-arguments} has been modified or is lexically
shadowed.
@end deffn

@deffn Procedure arg arglist n [default]
@deffnx Procedure arg* arglist n [default-thunk]
@deffnx Procedure argv n [default]

These procedures are useful for accessing arguments from argument lists.
@code{Arg} returns the nth element of @var{arglist}. The index is
1-based. If @var{n} is too large, @var{default} is returned; if no
@var{default}, then an error is signalled.

@code{Arg*} is similar, except that the @var{default-thunk} is called to
generate the default value.

@code{(argv n)} is simply @code{(arg (command-line) (+ n 1))}. The +1
offset ensures that the two forms

@example
(arg command-line-arguments n)
(argv n)
@end example

return the same argument (assuming the user has not rebound or modified
@code{command-line-arguments}).

Example:

@example
(if (null? command-line-arguments)
  (& (xterm -n ,host -title ,host
            -name ,(string-append "xterm_" host)))
  (let* ((progname (file-name-nondirectory (argv 1)))
         (title (string-append host ":" progname)))
   (& (xterm -n ,title
             -title ,title
             -e ,@@command-line-arguments))))
@end example

A subtlety: when the scsh interpreter is used to execute a scsh
program,the program name reported in the head of the
@code{(command-line)} list is the scsh program, not the interpreter. For
example, if we have a shell script in file @code{fullecho}:

@example
#!/usr/local/bin/scsh -s
!#
(for-each (lambda (arg) (display arg) (display " "))
          (command-line))
@end example

and we run the program

@example
fullecho hello world
@end example

the program will print out

@example
fullecho hello world
@end example

not

@example
/usr/local/bin/scsh -s fullecho hello world
@end example

This argument line processing ensures that if a scsh program is
subsequently compiled into a standalone executable or byte-compiled to a
heap-image executable by the Scheme 48 virtual machine, its semantics
will be unchanged---the arglist processing is invariant. In effect, the

@example
/usr/local/bin/scsh -s
@end example

is not part of the program; it's a specification for the machine to
execute the program on, so it is not properly part of the program's
argument list.
@end deffn

@anchor{System parameters}
@section System parameters

@deffn Procedure system-name

Returns the name of the host on which we are executing. This may be a
local name, such as "solar," as opposed to a fully-qualified domain name
such as "solar.csie.ntu.edu.tw."
@end deffn

@deffn Procedure uname

Returns a @var{uname-record} of the following structure:

@example
(define-record uname
   os-name
   node-name
   release
   version
   machine)
@end example

Each of the fields contains a string.

Be aware that @acronym{POSIX} limits the length of all entries to 32
characters, and that the node name does not necessarily correspond to
the fully-qualified domain name.
@end deffn

@anchor{Signal system}
@section Signal system

Signal numbers are bound to the variables @code{signal/hup},
@code{signal/int}, @dots{}. For the full list, see @ref{Table 3.2} and
@ref{Table 3.3}.

@deffn Procedure signal-process proc sig
@deffnx Procedure signal-process-group prgrp sig

These two procedures send signals to a specific process, and all the
processes in a specific process group, respectively. The @var{proc}
and @var{prgrp} arguments are either processes or integer process ids.
@end deffn

@deffn Procedure itimer secs
Schedules a timer interrupt in @var{secs} seconds. @emph{Note:} As the
thread system needs the timer interrupt for its own purpose,
@var{itimer} works by spawning a thread which calls the interrupt
handler for @code{interrupt/alrm} after the specified time.
@end deffn

@deffn Procedure process-sleep secs
@deffnx Procedure process-sleep-until time

The @code{sleep} procedure causes the process to sleep for @var{secs}
seconds. The @code{sleep-until} procedure causes the process to sleep
until @var{time}. @xref{Time}.

@emph{Note:} The use of these procedures is deprecated as they suspend
all running threads, including the ones Scsh uses for administrative
purposes.  Consider using the @code{sleep} procedure from the
@code{thread} package.
@end deffn

@anchor{Interrupt handlers}
@subsection Interrupt handlers

Scsh interrupt handlers are complicated by the fact that scsh is
implemented on top of the Scheme 48 virtual machine, which has its own
interrupt system, independent of the UNIX signal system. This means
that UNIX signals are delivered in two stages: first, UNIX delivers
the signal to the Scheme 48 virtual machine, then the Scheme 48
virtual machine delivers the signal to the executing Scheme program as
a Scheme 48 interrupt. This ensures that signal delivery happens
between two VM instructions, keeping individual instructions atomic.

The Scheme 48 machine has its own set of interrupts, which includes
the asynchronous UNIX signals. (See the table below.)

@multitable @columnfractions .33 .33 .33
@headitem Interrupt @tab UNIX signal @tab OS Variant
@item @code{interrupt/alrm}@footnote{Also bound to Scheme 48 interrupt interrupt/alarm.}
@tab @code{signal/alrm}
@tab @acronym{POSIX}
@item @code{interrupt/int}@footnote{Also bound to Scheme 48 interrupt interrupt/keyboard.}
@tab @code{signal/int} 
@tab @acronym{POSIX}
@item @code{interrupt/memory-shortage }
@tab @emph{N/A}
@item @code{interrupt/chld}
@tab @code{signal/chld} 
@tab @acronym{POSIX}
@item @code{interrupt/cont }
@tab @code{signal/cont }
@tab @acronym{POSIX}
@item @code{interrupt/hup }
@tab @code{signal/hup }
@tab @acronym{POSIX}
@item @code{interrupt/quit }
@tab @code{signal/quit }
@tab @acronym{POSIX}
@item @code{interrupt/term }
@tab @code{signal/term }
@tab @acronym{POSIX}
@item @code{interrupt/tstp }
@tab @code{signal/tstp }
@tab @acronym{POSIX}
@item @code{interrupt/usr1 }
@tab @code{signal/usr1 }
@tab @acronym{POSIX}
@item @code{interrupt/usr2 }
@tab @code{signal/usr2 }
@tab @acronym{POSIX}
@item @code{interrupt/info }
@tab @code{signal/info }
@tab BSD only
@item @code{interrupt/io }
@tab @code{signal/io }
@tab BSD + SVR4
@item @code{interrupt/poll }
@tab @code{signal/poll }
@tab SVR4 only
@item @code{interrupt/prof }
@tab @code{signal/prof }
@tab BSD + SVR4
@item @code{interrupt/pwr }
@tab @code{signal/pwr }
@tab SVR4 only
@item @code{interrupt/urg }
@tab @code{signal/urg }
@tab BSD + SVR4
@item @code{interrupt/vtalrm }
@tab @code{signal/vtalrm }
@tab BSD + SVR4
@item @code{interrupt/winch }
@tab @code{signal/winch }
@tab BSD + SVR4
@item @code{interrupt/xcpu }
@tab @code{signal/xcpu }
@tab BSD + SVR4
@item @code{interrupt/xfsz }
@tab @code{signal/xfsz }
@tab BSD + SVR4
@end multitable

@anchor{Table 3.2}
@b{Table 3.2}: Scheme 48 virtual-machine interrupts and related
UNIX signals. Only the @acronym{POSIX} signals are guaranteed to be
defined; however, your implementation and OS may define other signals
and interrupts not listed here.

@multitable @columnfractions .33 .33 .33
@headitem UNIX signal @tab Type @tab OS Variant
@item @code{signal/stop }
@tab Uncatchable 
@tab @acronym{POSIX}
@item @code{signal/kill }
@tab Uncatchable 
@tab @acronym{POSIX}
@item @code{signal/abrt }
@tab Synchronous 
@tab @acronym{POSIX}
@item @code{signal/fpe }
@tab Synchronous 
@tab @acronym{POSIX}
@item @code{signal/ill }
@tab Synchronous 
@tab @acronym{POSIX}
@item @code{signal/pipe }
@tab Synchronous 
@tab @acronym{POSIX}
@item @code{signal/segv }
@tab Synchronous 
@tab @acronym{POSIX}
@item @code{signal/ttin }
@tab Synchronous 
@tab @acronym{POSIX}
@item @code{signal/ttou }
@tab Synchronous 
@tab @acronym{POSIX}
@item @code{signal/bus }
@tab Synchronous 
@tab BSD + SVR4
@item @code{signal/emt }
@tab Synchronous 
@tab BSD + SVR4
@item @code{signal/iot }
@tab Synchronous 
@tab BSD + SVR4
@item @code{signal/sys }
@tab Synchronous 
@tab BSD + SVR4
@item @code{signal/trap }
@tab Synchronous 
@tab BSD + SVR4
@end multitable 

@anchor{Table 3.3}
@b{Table 3.3}: Uncatchable and synchronous UNIX signals. While
these signals may be sent with @code{signal-process} or
@code{signal-process-group}, there are no corresponding scsh interrupt
handlers. Only the @acronym{POSIX} signals are guaranteed to be
defined; however, your implementation and OS may define other signals
not listed here.

@deffn Procedure signal->interrupt integer
The programmer maps from UNIX signals to Scheme 48 interrupts with the
@code{signal->interrupt} procedure. If the signal does not have a
defined Scheme 48 interrupt, an error is signaled.
@end deffn

@deffn Procedure interrupt-set @math{integer_1} @dots{} @math{integer_n}
This procedure builds interrupt sets from its interrupt arguments. A
set is represented as an integer using a two's-complement
representation of the bit set.
@end deffn

@deffn Procedure enabled-interrupts
@deffnx Procedure set-enabled-interrupts interrupt-set

Get and set the value of the enabled-interrupt set. Only interrupts in
this set have their handlers called when delivered. When a disabled
interrupt is delivered to the Scheme 48 machine, it is held pending
until it becomes enabled, at which time its handler is invoked.

Interrupt sets are represented as integer bit sets (constructed with
the @code{interrupt-set} function). The @code{set-enabled-interrupts}
procedure returns the previous value of the enabled-interrupt set.
@end deffn

@deffn Syntax with-enabled-interrupts interrupt-set . body
@deffnx Procedure with-enabled-interrupts* interrupt-set thunk

Run code with a given set of interrupts enabled. Note that
``enabling'' an interrupt means enabling delivery from the Scheme 48
VM to the Scsh program. Using the Scheme 48 interrupt system is fairly
lightweight, and does not involve actually making a system call. Note
that enabling an interrupt means that the assigned interrupt handler
is allowed to run when the interrupt is delivered. Interrupts not
enabled are held pending when delivered. Interrupt sets are
represented as integer bit sets (constructed with the
@code{interrupt-set} procedure).
@end deffn

@deffn Procedure set-interrupt-handler interrupt handler

Assigns a handler for a given interrupt, and returns the interrupt's
old handler. The handler argument is @code{#f} (ignore), @code{#t}
(default), or a procedure taking an integer argument; the return value
follows the same conventions. Note that the interrupt argument is an
interrupt value, not a signal value. An interrupt is delivered to the
Scheme 48 machine by (1) blocking all interrupts, and (2) applying the
handler procedure to the set of interrupts that were enabled prior to
the interrupt delivery. If the procedure returns normally (i.e., it
doesn't throw to a continuation), the set of enabled interrupts will
be returned to its previous value. (To restore the enabled-interrupt
set before throwing out of an interrupt handler, see
@code{set-enabled-interrupts}.)

@emph{Note:} If you set a handler for the interrupt/chld interrupt,
you maybreak scsh's autoreaping process machinery. @xref{Process
objects and process reaping}.

@emph{Note:} We recommend you avoid using interrupt handlers unless
you absolutely have to. There is a better interface to handling
signals; @xref{The event interface to interrupts}.
@end deffn

@deffn Procedure interrupt-handler interrupt

Return the handler for a given interrupt. Note that the argument is an
interrupt value, not a signal value. A handler is either @code{#f}
(ignore), @code{#t} (default), or a procedure taking an integer
argument.
@end deffn

Note that Scsh does not support interrupt handlers for ``synchronous''
UNIX signals, such as @code{signal/ill} or @code{signal/pipe}. (For
more information about these signals, see @ref{Table 3.3}.)
Synchronous occurrences of these signals are better handled by raising
a Scheme exception.  There are, however, some rare situations where it
is necessary to ignore the occurrence of a synchronous signal. For
this case, the following procedures exist:

@deffn Procedure ignore-signal integer
@deffnx Procedure handle-signal-default integer

The procedure @code{ignore-signal} tells the process to ignore the
given signal. The procedure @code{handle-signal-default} resets the
signal handler to the default handler.

These procedures manipulate the raw signal handler of the Scsh process
and therefore undermine the signal handling facility of the VM. They
are intended to be used for ignoring synchronous signals if system
calls cannot succeed otherwise. Do not use these procedures for
asynchronous signals!
@end deffn

@anchor{Time}
@section Time

Scsh's time system is fairly sophisticated, particularly with respect to
its careful treatment of time zones. However, casual users shouldn't be
intimidated; all of the complexity is optional, and defaulting all the
optional arguments reduces the system to a simple interface.

@anchor{Time Terminology}
@subsection Time Terminology

``@acronym{UTC}'' and ``@acronym{UCT}'' stand for ``universal
coordinated time'', which is the official name for what is colloquially
referred to as ``Greenwich Mean Time''.

@acronym{POSIX} allows a single time zone to specify two different
offsets from @acronym{UTC}: one standard one, and one for ``summer
time''. Summer time is frequently some sort of daylight savings time.

The Scsh time package consistently uses this terminology: we never say
``@acronym{GMT}'' or ``@acronym{dst}''; we always say ``@acronym{utc}''
and ``summer time''.

@anchor{Basic data types}
@subsection Basic data types

We have two types: @emph{time} and @emph{date}.

A @emph{time} specifies an instant in the history of the universe. It is
location and time-zone independent@footnote{Physics pedants please note:
The Scsh authors live in a Newtonian universe. We disclaim
responsibility for calculations performed in non-@acronym{ANSI} standard
light-cones.}. A @emph{time} is a real value giving the number of
elapsed seconds since the UNIX ``epoch'' (Midnight, January 1,
1970 @acronym{UTC}). Time values provide arbitrary time resolution,
limited only by the number system of the underlying Scheme system.

A @emph{date} is a name for an instant in time that is specified
relative to some location/time-zone in the world, @emph{e.g.}:

@example
Friday October 31, 1994 3:47:21 pm EST.
@end example

Dates provide one-second resolution, and are expressed with the
following record type:

@example
(define-record date ; A Posix tm struct
  seconds       ; Seconds after the minute [0-59]
  minute        ; Minutes after the hour [0-59]
  hour          ; Hours since midnight [0-23]
  month-day     ; Day of the month [1-31]
  month         ; Months since January [0-11]
  year          ; Years since 1900
  tz-name       ; Time-zone name: #f or a string.
  tz-secs       ; Time-zone offset: #f or an integer.
  summer?       ; Summer (Daylight Savings) time in effect?
  week-day      ; Days since Sunday [0-6]
  year-day)     ; Days since Jan. 1 [0-365]
@end example

If the @code{tz-secs} field is given, it specifies the time-zone's
offset from @acronym{UTC} in seconds. If it is specified, the
@code{tz-name} and @code{summer?} fields are ignored when using the date
structure to determine a specific instant in time.

If the @code{tz-name} field is given, it is a time-zone string such as
``EST'' or ``HKT'' understood by the OS. Since @acronym{POSIX} time-zone
strings can specify dual standard/summer time-zones (@emph{e.g.},
``EST5EDT'' specifies U.S. Eastern Standard/Eastern Daylight Time), the
value of the @code{summer?} field is used to resolvethe ambiguous
boundary cases. For example, on the morning of the Fall daylight savings
change-over, 1:00am-2:00am happens twice. Hence the date 1:30am on this
morning can specify two different seconds; the @code{summer?} flag says
which one.

A date with @code{tz-name} = @code{tz-secs} = @code{#f} is a date that
is specified in terms ofthe system's current time zone.

There is redundancy in the @code{date} data structure. For example, the
@code{year-day} field is redundant with the @code{month-day} and
@code{month} fields. Either of these implies the values of the
@code{week-day} field. The @code{summer?} and @code{tz-name} fields are
redundant with the @code{tz-secs} field in terms of specifying an
instant in time. This redundancy is provided because consumers of dates
may want it broken out in different ways. The Scsh procedures that
produce date records fill them out completely. However, when date
records produced by the programmer are passed to Scsh procedures, the
redundancy is resolved by ignoring some of the secondary fields. This is
described for each procedure below.

@deffn Procedure make-date s min h mday mon y [tzn tzs summ? wday yday]

When making a @code{date} record, the last five elements of the record
are optional, and default to @code{#f}, @code{#f}, @code{#f}, @code{0},
and @code{0} respectively.  This is useful when creating a @code{date}
record to pass as an argument to @code{time}. Other procedures, however,
may refuse to work with these incomplete date records.
@end deffn

@anchor{Time zones}
@subsection Time zones

Several time procedures take time zones as arguments. When optional, the
time zone defaults to local time zone. Otherwise the time zone can be
one of:

@table @code

@item #f
Local time.

@item Integer
Seconds of offset from @acronym{UTC}. For example, New York City is
-18000 (-5 hours), San Francisco is -28800 (-8 hours).

@item String
A @acronym{POSIX} time zone string understood by the OS (@emph{i.e.},
the sort of time zone assigned to the @code{$TZ} environment variable).
@end table

An integer time zone gives the number of seconds you must add to
@acronym{UTC} to get time in that zone. It is not ``seconds west'' of
@acronym{UTC}---that flips the sign.

To get @acronym{UTC} time, use a time zone of either @code{0} or
@code{"UCT0"}.

@anchor{Time Procedures}
@subsection Time Procedures

@deffn Procedure time+ticks
@deffnx Procedure ticks/sec

The current time, with sub-second resolution. Sub-second resolution is
not provided by @acronym{POSIX}, but is available on many systems. The
time is returned as elapsed seconds since the UNIX epoch, plus a number
of subsecond ``ticks''. The length of a tick may vary from
implementation to implementation; it can be determined from
@code{(ticks/sec)}.

The system clock is not required to report time at the full resolution
given by @code{(ticks/sec)}. For example, on BSD, time is reported at 1
micro-second resolution, so @code{(ticks/sec)} is 1,000,000. That
doesn't mean the system clock has micro-second resolution.

If the OS does not support sub-second resolution, the @var{ticks} value
is always 0, and @code{(ticks/sec)} returns 1.

@emph{Remark:} I chose to represent system clock resolution as ticks per
second instead of seconds per tick to increase the odds that the value
could be represented as an exact integer, increasing efficiency and
making it easier for Scheme implementations that don't have
sophisticated numeric support to deal with the quantity.

You can convert seconds and ticks to seconds with the expression

@example
(+ secs (/ ticks (ticks/sec)))
@end example

Given that, why not have the fine-grained @code{time} procedure just
return a non-integer real for time? Following Common Lisp, I chose to
allow the system clock to report sub-second time in its own units to
lower the overhead of determining the time. This would be important for
a system that wanted to precisely time the duration of some event.
Timestamps could be collected with little overhead, deferring the
overhead of precisely calculating with them until after collection.

This is all a bit academic for the Scheme 48 implementation, where we
determine time with a heavyweight system call, but it's nice to plan for
the future.
@end deffn

@deffn Procedure date
@deffnx Procedure date [time tz]

Simple @code{(date)} returns the current date, in the local time zone.

With the optional arguments, @code{date} converts the time to the date as specified by the time zone @var{tz}. @var{Time} defaults to the current time; @var{tz} defaults to
local time, and is as described in the time-zone section.

If the @var{tz} argument is an integer, the date's @code{tz-name} field
is a @acronym{POSIX} time zone of the form ``@code{UTC+hh:mm:ss}''; the
trailing @code{:mm:ss} portion is deleted if it is zeroes.

@emph{Oops:} The @acronym{POSIX} facility for converting dates to times,
@code{mktime()}, has a broken design: it indicates an error by returning
-1, which is also a legal return value (for date 23:59:59 @acronym{UCT},
12/31/1969). Scsh resolves the ambiguity in a paranoid fashion: it
always reports an error if the underlying UNIX facility returns -1. We
feel your pain.
@end deffn

@deffn Procedure time
@deffnx Procedure time [date]

Simple @code{(time)} returns the current time.

With the optional @var{date} argument, @code{time} converts a date to a
time. @var{Date} defaults to the current date.

Note that the input date record is overconstrained. @code{Time} ignores
@var{date}'s @code{week-day} and @code{year-day} fields. If the date's
@code{tz-secs} field is set, the @code{tz-name} and @code{summer?}
fields are ignored.

If the @code{tz-secs} field is @code{#f}, then the time-zone is taken
from the @code{tz-name} field. A false
@code{tz-name} means the system's current time zone. When calculating with time-zones, the date's
@code{summer?} field is used to resolve am-biguities:

@table @code

@item #f
Resolve an ambiguous time in favor of non-summer time.

@item true
Resolve an ambiguous time in favor of summer time.

@end table

This is useful in boundary cases during the change-over. For example, in
the Fall, when US daylight savings time changes over at 2:00 am, 1:30 am
happens twice--it names two instants in time, an hour apart.  Outside of
these boundary cases, the @code{summer?} flag is ignored. For example,
if the standard/summer change-overs happen in the Fall and the Spring,
then the value of @code{summer?} is ignored for a January or July date.
A January date would be resolved with standard time, and a July date
with summer time, regardless of the @code{summer?} value.

The @code{summer?} flag is also ignored if the time zone doesn't have a
summer time---for example, simple @acronym{UTC}.
@end deffn

@deffn Procedure date->string date
@deffnx Procedure format-date fmt date

@code{Date->string} formats the date as a 24-character string of the
form: 

@example
Sun Sep 16 01:03:52 1973
@end example

@code{Format-date} formats the date according to the format string
@var{fmt}. The format string is copied verbatim, except that tilde
characters indicate conversion specifiers that are replaced by fields
from the date record. The table below gives the full set of conversion
specifiers supported by @code{format-date}.

@table @code
@item ~~
Converted to the @code{~} character

@item ~a 
Abbreviated weekday name

@item ~A 
Full weekday name

@item ~b 
Abbreviated month name

@item ~B 
Full month name

@item ~c 
Time and date using the time and date representation for the locale(~X ~x)

@item ~d 
Day of the month as a decimal number (01-31)

@item ~H 
Hour based on a 24-hour clock as a decimal number (00-23)

@item ~I 
Hour based on a 12-hour clock as a decimal number (01-12)

@item ~j 
Day of the year as a decimal number (001-366)

@item ~m 
Month as a decimal number (01-12)

@item ~M 
Minute as a decimal number (00-59)

@item ~p 
AM/PM designation associated with a 12-hour clock

@item ~S 
Second as a decimal number (00-61)

@item ~U 
Week number of the year; Sunday is first day of week (00-53)

@item ~w 
Weekday as a decimal number (0-6), where Sunday is 0

@item ~W 
Week number of the year; Monday is first day of week (00-53)

@item ~x 
Date using the date representation for the locale

@item ~X 
Time using the time representation for the locale

@item ~y 
Year without century (00-99)

@item ~Y 
Year with century (@emph{e.g.}, 1990)

@item ~Z 
Time zone name or abbreviation, or no characters if no time zone can be determined

@end table
@end deffn

@deffn Procedure fill-in-date! date
This procedure fills in missing, redundant slots in a date record. In
decreasing order of priority:

@itemize

@item year, month, month-day -> year-day

If the @code{year}, @code{month}, and @code{month-day} fields are all
defined (are all integers), the @code{year-day} field is set to the
corresponding value.

@item year, year-day -> month, month-day

If the @code{month} and @code{month-day} fields aren't set, but the
@code{year} and @code{year-day} fields are set, then @code{month} and
@code{month-day} are calculated.

@item year, month, month-day, year-day -> week-day

If either of the above rules is able to determine what day it is, the
@code{week-day} field is then set.

@item tz-secs -> tz-name

If @code{tz-secs} is defined, but @code{tz-name} is not, it is assigned
a time-zone name of the form ``@code{UTC+hh:mm:ss}''; the trailing
@code{:mm:ss} portion is deleted if it is zeroes.

@item tz-name, date, summer? -> tz-secs, summer?

If the date information is provided up to second resolution,
@code{tz-name} is also provided, and @code{tz-secs} is not set, then
@code{tz-secs} and @code{summer?} are set to their correct values.
Summer-time ambiguities are resolved using the original value of
@code{summer?}. If the time zone doesn't have a summertime variant, then
@code{summer?} is set to @code{#f}.

@item local time, date, summer? -> tz-name, tz-secs, summer?

If the date information is provided up to second resolution, but no time
zone information is provided (both @code{tz-name} and @code{tz-secs}
aren't set), then we proceed as in the above case, except the system's
current time zone is used.

@end itemize

These rules allow one particular ambiguity to escape: if both
@code{tz-name} and @code{tz-secs} are set, they are not brought into
agreement. It isn't clear how to do this, nor is it clear which one
should take precedence.

@emph{Oops:} @code{fill-in-date!} isn't implemented yet.
@end deffn

@anchor{Environment variables}
@section Environment variables

@deffn Procedure setenv var val
@deffnx Procedure getenv var

These procedures get and set the process environment, stored in the
external C variable @code{char **environ}. An environment variable
@var{var} is a string. If an environment variable is set to a string
@var{val}, then the process' global environment structure is altered
with an entry of the form ``@code{var=val}''. If @var{val} is @code{#f},
then any entry for @var{var} is deleted.
@end deffn

@deffn Procedure env->alist

The @code{env->alist} procedure converts the entire environment into an
alist, @emph{e.g.},

@example
(("TERM" . "vt100")
 ("SHELL" . "/usr/local/bin/scsh")
 ("PATH" . "/sbin:/usr/sbin:/bin:/usr/bin")
 ("EDITOR" . "emacs")
 ...)
@end example

@end deffn

@deffn Procedure alist->env alist

@var{Alist} must be an alist whose keys are all strings, and whose
values are all either strings or string lists. String lists are
converted to colon lists (see below). The alist is installed as the
current UNIX environment (@emph{i.e.}, converted to a null-terminated C
vector of ``@code{var=val}'' strings which is assigned to the global
@code{char **environ}).

@example
;;; Note $PATH entry is converted
;;; to /sbin:/usr/sbin:/bin:/usr/bin.
(alist->env '(("TERM" . "vt100")
              ("PATH" "/sbin" "/usr/sbin" "/bin")
              ("SHELL" . "/usr/local/bin/scsh")))
@end example

Note that @code{env->alist} and @code{alist->env} are not exact
inverses---@code{alist->env} will convert a list value into a single
colon-separated string, but @code{env->alist} will not parse
colon-separated values into lists. (See the @code{$PATH} element in the
examples given for each procedure.)
@end deffn

The following three functions help the programmer manipulate alist
tables in some generally useful ways. They are all defined using
@code{equal?} for key comparison.

@deffn Procedure alist-delete key alist
Delete any entry labelled by value @var{key}.
@end deffn

@deffn Procedure alist-update key val alist
Delete @var{key} from @var{alist}, then cons on a @code{(key . val)}
entry.
@end deffn

@deffn Procedure alist-compress alist
Compresses @var{alist} by removing shadowed entries. Example:

@example
;;; Shadowed (1 . c) entry removed.
(alist-compress '( (1 . a) (2 . b) (1 . c) (3 . d)))
==>  ((1 . a) (2 . b) (3 . d))
@end example
@end deffn

@deffn Procedure with-env* env-alist-delta thunk
@deffnx Procedure with-total-env* env-alist thunk

These procedures call @var{thunk} in the context of an altered
environment. They return whatever values @var{thunk} returns. Non-local
returns restore the environment to its outer value; throwing back into
the thunk by invoking a stored continuation restores the environment
back to its inner value.

The @var{env-alist-delta} argument specifies a modification to the
current environment---@var{thunk}'s environment is the original
environment overridden with the bindings specified by the alist delta.

The @var{env-alist} argument specifies a complete environment that is
installed for @var{thunk}.
@end deffn

@deffn Syntax with-env env-alist-delta . body
@deffnx Syntax with-total-env env-alist . body

These special forms provide syntactic sugar for @code{with-env*} and
@code{with-total-env*}. The environment alists are not evaluated
positions, but are implicitly backquoted. In this way, they tend to
resemble binding lists for @code{let} and @code{let*} forms.

Example: These four pieces of code all run the mailer with special
@code{$TERM} and @code{$EDITOR} values.

@example
(with-env (("TERM" . "xterm") ("EDITOR" . ,my-editor))
  (run (mail shivers@@lcs.mit.edu)))
@end example

@example
(with-env* `(("TERM" . "xterm") ("EDITOR" . ,my-editor))
  (lambda () (run (mail shivers@@csd.hku.hk))))
@end example

@example
(run (begin (setenv "TERM" "xterm")     ; Env mutation happens
            (setenv "EDITOR" my-editor) ; in the subshell.
            (exec-epf (mail shivers@@research.att.com))))
@end example

@example
;; In this example, we compute an alternate environment ENV2
;; as an alist, and install it with an explicit call to the
;; EXEC-PATH/ENV procedure.
(let* ((env (env->alist))                      ; Get the current environment
       (env1 (alist-update env "TERM" "xterm")); and compute the new env
       (env2 (alist-update env1 "EDITOR" my-editor)))
  (run (begin (exec-path/env "mail" env2 "shivers@@cs.cmu.edu"))))
@end example

@end deffn

@anchor{Path lists and colon lists}
@subsection Path lists and colon lists

When environment variables such as @code{$PATH} need to encode a list of
strings (such as a list of directories to be searched), the common UNIX
convention is to separate the list elements with colon
delimiters@footnote{@dots{}and hope the individual list elements don't
contain colons themselves.}. To convert between the colon-separated
string encoding and the list-of-strings representation, see the
@code{infix-splitter} function. (@xref{Parsing fields}.) and the string
library's @code{string-join} function. For example,

@example
(define split (infix-splitter (rx ":")))
(split "/sbin:/bin::/usr/bin")
==> '("/sbin" "/bin" "" "/usr/bin")

(string-join ":" '("/sbin" "/bin" "" "/usr/bin"))
==> "/sbin:/bin::/usr/bin"
@end example

The following two functions are useful for manipulating these ordered
lists, once they have been parsed from their colon-separated form.

@deffn Procedure add-before elt before list
@deffnx Procedure add-after elt after list

These functions are for modifying search-path lists, where element order
is significant.

@code{Add-before} adds @var{elt} to the list immediately before the
first occurrence of @var{before} in the list. If @var{before} is not in
the list, @var{elt} is added to the end of the list.

@code{Add-after} is similar: @var{elt} is added after the last
occurrence of @var{after}. If @var{after} is not found, @var{elt} is
added to the beginning of the list.

Neither function destructively alters the original path-list. The result
may share structure with the original list. Both functions use
@code{equal?} for comparing elements.
@end deffn

@anchor{$USER, $HOME, and $PATH}
@subsection $USER, $HOME, and $PATH

Like @code{sh} and unlike @code{csh}, Scsh has no interactive
dependencies on environment variables. It does, however, initialise
certain internal values at startup time from the initial process
environment, in particular @code{$HOME} and @code{$PATH}. Scsh never
uses @code{$USER} at all. It computes @code{(user-login-name)} from the
system call @code{(user-uid)}.

@deffn Variable home-directory string
@deffnx Variable exec-path-list string list thread-fluid

Scsh accesses @code{$HOME} at start-up time, and stores the value in the
global variable @code{home-directory}. It uses this value for @code{~}
lookups and for returning to home on @code{(chdir)}.

Scsh accesses @code{$PATH} at start-up time, colon-splits the path list,
and stores the value in the thread fluid @code{exec-path-list}. This
list is used for @code{exec-path} and @code{exec-path/env} searches.

To access, rebind or side-effect thread-fluid cells, you must open the
@code{thread-fluids} package.
@end deffn

@anchor{Terminal device control}
@section Terminal device control

Scsh provides a complete set of routines for manipulating terminal
devices---putting them in ``raw'' mode, changing and querying their
special characters, modifying their I/O speeds, and so forth. The Scsh
interface is designed both for generality and portability across
different UNIX platforms, so you don't have to rewrite your program each
time you move to a new system. We've also made an effort to use
reasonable, Scheme-like names for the multitudinous named constants
involved, so when you are reading code, you'll have less likelihood of
getting lost in a bewildering maze of obfuscatory constants named
@code{ICRNL}, @code{INPCK}, @code{IUCLC}, and @code{ONOCR}.

This section can only lay out the basic functionality of the terminal
device interface. For further details, see the @code{termios(3)} man
page on your system, or consult one of the standard UNIX texts.

@anchor{Portability across OS variants}
@subsection Portability across OS variants

Terminal-control software is inescapably complex, ugly, and low-level.
UNIX variants each provide their own way of controlling terminal
devices, making it difficult to provide interfaces that are portable
across different UNIX systems. Scsh's terminal support is based
primarily upon the @acronym{POSIX} @code{termios} interface. Programs
that can be written using only the @acronym{POSIX} interface are likely
to be widely portable.

The bulk of the documentation that follows consists of several pages
worth of tables defining different named constants that enable and
disable different features of the terminal driver. Some of these flags
are @acronym{POSIX}; others are taken from the two common branches of
UNIX development, SVR4 and 4.3+ Berkeley.  Scsh guarantees that the
non-@acronym{POSIX} constants will be bound identifiers.

@itemize
@item If your OS supports a particular non-@acronym{POSIX} flag, its
named constant will be bound to the flag's value.

@item If your OS doesn't support the flag, its named constant will be
present, but bound to @code{#f}.
@end itemize

This means that if you want to use SVR4 or Berkeley features in a
program, your program can portably test the values of the flags before
using them---the flags can reliably be referenced without producing
OS-dependent ``unbound variable'' errors.

Finally, note that although @acronym{POSIX}, SVR4, and Berkeley cover
the lion's share of the terminal-driver functionality, each operating
system inevitably has nonstandard extensions. While a particular Scsh
implementation may provide these extensions, they are not portable, and
so are not documented here.

@anchor{Miscellaneous procedures}
@subsection Miscellaneous procedures

@deffn Procedure tty? fd/port
Return true if the argument is a tty.
@end deffn

@deffn Procedure tty-file-name fd/port
The argument @var{fd/port} must be a file descriptor or port open on a
tty. Return the filename of the tty.
@end deffn

@anchor{The tty-info record type}
@subsection The tty-info record type

The primary data structure that describes a terminal's mode is a
@code{tty-info} record, defined as follows:

@example
(define-record tty-info
  control-chars         ; String: Magic input chars
  input-flags           ; Int: Input processing
  output-flags          ; Int: Output processing
  control-flags         ; Int: Serial-line control
  local-flags           ; Int: Line-editting UI
  input-speed           ; Int: Code for input speed
  output-speed          ; Int: Code for output speed
  min                   ; Int: Raw-mode input policy
  time)                 ; Int: Raw-mode input policy
@end example

@subsubsection The control-characters string

The @code{control-chars} field is a character string; its characters may
be indexed by integer values taken from @ref{Table 4}.

As discussed above, only the @acronym{POSIX} entries in table 4 are
guaranteed to be legal, integer indices. A program can reliably test the
OS to see if the non-@acronym{POSIX} characters are supported by
checking the index constants. If the control-character function is
supported by the terminal driver, then the corresponding index will be
bound to an integer; if it is not supported, the index will be bound to
@code{#f}.

To disable a given control-character function, set its corresponding
entry in the @code{tty-info:control-chars} string to the special
character @code{disable-tty-char} (and then use the @code{(set-tty-info
@var{fd/port} @var{info})} procedure to update the terminal's state).

@subsubsection The flag fields

The @code{tty-info} record's @code{input-flags}, @code{output-flags},
@code{control-flags}, and @code{local-flags} fields are all bit sets
represented as two's-complement integers. Their values are composed by
or'ing together values taken from the named constants listed in
@pxref{Table 4}, @pxref{Table 5}, @pxref{Table 6}, @pxref{Table 7}, and
@pxref{Table 8}.

As discussed above, only the @acronym{POSIX} entries listed in these
tables are guaranteed to be legal, integer flag values. A program can
reliably test the OS to see if the non-@acronym{POSIX} flags are
supported by checking the named constants. If the feature is supported
by the terminal driver, then the corresponding flag will be bound to an
integer; if it is not supported, the flag will be bound to @code{#f}.

@subsubsection The speed fields

The @code{input-speed} and @code{output-speed} fields determine the I/O
rate of the terminal's line. The value of these fields is an integer
giving the speed in bits-per-second. The following speeds are supported
by @acronym{POSIX}:

@example
0   134  600  4800
50  150 1200  9600
75  200 1800 19200
110 300 2400 38400
@end example

Your OS may accept others; it may also allow the special symbols
@code{'exta} and @code{'extb}.

@subsubsection The min and time fields

The integer @code{min} and @code{time} fields determine input blocking
behaviour during non-canonical (raw) input; otherwise, they are ignored.
See the @code{termios(3)} man page for further details.

Be warned that @acronym{POSIX} allows the base system call's
representation of the @code{tty-info} record to share storage for the
@code{min} field and the @code{ttychar/eof} element of the
control-characters string, and for the @code{time} field and the
@code{ttychar/eolelement} of the control-characters string. Many
implementations in fact do this.

To stay out of trouble, set the @code{min} and @code{time} fields only
if you are putting the terminal into raw mode; set the @acronym{EOF} and
@acronym{EOL} control-characters only if you are putting the terminal
into canonical mode. It's ugly, but it's UNIX.

@anchor{Using tty-info records}
@subsection Using tty-info records

@deffn Procedure make-tty-info if of cf lf ispeed ospeed min time
@deffnx Procedure copy-tty-info tty-info-record

These procedures make it possible to create new @code{tty-info} records.
The typical method for creating a new record is to copy one retrieved by
a call to the @code{tty-info} procedure, then modify the copy as
desired. Note that the @code{make-tty-info} procedure does not take a
parameter to define the new record's control characters@footnote{Why?
Because the length of the string varies from UNIX to UNIX. For example,
the word-erase control character (typically control-w) is provided by
most UNIXes, but is not part of the @acronym{POSIX} spec.}. Instead, it
simply returns a @code{tty-info} record whose control-character string
has all elements initialised to @acronym{ASCII} nul. You may then
install the special characters by assigning to the string. Similarly,
the control-character string in the record produced by
@code{copy-tty-info} does not share structure with the string in the
record being copied, so you may mutate it freely.
@end deffn

@deffn Procedure tty-info [fd/port/fname]
The @var{fd/port/fname} parameter is an integer file descriptor or
Scheme I/O port opened on a terminal device, or a file-name for a
terminal device; it defaults to the current input port. This procedure
returns a @code{tty-info} record describing the terminal's current mode.
@end deffn

@deffn Procedure set-tty-info/now fd/port/fname info
@deffnx Procedure set-tty-info/drain fd/port/fname info
@deffnx Procedure set-tty-info/flush fd/port/fname info

The @var{fd/port/fname} parameter is an integer file descriptor or
Scheme I/O port opened on a terminal device, or a file-name for a
terminal device.  The procedure chosen determines when and how the
terminal's mode is altered, as shown in the table below:

@table @code
@item set-tty-info/now
Make change immediately.

@item set-tty-info/drain 
Drain output, then change.

@item set-tty-info/flush 
Drain output, flush input, then change.
@end table

@emph{Oops:} If I had defined these with the parameters in the reverse
order, I could have made @var{fd/port/fname} optional. Too late now.
@end deffn

@anchor{Other terminal-device procedures}
@subsection Other terminal-device procedures

@deffn Procedure send-tty-break [fd/port/fname duration]

The @var{fd/port/fname} parameter is an integer file descriptor or
Scheme I/O port opened on a terminal device, or a filename for a
terminal device; it defaults to the current output port. Sends a break
signal to the designated terminal. A break signal is a sequence of
continuous zeroes on the terminal's transmission line.

The duration argument determines the length of the break signal. A zero
value (the default) causes a break of between 0.25 and 0.5 seconds to be
sent; other values determine a period in a manner that will depend upon
local community standards.
@end deffn

@deffn Procedure drain-tty [fd/port/fname]

The @var{fd/port/fname} parameter is an integer file descriptor or
Scheme I/O port opened on a terminal device, or a filename for a
terminal device; it defaults to the current output port.

This procedure waits until all the output written to the terminal device
has been transmitted to the device. If @var{fd/port/fname} is an output
port with buffered I/O enabled, then the port's buffered characters are
flushed before waiting for the device to drain.
@end deffn

@deffn Procedure flush-tty/input [fd/port/fname]
@deffnx Procedure flush-tty/output [fd/port/fname]
@deffnx Procedure flush-tty/both [fd/port/fname]

The @var{fd/port/fname} parameter is an integer file descriptor or
Scheme I/O port opened on a terminal device, or a filename for a
terminal device; it defaults to the current input port
(@code{flush-tty/input} and @code{flush-tty/both}), or output port
(@code{flush-tty/output}).

These procedures discard the unread input chars or unwritten output
chars in the tty's kernel buffers.
@end deffn

@deffn Procedure start-tty-output [fd/port/fname]
@deffnx Procedure stop-tty-output [fd/port/fname]
@deffnx Procedure start-tty-input [fd/port/fname]
@deffnx Procedure stop-tty-input [fd/port/fname]

These procedures can be used to control a terminal's input and output
flow. The @var{fd/port/fname} parameter is an integer file descriptor or
Scheme I/O port opened on a terminal device, or a filename for a
terminal device; it defaults to the current input or output port.

The @code{stop-tty-output} and @code{start-tty-output} procedures
suspend and resume output from a terminal device. The
@code{stop-tty-input} and @code{start-tty-input} procedures transmit the
special STOP and START characters to the terminal with the intention of
stopping and starting terminal input flow.
@end deffn

@anchor{Control terminals, sessions, and terminal process groups}
@subsection Control terminals, sessions, and terminal process groups

@deffn Procedure open-control-tty tty-name [flags]

This procedure opens terminal device @var{tty-name} as the process'
control terminal (see the @code{termios} man page for more information
on control terminals). The @var{tty-name} argument is a filename such as
@code{/dev/ttya}. The @var{flags} argument is a value suitable as the
second argument to the @code{open-file} call; it defaults to
@code{open/read+write}, causing the terminal to be opened for both input
and output.

The port returned is an input port if the flags permit it, otherwise an
output port. @acronym{R5RS}/Scheme 48/scsh do not have input/output ports, so it's
one or the other. However, you can get both read and write ports open on
a terminal by opening it read/write, taking the result input port, and
duping it to an output port with @code{dup->outport}.

This procedure guarantees to make the opened terminal the process'
control terminal only if the process does not have an assigned control
terminal at the time of the call. If the scsh process already has a
control terminal, the results are undefined.

To arrange for the process to have no control terminal prior to calling
this procedure, use the @code{become-session-leader} procedure.
@end deffn

@deffn Procedure become-session-leader

This is the C @code{setsid()} call. @acronym{POSIX} job-control has a
three-level hierarchy: session -> process-group -> process. Every
session has an associated control terminal. This procedure places the
current process into a brand new session, and disassociates the process
from any previous control terminal. You may subsequently use
@code{open-control-tty} to open a new control terminal.

It is an error to call this procedure if the current process is already
a process-group leader. One way to guarantee this is not the case is
only to call this procedure after forking.
@end deffn

@deffn Procedure tty-process-group fd/port/fname
@deffnx Procedure set-tty-process-group fd/port/fname pgrp

This pair of procedures gets and sets the process group of a given
terminal.
@end deffn

@deffn Procedure control-tty-file-name

Return the filename of the process' control tty. On every version of
UNIX of which we are aware, this is just the string ``@code{/dev/tty}''.
However, this procedure uses the official @acronym{POSIX} interface, so
it is more portable than simply using a constant string.
@end deffn

@anchor{Pseudo-terminals}
@subsection Pseudo-terminals

Scsh implements an interface to Berkeley-style pseudo-terminals.

@deffn Procedure fork-pty-session thunk

This procedure gives a convenient high-level interface to
pseudo-terminals. It first allocates a pty/tty pair of devices, and then
forks a child to execute procedure @var{thunk}. In the child process

@itemize
@item Stdio and the current I/O ports are bound to the terminal device.

@item The child is placed in its own, new session. (See
@code{become-session-leader}.)

@item The terminal device becomes the new session's controlling
terminal. (See @code{open-control-tty}.)

@item The @code{(error-output-port)} is unbuffered.
@end itemize

The @code{fork-pty-session} procedure returns four values: the child's
process object, two ports open on the controlling pty device, and the
name of the child's corresponding terminal device.
@end deffn

@deffn Procedure open-pty

This procedure finds a free pty/tty pair, and opens the pty device with
read/write access. It returns a port on the pty, and the name of the
corresponding terminal device.  The port returned is an input
port---Scheme doesn't allow input/output ports. However, you can easily
use @code{(dup->outport pty-inport)} to produce a matching output port.
You may wish to turn off I/O buffering for this output port.
@end deffn

@deffn Procedure pty-name->tty-name pty-name
@deffnx Procedure tty-name->pty-name tty-name

These two procedures map between corresponding terminal and pty
controller names. For example,

@example
(pty-name->tty-name "/dev/ptyq3") ==> "/dev/ttyq3"
(tty-name->pty-name "/dev/ttyrc") ==> "/dev/ptyrc"
@end example

@emph{Remark:} This is rather Berkeley-specific. SVR4 ptys are rare
enough that I've no real idea if it generalises across the UNIX gap.
Experts are invited to advise. Users feel free to not worry---the
predominance of current popular UNIX systems use Berkeley ptys.
@end deffn

@deffn Procedure make-pty-generator

This procedure returns a generator of candidate pty names. Each time the
returned procedure is called, it produces a new candidate. Software that
wishes to search through the set of available ptys can use a pty
generator to iterate over them. After producing all the possible ptys, a
generator returns @code{#f} every time it is called. Example:

@example
(define pg (make-pty-generator))
(pg) =) "/dev/ptyp0"
(pg) =) "/dev/ptyp1"
@dots{}
(pg) =) "/dev/ptyqe"
(pg) =) "/dev/ptyqf" (Last one)
(pg) =) #f
(pg) =) #f
@dots{}
@end example
@end deffn

@multitable @columnfractions .33 .33 .33
@headitem Scsh @tab C @tab Typical character
@item @acronym{POSIX}

@item ttychar/delete-char
@tab ERASE 
@tab del

@item ttychar/delete-line 
@tab KILL 
@tab ^U

@item ttychar/eof 
@tab EOF 
@tab ^D

@item ttychar/eol 
@tab EOL

@item ttychar/interrupt 
@tab INTR 
@tab ^C

@item ttychar/quit 
@tab QUIT 
@tab ^\

@item ttychar/suspend 
@tab SUSP 
@tab ^Z

@item ttychar/start 
@tab START 
@tab ^Q

@item ttychar/stop 
@tab STOP 
@tab ^S


@item SVR4 and 4.3+BSD

@item ttychar/delayed-suspend 
@tab DSUSP 
@tab ^Y

@item ttychar/delete-word 
@tab WERASE 
@tab ^W

@item ttychar/discard 
@tab DISCARD 
@tab ^O

@item ttychar/eol2 
@tab EOL2

@item ttychar/literal-next 
@tab LNEXT 
@tab ^V

@item ttychar/reprint 
@tab REPRINT 
@tab ^R

@item 4.3+BSD
@item ttychar/status 
@tab STATUS 
@tab ^T

@end multitable

@anchor{Table 4}
@b{Table 4:} Indices into the @code{tty-info} record's control-chars
string, and the character traditionally found at each index. Only the
indices for the @acronym{POSIX} entries are guaranteed to be
non-@code{#f}.

@multitable @columnfractions .33 .33 .33
@headitem Scsh @tab C @tab Meaning

@item @acronym{POSIX}

@item ttyin/check-parity 
@tab INPCK 
@tab Check parity.

@item ttyin/ignore-bad-parity-chars 
@tab IGNPAR 
@tab Ignore chars with parity errors.

@item ttyin/mark-parity-errors 
@tab PARMRK 
@tab Insert chars to mark parity errors.

@item ttyin/ignore-break 
@tab IGNBRK 
@tab Ignore breaks.

@item ttyin/interrupt-on-break 
@tab BRKINT 
@tab Signal on breaks.

@item ttyin/7bits 
@tab ISTRIP 
@tab Strip char to seven bits.

@item ttyin/cr->nl 
@tab ICRNL 
@tab Map carriage-return to newline.

@item ttyin/ignore-cr 
@tab IGNCR 
@tab Ignore carriage-returns.

@item ttyin/nl->cr 
@tab INLCR 
@tab Map newline to carriage-return.

@item ttyin/input-flow-ctl 
@tab IXOFF 
@tab Enable input flow control.

@item ttyin/output-flow-ctl 
@tab IXON 
@tab Enable output flow control.

@item SVR4 and 4.3+BSD

@item ttyin/xon-any 
@tab IXANY 
@tab Any char restarts after stop.

@item ttyin/beep-on-overflow 
@tab IMAXBEL 
@tab Ring bell when queue full.

@item SVR4

@item ttyin/lowercase 
@tab IUCLC 
@tab Map upper case to lower case.
@end multitable

@anchor{Table 5}
@b{Table 5: Input-flags.} These are the named flags for the @code{tty-info}
record's @code{input-flags} field. These flags generally control the
processing of input characters.  Only the @acronym{POSIX} entries are
guaranteed to be non-@code{#f}.

@multitable @columnfractions .33 .33 .33
@headitem Scsh @tab C @tab Meaning

@item @acronym{POSIX}

@item ttyout/enable 
@tab OPOST 
@tab Enable output processing.

@item SVR4 and 4.3+BSD

@item ttyout/nl->crnl 
@tab ONLCR 
@tab Map nl to cr-nl.

@item 4.3+BSD

@item ttyout/discard-eot 
@tab ONOEOT 
@tab Discard EOT chars.

@item ttyout/expand-tabs 
@tab OXTABS7 
@tab Expand tabs.

@item SVR4

@item ttyout/cr->nl 
@tab OCRNL 
@tab Map cr to nl.

@item ttyout/nl-does-cr 
@tab ONLRET 
@tab Nl performs cr as well.

@item ttyout/no-col0-cr 
@tab ONOCR 
@tab No cr output in column 0.

@item ttyout/delay-w/fill-char 
@tab OFILL 
@tab Send fill char to delay.

@item ttyout/fill-w/del 
@tab OFDEL 
@tab Fill char is @acronym{ASCII} DEL.

@item ttyout/uppercase 
@tab OLCUC 
@tab Map lower to upper case.
@end multitable

@anchor{Table 6}
@b{Table 6: Output-flags.} These are the named flags for the @code{tty-info}
record's @code{output-flags} field. These flags generally control the
processing of output characters.  Only the @acronym{POSIX} entries are
guaranteed to be non-@code{#f}.

@multitable @columnfractions .33 .33 .33
@headitem Delay constants @tab Value @tab Comment
@item Backspace delay
@tab ttyout/bs-delay
@tab Bit-field mask

@item
@tab ttyout/bs-delay0
@tab

@item 
@tab ttyout/bs-delay1
@tab

@item Carriage-return delay
@tab ttyout/cr-delay
@tab Bit-field mask

@item
@tab ttyout/cr-delay0
@tab

@item
@tab ttyout/cr-delay1
@tab

@item
@tab ttyout/cr-delay2
@tab

@item
@tab ttyout/cr-delay3
@tab 

@item Form-feed delay
@tab ttyout/ff-delay
@tab Bit-field mask

@item
@tab ttyout/ff-delay0
@tab

@item
@tab ttyout/ff-delay1
@tab 

@item Horizontal-tab delay
@tab ttyout/tab-delay
@tab Bit-field mask

@item
@tab ttyout/tab-delay0
@tab

@item
@tab ttyout/tab-delay1
@tab

@item
@tab ttyout/tab-delay2
@tab

@item
@tab ttyout/tab-delayx
@tab Expand tabs

@item Newline delay
@tab ttyout/nl-delay
@tab Bit-field mask

@item
@tab ttyout/nl-delay0
@tab 

@item
@tab ttyout/nl-delay1
@tab 

@item Vertical tab delay
@tab ttyout/vtab-delay
@tab Bit-field mask

@item
@tab ttyout/vtab-delay0
@tab

@item
@tab ttyout/vtab-delay1
@tab 

@item All
@tab ttyout/all-delay 
@tab Total bit-field mask
@end multitable

@anchor{Table 7}
@b{Table 7: Delay constants.} These are the named flags for the
@code{tty-info} record's @code{output-flags} field. These flags control
the output delays associated with printing special characters.  They are
non-@acronym{POSIX}, and have non-@code{#f} values only on SVR4 systems.

@multitable @columnfractions .33 .33 .33
@headitem Scsh @tab C @tab Meaning

@item @acronym{POSIX}

@item ttyc/char-size
@tab CSIZE 
@tab Character size mask

@item ttyc/char-size5
@tab CS5 
@tab 5 bits

@item ttyc/char-size6 
@tab CS6 
@tab 6 bits

@item ttyc/char-size7 
@tab CS7 
@tab 7 bits

@item tttyc/char-size8 
@tab CS8 
@tab 8 bits

@item ttyc/enable-parity 
@tab PARENB 
@tab Generate and detect parity.

@item ttyc/odd-parity 
@tab PARODD 
@tab Odd parity.

@item ttyc/enable-read 
@tab CREAD 
@tab Enable reception of chars.

@item ttyc/hup-on-close 
@tab HUPCL 
@tab Hang up on last close.

@item ttyc/no-modem-sync 
@tab LOCAL 
@tab Ignore modem lines.

@item ttyc/2-stop-bits 
@tab CSTOPB 
@tab Send two stop bits.

@item 4.3+BSD

@item ttyc/ignore-flags 
@tab CIGNORE 
@tab Ignore control flags.

@item ttyc/CTS-output-flow-ctl 
@tab CCTS_OFLOW 
@tab CTS flow control of output

@item ttyc/RTS-input-flow-ctl 
@tab CRTS_IFLOW 
@tab RTS flow control of input

@item ttyc/carrier-flow-ctl 
@tab MDMBUF
@tab
@end multitable

@anchor{Table 8}
@b{Table 8: Control-flags.} These are the named flags for the
@code{tty-info} record's @code{control-flags} field. These flags
generally control the details of the terminal's serial line. Only the
@acronym{POSIX} entries are guaranteed to be non-@code{#f}.

@multitable @columnfractions .33 .33 .33
@headitem Scsh @tab C @tab Meaning

@item @acronym{POSIX}

@item ttyl/canonical 
@tab ICANON 
@tab Canonical input processing.

@item ttyl/echo 
@tab ECHO 
@tab Enable echoing.

@item ttyl/echo-delete-line 
@tab ECHOK 
@tab Echo newline after line kill.

@item ttyl/echo-nl 
@tab ECHONL 
@tab Echo newline even if echo is off.

@item ttyl/visual-delete 
@tab ECHOE 
@tab Visually erase chars.

@item ttyl/enable-signals 
@tab ISIG 
@tab Enable ^C, ^Z signalling.

@item ttyl/extended 
@tab IEXTEN 
@tab Enable extensions.

@item ttyl/no-flush-on-interrupt 
@tab NOFLSH 
@tab Don't flush after interrupt.

@item ttyl/ttou-signal 
@tab ITOSTOP 
@tab SIGTTOU on background output.

@item SVR4 and 4.3+BSD

@item ttyl/echo-ctl 
@tab ECHOCTL 
@tab Echo control chars as "^X".

@item ttyl/flush-output 
@tab FLUSHO 
@tab Output is being flushed.

@item ttyl/hardcopy-delete 
@tab ECHOPRT 
@tab Visual erase for hardcopy.

@item ttyl/reprint-unread-chars 
@tab PENDIN 
@tab Retype pending input.

@item ttyl/visual-delete-line 
@tab ECHOKE 
@tab Visually erase a line-kill.

@item 4.3+BSD

@item ttyl/alt-delete-word 
@tab ALTWERASE 
@tab Alternate word erase algorithm

@item ttyl/no-kernel-status 
@tab NOKERNINFO 
@tab No kernel status on ^T.

@item SVR4

@item ttyl/case-map 
@tab XCASE 
@tab Canonical case presentation.

@end multitable

@anchor{Table 9}
@b{Table 9: Local-flags.} These are the named flags for the
@code{tty-info} record's @code{local-flags} field. These flags generally
control the details of the line-editing user interface. Only the
@acronym{POSIX} entries are guaranteed to be non-@code{#f}.

@node Networking, Strings and characters, System calls, Top
@chapter Networking
 
The Scheme Shell provides a BSD-style sockets interface. There is not
an official standard for a network interface for scsh to adopt (this
is the subject of the forthcoming @acronym{POSIX}.8
standard). However, Berkeley sockets are a de facto standard, being
found on most UNIX workstations and PC operating systems.

It is fairly straightforward to add higher-level network protocols
such as @acronym{SMTP}, Telnet, or @acronym{HTTP} on top of the the
basic socket-level support scsh provides.  The Scheme Underground has
also released a network library with many of these protocols as a
companion to the current release of scsh. See this code for examples
showing the use of the sockets interface.

@anchor{High-level interface}
@section High-level interface

For convenience, and to avoid some of the messy details of the socket
interface, we provide a high level socket interface. These routines
attempt to make it easy to write simple clients and servers without
having to think of many of the details of initiating socket
connections. We welcome suggested improvements to this interface,
including better names, which right now are solely descriptions of the
procedure's action. This might be fine for people who already
understand sockets, but does not help the new networking programmer.

@deffn Procedure socket-connect protocol-family socket-type . args

@code{Socket-connect} is intended for creating client
applications. @var{Protocol-family} is specified as either the
@code{protocol-family/internet} or
@code{protocol-family/unix}. @var{Socket-type} is specified as either
@code{socket-type/stream} or @code{socket-type/datagram}. See
@code{socket} for amore complete description of these terms.

The variable @var{args} list is meant to specify protocol family
specific information. For Internet sockets, this consists of two
arguments: a host name and a port number. For UNIX sockets, this
consists of a pathname.

@code{Socket-connect} returns a socket which can be used for input and
output from a remote server. See @code{socket} for a description of
the @code{socket} record.
@end deffn

@deffn Procedure bind-listen-accept-loop protocol-family proc arg

@code{Bind-listen-accept-loop} is intended for creating server
applications. @var{Protocol-family} is specified as either the
@code{protocol-family/internet} or
@code{protocol-family/unix}. @var{Proc} is a procedure of two
arguments: a @code{socket} and a socket-address. @var{Arg} specifies a
port number for Internet sockets or a pathname for UNIX sockets. See
@code{socket} for a more complete description of these terms.

@var{Proc} is called with a socket and a socket address each time
there is a connection from a client application. The socket allows
communications with the client. The socket address specifies the
address of the remoteclient.

This procedure does not return, but loops indefinitely accepting
connections from client programs.
@end deffn

@deffn Procedure bind-prepare-listen-accept-loop protocol-family prepare proc arg

Same as @code{bind-listen-accept-loop} but runs the thunk
@var{prepare} after binding the address and before entering the
loop. The typical task of the @var{prepare} procedure is to change the
user ID from the superuser to some unprivileged ID once the address
has been bound.
@end deffn

@anchor{Sockets}
@section Sockets

@deffn Procedure create-socket protocol-family type [protocol]
@deffnx Procedure create-socket-pair type
@deffnx Procedure close-socket socket

A socket is one end of a network connection. Three specific properties
of sockets are specified at creation time: the protocol-family, type,
and protocol.

The @var{protocol-family} specifies the protocol family to be used with
the socket. This also determines the address family of socket addresses,
which are described in more detail below. Scsh currently supports the
UNIX internal protocols and the internet protocols using the following
constants:

@example
protocol-family/unspecified
protocol-family/UNIX
protocol-family/internet
@end example

The @var{type} specifies the style of communication. Examples that your
operating system probably provides are stream and datagram sockets.
Others may be available depending on your system. Typical values are:

@example
socket-type/stream
socket-type/datagram
socket-type/raw
@end example

The @var{protocol} specifies a particular protocol to use within a
protocol family and type. Usually only one choice exists, but it's
probably safest to set this explicitly. See the protocol database
routines for information on lookingup protocol constants.

New sockets are typically created with @code{create-socket}. However,
@code{create-socket-pair} can also be used to create a pair of connected
sockets in the @code{protocol-family/unix} protocol family. The value of
a returned socket is a @emph{socket} record, defined to have the
following structure:

@example
(define-record socket
   family       ; protocol family
   inport       ; input-port
   outport)     ; output-port
@end example

The @code{family} specifies the protocol family of the socket. The
@code{inport} and @code{outport} fields are ports that can be used for
input and output, respectively. For a stream socket, they are only
usable after a connection has been established via @code{connect-socket}
or @code{accept-connection}. For a data-gram socket, @code{outport} can
be used immediately using @code{send-message}, and @code{inport} can be
used after @code{bind} has created a local address.

@code{Close-socket} provides a convenient way to close a socket's port.
It is preferred to explicitly closing the @code{inport} and
@code{outport} because using @code{close} on sockets is not currently
portable across operating systems.
@end deffn

@deffn Procedure port->socket port protocol-family

This procedure turns @var{port} into a socket object. The port's
underlying file descriptor must be a socket with protocol family
@var{protocol-family}.  @code{Port->socket} applies @code{dup->inport}
and @code{dup->outport} to @var{port} to create the ports of the socket
object.

@code{Port->socket} comes in handy for writing servers which run as
children of @code{inetd}: after receiving a connection @code{inetd}
creates a socket and passes it as standard input to its child.
@end deffn

@anchor{Socket addresses}
@section Socket addresses

The format of a socket address depends on the address family of the
socket. Address-family-specific routines are provided to convert
protocol-specific addresses to socket addresses. The value returned by
these routines is a @code{socket-address} record, defined to have the
following visible structure:

@example
(define-record socket-address
  family)       ; address family
@end example

The @code{family} is one of the following constants:

@example
address-family/unspecified
address-family/unix
address-family/internet
@end example

@deffn Procedure unix-address->socket-address pathname

@code{Unix-address->socket-address} returns a @code{socket-address}
based on the string @var{pathname}. There is a system dependent limit on
the length of @var{pathname}.
@end deffn

@deffn Procedure internet-address->socket-address host-address service-port

@code{Internet-address->socket-address} returns a socket-address based
on an integer @var{host-address} and an integer @var{service-port}.
Besides being a 32-bit host address, an internet host address can also
be one of the followingconstants:

@example
internet-address/any
internet-address/loopback
internet-address/broadcast
@end example

The use of @code{internet-address/any} is described below in
@code{bind-socket}.  @code{Internet-address/loopback} is an address that
always specifies the local machine.  @code{Internet-address/broadcast}
is used for network broadcast communications.

For information on obtaining a host's address, see the @code{host-info}
procedure.
@end deffn

@deffn Procedure socket-address->unix-address socket-address
@deffnx Procedure socket-address->internet-address socket-address

The routines @code{socket-address->internet-address} and
@code{socket-address->unix-address} return the address-family-specific
addresses. Be aware that most implementations don't correctly return
anything more than an empty string for addresses in the UNIX
address-family.
@end deffn

@anchor{Socket primitives}
@section Socket primitives

The procedures in this section are presented in the order in which a
typical program will use them. Consult a text on network systems programming for
more information on sockets. Some recommended ones are:

@itemize
@item @emph{UNIX Network Programming} by W. Richard Stevens

@item @emph{An Introductory 4.3BSD Interprocess Communication Tutorial}

@item @emph{An Advanced 4.3BSD Interprocess Communication Tutorial}

@item The previous two documents were reprinted in @emph{UNIX Programmer's Supplementary Documents Volume 1}.
@end itemize

The middle two tutorials are freely available as part of
@acronym{BSD}.  In the absence of these, your UNIX manual pages for
@code{socket()} might be a good starting point for information.

@deffn Procedure connect-socket socket socket-address

@code{Connect-socket} sets up a connection from a socket to a remote
@var{socket-address}. A connection has different meanings depending on
the socket type. A stream socket must be connected before use. A
datagram socket can be connected multiple times, but need not be
connected at all if the remote address is specified with each
@code{send-message}, described below. Also, datagram sockets may be
disassociated from a remote address by connecting to a null remote
address.
@end deffn

@deffn Procedure connect-socket-no-wait socket socket-address
@deffnx Procedure connect-socket-successful? socket

Just like @code{connect-socket}, @code{connect-socket-no-wait} sets up a
connection from a @var{socket} to a remote @var{socket-address}. Unlike
@code{connect-socket}, @code{connect-socket-no-wait} does not block if
it cannot establish the connection immediately. Instead it will return
@code{#f} at once. In this case a subsequent @code{select} on the output
port of the socket will report the output port as ready as soon as the
operation system has established the connection or as soon as setting up
the connection led to an error. Afterwards,the procedure
@code{connect-socket-successful?} can be used to test whether the
connection has been established successfully or not.
@end deffn

@deffn Procedure bind-socket socket socket-address

@code{Bind-socket} assigns a certain local @var{socket-address} to a
socket. Binding a socket reserves the local address. To receive
connections after binding the socket, use @code{listen-socket} for
stream sockets and @code{receive-message} for datagram sockets.

Binding an internet socket with a host address of
@code{internet-address/any} indicates that the caller does not care to
specify from which local network interface connections are received.
Binding an internet socket with a service port number of zero indicates
that the caller has no preference as to the port number assigned.

Binding a socket in the UNIX address family creates a socket special
file in the file system that must be deleted before the address can be
reused. See @code{delete-file}.
@end deffn

@deffn Procedure listen-socket socket backlog

@code{Listen-socket} allows a stream socket to start receiving
connections, allowing a queue of up to @var{backlog} connection
requests. Queued connections may be accepted by
@code{accept-connection}.
@end deffn

@deffn Procedure accept-connection socket

@code{Accept-connection} receives a connection on a socket, returning a
new socket that can be used for this connection and the remote socket
address associated with the connection.
@end deffn

@deffn Procedure socket-local-address socket
@deffnx Procedure socket-remote-address socket

Sockets can be associated with a local address or a remote address or
both.

@code{Socket-local-address} returns the local @code{socket-address}
record associated with @var{socket}.

@code{Socket-remote-address} returns the remote @code{socket-address}
record associated with @var{socket}.
@end deffn

@deffn Procedure shutdown-socket socket how-to

@code{Shutdown-socket} shuts down part of a full-duplex socket. The
method of shutting down is specified by the @var{how-to} argument, one
of:

@example
shutdown/receives
shutdown/sends
shutdown/sends+receives
@end example
@end deffn

@anchor{Performing input and output on sockets}
@section Performing input and output on sockets

@deffn Procedure receive-message socket length [flags]
@deffnx Procedure receive-message! socket string [start] [end] [flags]
@deffnx Procedure receive-message/partial socket length [flags]
@deffnx Procedure receive-message!/partial socket string [start] [end] [flags]

@deffnx Procedure send-message socket string [start] [end] [flags] [socket-address]
@deffnx Procedure send-message/partial socket string [start] [end] [flags] [socket-address]

For most uses, standard input and output routines such as
@code{read-string} and @code{write-string} should suffice. However, in
some cases an extended interface is required. The @code{receive-message}
and @code{send-message} procedures parallel the @code{read-string} and
@code{write-string} procedures with a similar naming scheme.

One additional feature of these routines is that @code{receive-message}
returns the remote @code{socket-address} and @code{send-message} takes
an optional remote @code{socket-address}. This allows a program to know
the source of input from a datagram socket and to use a datagram socket
for output without first connecting it.  All of these procedures take an
optional @var{flags} field. This argument is an integer bit-mask,
composed by or'ing together the following constants:

@example
message/out-of-band
message/peek
message/dont-route
@end example

See @code{read-string} and @code{write-string} for a more detailed
description of the arguments and return values.
@end deffn

@anchor{Socket options}
@section Socket options

@deffn Procedure socket-option socket level option
@deffnx Procedure set-socket-option socket level option value

@code{Socket-option} and @code{set-socket-option} allow the inspection
and modification, respectively, of several options available on sockets.
The @var{level} argument specifies what protocol level is to be examined
or affected. A level of @code{level/socket} specifies the highest
possible level that is available on all socket types. A specific
protocol number can also be used as provided by @code{protocol-info},
described below.

There are several different classes of socket options. The first class
consists of boolean options which can be either true or false. Examples
of this option type are:

@example
socket/debug
socket/accept-connect
socket/reuse-address
socket/keep-alive
socket/dont-route
socket/broadcast
socket/use-loop-back
socket/oob-inline
socket/use-privileged
socket/cant-signal
tcp/no-delay
@end example

Value options are another category of socket options. Options of this
type are an integer value. Examples of this option type are:

@example
socket/send-buffer
socket/receive-buffer
socket/send-low-water
socket/receive-low-water
socket/error
socket/type
ip/time-to-live
tcp/max-segment
@end example

A third option type specifies how long for data to linger after a socket
has been closed. There is only one option of this type:
@code{socket/linger}. It is set with either @code{#f} to disable it or
an integer number of seconds to linger and returns a value of the same
type upon inspection.

The fourth and final option type is a timeout option.There are two
examples of this option type: @code{socket/send-timeout} and
@code{socket/receive-timeout}. These are set with a real number of
microseconds resolution and return a value of the same type upon
inspection.
@end deffn

@anchor{Database-information entries}
@section Database-information entries

@deffn Procedure host-info name-or-socket-address
@deffnx Procedure network-info name-or-network-number
@deffnx Procedure service-info name-or-port-number [protocol-name]
@deffnx Procedure protocol-info name-or-protocol-number

@code{Host-info} allows a program to look up a host entry based on
either its string @var{name} or @var{socket-address}. The value returned
by this routine is a @code{hostinfo} record, defined to have the
following structure:

@example
(define-record host-info
  name          ; Host name
  aliases       ; Alternative names
  addresses)    ; Host addresses
@end example

@code{Host-info} could fail and raise an error for one of the following
reasons:

@example
herror/host-not-found
herror/try-again
herror/no-recovery
herror/no-data
herror/no-address
@end example

@code{Network-info} allows a program to look up a network entry based on
either its string @var{name} or @var{network number}. The value returned
by this routine is a @code{network-info} record, defined to have the
following structure:

@example
(define-record network-info
  name          ; Network name
  aliases       ; Alternative names
  net)          ; Network number
@end example

@code{Service-info} allows a program to look up a service entry based on
either its string @var{name} or integer @var{port-number}. The value returned
by this routine is a @code{service-info} record, defined to have the
following structure:

@example
(define-record service-info
  name          ; Service name
  aliases       ; Alternative names
  port          ; Port number
  protocol)     ; Protocol name
@end example

@code{Protocol-info} allows a program to look up a protocol entry based
on either its string @var{name} or integer @var{protocol number}. The value
returned by this routine is a @code{protocol-info} record, defined to
have the following structure:

@example
(define-record protocol-info
  name          ; Protocol name
  aliases       ; Alternative names
  number)       ; Protocol number)
@end example

@code{Network-info}, @code{service-info} and @code{protocol-info} return
@code{#f} if the specified entity was not found.
@end deffn

@node Strings and characters, Pattern-matching strings with regular expressions, Networking, Top
@chapter Strings and characters

Strings are the basic communication medium for UNIX processes, so a UNIX
programming environment must have reasonable facilities for manipulating
them. Scsh provides a powerful set of procedures for processing strings
and characters. Besides the the facilities described in this chapter,
scsh also provides

@itemize
@item @ref{Pattern-matching strings with regular expressions}

A complete regular expression system.

@item @ref{Awk record I/O and field parsing}

These procedures let you read in chunks of text delimited by selected
characters, and parse each record into fields based on regular
expressions (for example, splitting a string at every occurrence of
colon or whitespace). The @code{awk} form allows you to loop over
streams of these records in a convenient way.

@item The SRFI-13 string libraries

This pair of libraries contains procedures that create, fold, iterate
over, search, compare, assemble, cut, hash, case-map, and otherwise
manipulate strings. They are provided by the @code{string-lib} and
@code{string-lib-internals} packages, and are also available in the
default @code{scsh} package.

More documentation on these procedures can be found at URLs

@example
@uref{http://srfi.schemers.org/srfi-13/srfi-13.html}
@uref{http://srfi.schemers.org/srfi-13/srfi-13.txt}
@end example

@item The SRFI-14 character-set library

This library provides a set-of-characters abstraction, which is
frequently useful when searching, parsing, filtering, or otherwise
operating on strings and character data. The SRFI is provided by the
@code{char-set-lib} package; its bindings are also available in the
default @code{scsh} package.

More documentation on this library can be found at URLs

@example
@uref{http://srfi.schemers.org/srfi-14/srfi-14.html}
@uref{http://srfi.schemers.org/srfi-14/srfi-14.txt}
@end example
@end itemize

@anchor{Manipulating file names}
@section Manipulating file names

These procedures do not access the file system at all; they merely
operate on file-name strings. Much of this structure is patterned after
the GNU Emacs design. Perhaps a more sophisticated system would be
better, something like the pathname abstractions of Common Lisp or MIT
Scheme. However, being UNIX-specific, we can be a little less general.

@anchor{Filename Terminology}
@subsection Filename Terminology

These procedures carefully adhere to the @acronym{POSIX} standard for
filename resolution, which occasionally entails some slightly odd
things. This section will describe these rules, and give some basic
terminology.

A @emph{filename} is either the file system root (``@code{/}''), or a
series of slash-terminated directory components, followed by a a file
component. Root is the only filename that may end in slash. Some
examples:

@multitable @columnfractions .33 .33 .33
@headitem Filename
@tab Dir components 
@tab File component
@item @code{src/des/main.c} 
@tab @code{("src" "des")} 
@tab @code{"main.c"}
@item @code{/src/des/main.c} 
@tab @code{("" "src" "des")} 
@tab @code{"main.c"}
@item @code{main.c} 
@tab @code{()} 
@tab @code{"main.c"}
@end multitable

Note that the relative filename @code{src/des/main.c} and the absolute
filename @code{/src/des/main.c} are distinguished by the presence of the
root component @code{""} in the absolute path.

Multiple embedded slashes within a path have the same meaning as a
single slash. More than two leading slashes at the beginning of a path
have the same meaning as a single leading slash---they indicate that the
filename is an absolute one, with the path leading from root. However,
@acronym{POSIX} permits the OS to give special meaning to two leading
slashes. For this reason, the routines in this section do not simplify
two leading slashes to a single slash.

A filename in @emph{directory form} is either a filename terminated by
a slash, @emph{e.g.}, @code{"/src/des/"}, or the empty string,
@code{""}. The empty string corresponds to the current working
directory, whose filename is dot (@code{"."}). Working backwards from
the append-a-slash rule, we extend the syntax of @acronym{POSIX} file
names to define the empty string to be a filename form of the root
directory @code{"/"}.  (However, @code{"/"} is also acceptable as a file
name form for root.)  So the empty string has two interpretations: as a
filename form, it is the file system root; as a directory form, it is
the current working directory. Slash is also an ambiguous form: @code{/}
is botha directory form and a filename form.

The directory form of a filename is very rarely used. Almost all of the
procedures in scsh name directories by giving their file-name form
(without the trailing slash), not their directory form. So, you say
@code{"/usr/include"}, and @code{"."}, not @code{"/usr/include/"} and
@code{""}. The sole exceptions are @code{file-name-as-directory} and
@code{directory-as-file-name}, whose jobs are to convert back and forth
between these forms, and @code{file-name-directory}, whose job it is to
split out the directory portion of a filename. However, most procedures
that expect a directory argument will coerce a filename in directory
form to filename form if it does not have a trailing slash. Bear in
mind that the ambiguous case, empty string, will be interpreted in file
name form, i.e., as root.

@page @c Required for printed output.
@anchor{Filename Procedures}
@subsection Filename Procedures

@deffn Procedure file-name-directory? fname
@deffnx Procedure file-name-non-directory? fname

These predicates return true if the string is in directory form or
filename form (see the above discussion of these two forms). Note that
they both return true on the ambiguous case of the empty string, which
is both a directory (the current working directory), and a filename
(the file system root).

@multitable @columnfractions .33 .33 .33
@headitem Filename 
@tab @code{*-directory?} 
@tab @code{*-non-directory?}
@item @code{"src/des"} 
@tab @code{#f} 
@tab @code{#t}
@item @code{"src/des/"} 
@tab @code{#t}
@tab @code{#f}
@item @code{"/"} 
@tab @code{#t} 
@tab @code{#f}
@item @code{"."} 
@tab @code{#f} 
@tab @code{#t}
@item @code{""} 
@tab @code{#t} 
@tab @code{#t}
@end multitable
@end deffn

@deffn Procedure file-name-as-directory fname

Convert a filename to directory form. Basically, add a trailing slash
if needed:

@example
(file-name-as-directory "src/des")
  ==> "src/des/"

(file-name-as-directory "src/des/")
  ==> "src/des/"
@end example

@code{.}, @code{/}, and @code{""} are special:

@example
(file-name-as-directory ".")
==> ""

(file-name-as-directory "/")
==> "/"

(file-name-as-directory "") 
==> "/"
@end example
@end deffn

@deffn Procedure directory-as-file-name fname

Convert a directory to a simple filename. Basically, kill a trailing
slash if one is present:

@example
(directory-as-file-name "foo/bar/") =) "foo/bar"
@end example

@code{/} and @code{""} are special:

@example
(directory-as-file-name "/") 
==> "/"

(directory-as-file-name "") 
==> "."
@end example
@end deffn

@deffn Procedure file-name-absolute? fname

Does @var{fname} begin with a root or @code{~} component? (Recognising
@code{~} as a home directory specification is an extension of
@acronym{POSIX} rules.)

@example
(file-name-absolute? "/usr/shivers") 
==> #t

(file-name-absolute? "src/des") 
==> #f

(file-name-absolute? "~/src/des") 
==> #t
@end example

Non-obvious case:

@example
(file-name-absolute? "") 
=> #t
@end example
@end deffn

@deffn Procedure file-name-directory fname

Return the directory component of @var{fname} in directory form. If
the filename is already in directory form, return it as-is.

@example
(file-name-directory "/usr/bdc") 
==> "/usr/"

(file-name-directory "/usr/bdc/") 
==> "/usr/bdc/"

(file-name-directory "bdc/.login") 
==> "bdc/"

(file-name-directory "main.c") 
==> ""
@end example

The filesystem root has no directory component:

@example
(file-name-directory "/") 
==> ""

(file-name-directory "") 
==> ""
@end example
@end deffn

@deffn Procedure file-name-nondirectory fname

Return the non-directory component of @var{fname}.

@example
(file-name-nondirectory "/usr/ian") 
==> "ian"

(file-name-nondirectory "/usr/ian/") 
==> ""

(file-name-nondirectory "ian/.login") 
==> ".login"

(file-name-nondirectory "main.c") 
==> "main.c"

(file-name-nondirectory "") 
==> ""

(file-name-nondirectory "/") 
==> "/"
@end example
@end deffn

@deffn Procedure split-file-name fname

Split a filename into its components.

@example
(split-file-name "src/des/main.c")
==> ("src" "des" "main.c")

(split-file-name "/src/des/main.c")
==> ("" "src" "des" "main.c")

(split-file-name "main.c")
==> ("main.c")

(split-file-name "/")
==> ("")
@end example
@end deffn

@deffn Procedure path-list->file-name path-list [dir]

Inverse of @code{split-file-name}.

@example
(path-list->file-name '("src" "des" "main.c"))
==> "src/des/main.c"

(path-list->file-name '("" "src" "des" "main.c"))
==> "/src/des/main.c"
@end example

The optional @var{dir} argument anchors relative path lists:

@example
(path-list->file-name '("src" "des" "main.c") "/usr/shivers")
==> "/usr/shivers/src/des/main.c"
@end example

@var{Dir} is usually set to @code{(cwd)}.
@end deffn

@deffn Procedure file-name-extension fname

Return the filename's extension.

@example
(file-name-extension "main.c") 
==> ".c"

(file-name-extension "main.c.old") 
==> ".old"

(file-name-extension "/usr/shivers") 
==> ""
@end example

Weird cases:

@example
(file-name-extension "foo.") 
==> "."

(file-name-extension "foo..") 
==> "."
@end example

Dot files are not extensions:

@example
(file-name-extension "/usr/shivers/.login") 
==> ""
@end example
@end deffn

@deffn Procedure file-name-sans-extension fname

Return everything but the file extension.

@example
(file-name-sans-extension "main.c") 
==> "main"

(file-name-sans-extension "main.c.old") 
==> "main.c""

(file-name-sans-extension "/usr/shivers")
==> "/usr/shivers"
@end example

Weird cases:

@example
(file-name-sans-extension "foo.") 
==> "foo"

(file-name-sans-extension "foo..") 
==> "foo."
@end example

Dot files are not extensions:

@example
(file-name-sans-extension "/usr/shivers/.login")
==> "/usr/shivers/.login
@end example

Note that appending the results of @code{file-name-extension} and
@code{file-name-sans-extension} in all cases produces the original
filename.
@end deffn

@deffn Procedure parse-file-name fname

Let @var{f} be @code{(file-name-nondirectory @var{fname})}. This
function returns three values:

@itemize
@item @code{(file-name-directory @var{fname})}
@item @code{(file-name-sans-extension @var{f})}
@item @code{(file-name-extension @var{f})}
@end itemize

The inverse of @code{parse-file-name}, in all cases, is
@code{string-append}. The boundary case of @code{/} was chosen to
preserve this inverse.
@end deffn

@deffn Procedure replace-extension fname ext

This procedure replaces @var{fname}'s extension with @var{ext}. It is exactly equivalent to

@example
(string-append (file-name-sans-extension @var{fname}) @var{ext})
@end example
@end deffn

@deffn Procedure simplify-file-name fname

Removes leading and internal occurrences of dot (``@code{.}''). A
trailing dot is left alone, as the parent could be a symlink. Removes
internal and trailing double-slashes. A leading double-slash is left
alone, in accordance with @acronym{POSIX}. However, if there are three
or more leading slashes, they are reduced to a single slash, in
accordance with @acronym{POSIX}. Double-dots (``@code{..}'', also
known as the parent directory) are left alone, in case they come after
symlinks or appear in a @code{/../machine/...} ``super-root'' form
(which @acronym{POSIX} permits).
@end deffn

@deffn Procedure resolve-file-name fname [dir]

@itemize
@item Do @code{~} expansion.

@item If directory @var{dir} is given, convert a relative filename to
an absolute one, relative to @var{dir}.
@end itemize
@end deffn

@deffn Procedure expand-file-name fname [dir]

Resolve and simplify the filename.
@end deffn

@deffn Procedure absolute-file-name fname [dir]

Convert the filename @var{fname} into an absolute filename, relative
to the directory @var{dir}, which defaults to the current working
directory. The filename is simplified before being returned.

This procedure does not treat a leading tilde character specially.
@end deffn

@deffn Procedure home-dir [user]

@code{Home-dir} returns @var{user}'s home directory. @var{User}
defaults to the current user.

@example
(home-dir)
==> "/user1/lecturer/shivers"

(home-dir "ctkwan")
==> "/user0/research/ctkwan"
@end example
@end deffn

@deffn Procedure home-file [user] fname

Returns the filename @var{fname} relative to @var{user}'s home
directory; @var{user} defaults to the current user.

@example
(home-file "man") 
==> "/usr/shivers/man"

(home-file "fcmlau" "man") 
==> "/usr/fcmlau/man"
@end example
@end deffn

The general @code{substitute-env-vars} string procedure, defined in
the previous section, is also frequently useful for expanding
filenames.

@anchor{Other string manipulation facilities}
@section Other string manipulation facilities

@deffn Procedure substitute-env-vars fname

Replace occurrences of environment variables with their values. An
environment variable is denoted by a dollar sign followed by
alphanumeric characters and underscores, or is surrounded by braces.

@example
(substitute-env-vars "$USER/.login")
==> "shivers/.login"

(substitute-env-vars "$@{USER@}_log")
==> "shivers_log"
@end example
@end deffn

@anchor{ASCII encoding}
@section ASCII encoding

@deffn Procedure char->ascii character
@deffnx Procedure ascii->char integer

These are identical to @code{char->integer} and @code{integer->char}
except that they use the ASCII encoding.
@end deffn

@anchor{Character predicates}
@section Character predicates

@deffn Procedure char-letter? character
@deffnx Procedure char-lower-case? character
@deffnx Procedure char-upper-case? character
@deffnx Procedure char-title-case? character
@deffnx Procedure char-digit? character
@deffnx Procedure char-letter+digit? character
@deffnx Procedure char-graphic? character
@deffnx Procedure char-printing? character
@deffnx Procedure char-whitespace? character
@deffnx Procedure char-blank? character
@deffnx Procedure char-iso-control? character
@deffnx Procedure char-punctuation? character
@deffnx Procedure char-hex-digit? character
@deffnx Procedure char-ascii? character

Each of these predicates tests for membership in one of the standard
character sets provided by the SRFI-14 character-set
library. Additionally, the following redundant bindings are provided
for @acronym{R5RS} compatibility:

@multitable @columnfractions .50 .50
@headitem @acronym{R5RS} name 
@tab scsh definition

@item @code{char-alphabetic?} 
@tab @code{char-letter+digit?}

@item @code{char-numeric?} 
@tab @code{char-digit?}

@item @code{char-alphanumeric?}
@tab @code{char-letter+digit?}

@end multitable
@end deffn

@anchor{Deprecated character-set procedures}
@section Deprecated character-set procedures

The SRFI-13 character-set library grew out of an earlier library
developed for scsh. However, the SRFI standardisation process
introduced incompatibilities with the original scsh bindings. The
current version of scsh provides the library
@code{obsolete-char-set-lib}, which contains the old bindings found in
previous releases of scsh. The following table lists the members of
this library, along with the equivalent SRFI-13 binding. This obsolete
library is deprecated and not open by default in the standard scsh
environment; new code should use the SRFI-13 bindings.

@multitable @columnfractions .50 .50
@headitem Old @code{obsolete-char-set-lib}
@tab SRFI-13 @code{char-set-lib}

@item @code{char-set-members}
@tab @code{char-set->list}

@item @code{chars->char-set}
@tab @code{list->char-set}

@item @code{ascii-range->char-set}
@tab @code{ucs-range->char-set} (not exact)

@item @code{predicate->char-set}
@tab @code{char-set-filter} (not exact)

@item @code{char-set-every?}
@tab @code{char-set-every}

@item @code{char-set-any?}
@tab @code{char-set-any}

@item @code{char-set-invert}
@tab @code{char-set-complement}

@item @code{char-set-invert!}
@tab @code{char-set-complement!}

@item @code{char-set:alphabetic}
@tab @code{char-set:letter}

@item @code{char-set:numeric}
@tab @code{char-set:digit}

@item @code{char-set:alphanumeric}
@tab @code{char-set:letter+digit}

@item @code{char-set:control}
@tab @code{char-set:iso-control}

@end multitable

Note also that the @code{->char-set} procedure no longer handles a
predicate argument.

@node Pattern-matching strings with regular expressions, Reading delimited strings, Strings and characters, Top
@chapter Pattern-matching strings with regular expressions

Scsh provides a rich facility for matching regular-expression patterns
in strings. The system is composed of several pieces:

@itemize
@item An s-expression notation for writing down general regular expressions

In most systems, regexp patterns are encoded as string literals, such
as @code{"g(oo|ee)se"}. In scsh, they are written using s-expressions,
such as @code{(: "g" (| "oo" "ee") "se")}; such an expression is
called an @acronym{SRE}, or ``s-expression regexp''. The @acronym{SRE}
notation has several advantages over the traditional string-based
notation. It's more expressive, can be commented, and can be indented
to expose the structure of the form.

@item An abstract data type (@acronym{ADT}) representation for regexp values

Traditional regular-expression systems compute regular expressions
from run-time values using strings. This can be awkward. Scsh,
instead, provides a separate data type for regexps, with a set of
basic constructor and accessor functions; regular expressions can be
dynamically computed and manipulated using these functions.

@item Some tools that work on the regexp @acronym{ADT}

Case-sensitve to case-insensitive regexp transform, a regexp
simplifier, and so forth.

@item Parsers and unparsers that can convert between external representations and the regexp @acronym{ADT}

The supported external representations include both @acronym{POSIX}
strings and @acronym{SRE}s.

Being able to convert regexps to @acronym{POSIX} strings allows
implementations to implement regexp matching using standard
@acronym{POSIX} C-based engines.

@item Syntax support for the @acronym{SRE} notation

The @code{rx} macro provides a new special form that allows you to
embed regexps in the s-expression notation within a Scheme
program. Evaluating the macro form produces a regexp @acronym{ADT}
value which can be used by Scheme pattern-matching procedures and
other regexp consumers.

@item Pattern-matching and searching procedures

Spencer's @acronym{POSIX} regexp engine is linked in to the runtime;
the regexp code uses this engine to provide text matching.
@end itemize

The regexp language supported is a complete superset of @acronym{POSIX} functionality, providing:

@itemize

@item Sequencing and choice (@code{|})

@item Repetition (@code{*}, @code{+}, @code{?}, @code{@{m,n@}})

@item Character classes (e.g., @code{[aeiou]}) and wildcard (@code{.})

@item Beginning- and end-of-string anchors (@code{^}, @code{$})

@item Case-sensitivity control

@item Submatch-marking
@end itemize

@anchor{Summary SRE syntax}
@section Summary SRE syntax

The following figures give a summary of the @acronym{SRE} syntax; the
next section is a friendlier tutorial introduction.

@table @code
@item @var{string} 

Literal match---interpreted relative to the current case-sensitivity
lexical context (default is case sensitive)

@item @code{(@var{string1} @var{string2} @dots{})}

Set of characters, @emph{e.g.}, @code{("abc" "XYZ")}. Interpreted
relative to the current case-sensitivity lexical context.

@item @code{(* @var{sre} @dots{})}

Zero (0) or more matches.

@item @code{(+ @var{sre} @dots{})}

One (1) or more matches.

@item @code{(? @var{sre} @dots{})}

Zero (0) or one (1) matches.

@item @code{(= @var{n} @var{sre} @dots{})}

@var{N} matches.

@item @code{(>= @var{n} @var{sre} @dots{})}
 
@var{N} or more matches.

@item @code{(** @var{n} @var{m} @var{sre} @dots{})}

@var{N} to @var{m} matches. @var{N} and @var{m} are Scheme expressions
producing non-negative integers. @var{M} may also be @code{#f},
meaning ``infinity''.

@item @code{(| @var{sre} @dots{})}
@itemx @code{(or @var{sre} @dots{})}

Choice (@code{or} is an @acronym{R5RS} symbol; @code{|} is not
specified by @acronym{R5RS}.)

@item @code{(: @var{sre} @dots{})}
@itemx @code{(seq @var{sre} @dots{})}

Sequence (@code{seq} is a legal Common Lisp symbol).

@item @code{(submatch @var{sre} @dots{})}

Numbered submatch.

@item @code{(dsm @var{pre} @var{post} @var{sre} @dots{})} 

Deleted submatches. @var{Pre} and @var{post} are numerals.

@item @code{(uncase @var{sre} @dots{})}
 
Case-folded match.

@item @code{(w/case @var{sre} @dots{})}
@item @code{(w/nocase @var{sre} @dots{})}

Introduce a lexical case-sensitivity context.

@item @code{,@@exp}

Dynamically computed regexp.

@item @code{,}@var{exp}

Same as @code{,}@var{@@exp}, but no submatch info. @var{Exp} must
produce a character, string, char-set, or regexp.

@item @var{bos} @var{eos}

Beginning/end of string.

@item @var{bol} @var{eol}

Beginning/end of line.
@end table

@anchor{Figure 2}

@b{Figure 2}: SRE Syntax Summary (Part 1).

@table @code

@item @code{(posix-string @var{string})} 

Escape for @acronym{POSIX} string notation.

@item @var{char} 
@itemx @var{class-name}

@var{Char} denotes a singleton character. @var{Class-name} refers to
classes of characters, @emph{e.g.}, alphanumeric, whitespace, etc.

These two forms are interpreted subject to the lexical case-sensitivity
context.

@item @code{(~ @var{cset-sre} @dots{})}

Character set complement-of-union @code{([^@dots{}])}.

@item @code{(- @var{cset-sre} @dots{})} 

Character set difference.

@item @code{(& @var{cset-sre} @dots{})} 

Character set intersection.

@item @code{(/ @var{range-spec} @dots{})}

Character range---interpreted subject to the lexical case-sensitivy
context.
@end table

@anchor{Figure 3}

@b{Figure 3}: @acronym{SRE} Syntax Summary (Part 2).

@table @code
@item any

@emph{N/A}.

@item nonl

@emph{N/A}.

@item lower-case 

@code{lower}

@item upper-case 

@code{upper}

@item alphabetic 

@code{alpha}

@item numeric 

@code{digit | num}

@item alphanumeric 

@code{alnum}

@item punctuation 

@code{punct}

@item graphic 

@code{graph}

@item whitespace 

@code{space | white}

@item printing 

@code{print}

@item control 

@code{cntrl}

@item hex-digit 

@code{xdigit | hex}

@item ascii

@emph{N/A}.

@end table

@anchor{Figure 4}

@b{Figure 4}: The table above shows @emph{class-names} and their
associated @emph{range-specs}. Where the vertical bar is shown,
characters are taken in pairs to form inclusive ranges, @emph{e.g.},
@emph{range-spec ::= string | char}.

@example
<cset-sre> ::= (~ <cset-sre> ...)   Set complement-of-union
             | (- <cset-sre> ...)   Set difference
             | (& <cset-sre> ...)   Intersection
             | (| <cset-sre> ...)   Set union
             | (/ <range-spec> ...) Range
             
             | (<string>)           Constant set
             | <char>               Singleton constant set
             | <string>             For 1-char string "c"
             
             | <class-name>         Constant set
             
             | ,<exp> <exp>         Evaluates to a char-set,
             | ,@@<exp>              char, single-char string, 
                                    or re-char-set regexp.

             | (uncase <cset-sre>)  Case-folding
             | (w/case <cset-sre>)
             | (w/nocase <cset-sre>)
@end example

@anchor{Figure 5}

@b{Figure 5}: These are the ``type-checking'' rules applied to
@acronym{SRE}s that specify character sets.

@page
@anchor{Examples}
@section Examples

@example
(- alpha ("aeiouAEIOU"))                ; Various forms of
(- alpha ("aeiou") ("AEIOU"))           ; non-vowel letter
(w/nocase (- alpha ("aeiou")))
(- (/"azAZ") ("aeiouAEIOU"))
(w/nocase (- (/"az") ("aeiou")))

;;; Upper-case letter, lower-case vowel, or digit
(| upper ("aeiou") digit)
(| (/"AZ09") ("aeiou"))

;;; Not an SRE, but Scheme code containing some embedded SREs.
(let* ((ws (rx (+ whitespace))) ; Seq of whitespace
       (date (rx (: (| "Jan" "Feb" "Mar" ...)   ; A month/day date.
                     ,ws
                     (| ("123456789")           ; 1-9
                     (: ("12") digit)           ; 10-29
                     "30" "31")))))             ; 30-31

   ;; Now we can use DATE several times:
   (rx ... ,date ... (* ... ,date ...)
       ... .... ,date))

;;; More Scheme code
(define (csl re)                ; A comma-separated list of REs is
  (rx (| ""                     ; either zero of them (empty string),
         (: ,re                 ; or one RE, followed by
            (* ", " ,re)))))    ; zero or more comma-space-RE matches.

(csl (rx (| "John" "Paul" "George" "Ringo")))
@end example

@anchor{A short tutorial}
@section A short tutorial

S-expression regexps are called @acronym{SRE}s. Keep in mind that they
are not Scheme expressions; they are another, separate notation that
is expressed using the underlying framework of s-expression list
structure: lists, symbols, etc. @acronym{SRE}s can be embedded inside
of Scheme expressions using special forms that extend Scheme's syntax
(such as the @code{rx} macro); there are places in the SRE grammar
where one may place a Scheme expression. In these ways, @acronym{SRE}s
and Scheme expressions can be intertwined. But this isn't fundamental;
@acronym{SRE}s may be used in a completely Scheme-independent
context. By simply restricting the notation to eliminate two special
Scheme-embedding forms, they can be a completely independent notation.

@subsubsection Constant strings 

The simplest @acronym{SRE} is a string, denoting a constant
regexp. For example, the @acronym{SRE} @code{"Spot"} matches only the
string <<capital S, little p, little o, little t>>. There is no
interpretation of the characters in the string at all---the
@acronym{SRE} @code{".*["} matches the string <<period, asterisk,
open-bracket>>.

@subsubsection Simple character sets 

To specify a set of characters, write a list whose single element is a
string containing the set's elements. So the @acronym{SRE}
@code{("aeiou")} only matches a vowel. One way to think of this,
notationally, is that the set brackets are @code{("} and @code{")}.

@subsubsection Wild card 

Another simple @acronym{SRE} is the symbol @code{any}, which matches
any single character---including newline, but excluding
@acronym{ASCII} @code{NUL}.

@subsubsection Sequences 

We can form sequences of @acronym{SRE}s with the @acronym{SRE}
@code{(: @var{sre} @dots{})}. So the @acronym{SRE}@code{(: "x" any
"z")} matches any three-character string starting with ``x'' and
ending with ``z''. As we'll see shortly, many @acronym{SRE} forms have
bodies that are implicit sequences of other @acronym{SRE}s, analogous
to the manner in which the body of a Scheme @code{lambda} or
@code{let} expression is an implicit @code{begin} sequence. The regexp
@code{(seq @var{sre} @dots{})} is completely equivalent to @code{(:
@var{sre} @dots{})}; it's included in order to have a syntax that
doesn't require @code{:} to be a legal symbol@footnote{That is, for
use within s-expression syntax frameworks that, unlike @acronym{R5RS},
don't allow for @code{:} as a legal symbol. A Common Lisp embedding of
@acronym{SRE}s, for example, would need to use @code{seq} insteadof
@code{:}.}

@subsubsection Choices 

The @acronym{SRE} @code{(| @var{sre} @dots{})} is a regexp that
matches anything any of the @var{sre} regexps match. So the regular
expression @code{(| "sasha" "Pete")} matches either the string
``sasha'' or the string ``Pete''. The regexp @code{(| ("aeiou")
("0123456789"))} is the same as @code{("aeiou0123456789")}. The regexp
@code{(or @var{sre} @dots{})} is completely equivalent to @code{(|
@var{sre} @dots{})}; it's included in order to have a syntax that
doesn't require @code{|} to be a legal symbol.

@subsubsection Repetition
There are several @acronym{SRE} forms that match multiple occurences
of a regular expression. For example, the @acronym{SRE} @code{(*
@var{sre} @dots{})} matches zero or more occurences of the sequence
@code{(: @var{sre} @dots{})}. Here is the complete list of
@acronym{SRE} repetition forms:

@multitable @columnfractions .25 .25 .25 .25
@headitem @acronym{SRE} 
@tab Means 
@tab At least 
@tab No more than

@item @code{(* @var{sre} @dots{})} 
@tab zero-or-more 
@tab 0 
@tab infinity

@item @code{(+ @var{sre} @dots{})} 
@tab one-or-more 
@tab 1 
@tab infinity

@item @code{(? @var{sre} @dots{})} 
@tab zero-or-one 
@tab 0 
@tab 1

@item @code{(= @var{from} @var{sre} @dots{})} 
@tab exactly-n
@tab @var{from} 
@tab @var{from}

@item @code{(>= @var{from} @var{sre} @dots{})} 
@tab n-or-more 
@tab @var{from} 
@tab infinity

@item @code{(** @var{from} @var{to} @var{sre} @dots{})} 
@tab n-to-m 
@tab @var{from} 
@tab @var{to}

@end multitable

A @var{from} field is a Scheme expression that produces an integer. A
@var{to} field is a Scheme expression that produces either an integer,
or false, meaning infinity.

While it is illegal for the @var{from} or @var{to} fields to be
negative, it is allowed for @var{from} to be greater than @var{to} in
a @code{**} form---this simply produces a regexp that will never match
anything.

As an example, we can describe the names of @code{car}/@code{cdr}
access functions (@code{car}, @code{cdr}, @code{cadr}, @code{cdar},
@code{caar} , @code{cddr}, @code{caaadr}, etc.) with either of the
@acronym{SRE}s

@example
(: "c" (+ (| "a" "d")) "r")
(: "c" (+ ("ad")) "r")
@end example

We can limit the ``a''/``d'' chains to 4 characters or less with the @acronym{SRE}

@example
(: "c" (** 1 4 ("ad")) "r")
@end example

Some boundary cases:

@example
(** 5 2 "foo")  ; Will never match
(** 0 0 "foo")  ; Matches the empty string
@end example

@subsubsection Character classes 
There is a special set of @acronym{SRE}s that form "character
classes"---basically, a regexp that matches one character from some
specified set of characters. There are operators to take the
intersection, union, complement, and difference of character classes
to produce a new character class. (Except for union, these
capabilities are not provided for general regexps as they are
computationally intractable in the general case.)

A single character is the simplest character class: @code{#\x} is a
character class that matches only ``x''. A string that has only one
letter is also a character class: ``x'' is the same @acronym{SRE} as
@code{#\x}.

The character-set notation (@emph{string}) we've seen is a primitive
character class, as is the wildcard @code{any}. When arguments to the
choice operator, @code{|}, are all character classes, then the choice
form is itself a character class. So these @acronym{SRE}s are all
character classes:

@example
("aeiou")
(| #\a #\e #\i #\o #\u)
(| ("aeiou") ("1234567890"))
@end example

However, these @acronym{SRE}s are not character classes:

@example
"aeiou"
(| "foo" #\x)
@end example

The @code{(~ @var{cset-sre} @dots{})} character class matches one
character not in the specified classes:

@example
(~ ("0248") ("1359"))
@end example

matches any character that is not a digit.

More compactly, we can use the @code{/} operator to specify character sets by
giving the endpoints of contiguous ranges, where the endpoints are
specified by a sequence of strings and characters. For example, any of
these character classes

@example
(/ #\A #\Z #\a #\z #\0 #\9)
(/ "AZ" #\a #\z "09")
(/ "AZ" #\a "z09")
(/"AZaz09")
@end example

matches a letter or a digit. The range endpoints are taken in pairs to
form inclusive ranges of characters. Note that the exact set of
characters included in a range is dependent on the underlying
implementation's character type, so ranges may not be portable across
different implementations.

There is a wide selection of predefined, named character classes that
may be used. One such @acronym{SRE} is the wildcard
@code{any}. @code{Nonl} Is A Character Class matching anything but
newline; it is equivalent to @code{(~ #\newline)} and is useful as a
wildcard in line-oriented matching.

There are also predefined named character classes for the standard
@acronym{POSIX} and @acronym{GNU} character classes:

@multitable @columnfractions .33 .33 .33
@headitem scsh name
@tab @acronym{POSIX}/ctype 
@tab Alternate name 

@item lower-case 
@tab lower

@item upper-case 
@tab upper

@item alphabetic 
@tab alpha

@item numeric 
@tab digit 
@tab num

@item alphanumeric 
@tab alnum 
@tab alphanum

@item punctuation 
@tab punct

@item graphic 
@tab graph

@item blank 
@tab (Gnu extension)

@item whitespace 
@tab space 
@tab white 

@item printing 
@tab print

@item control 
@tab cntrl

@item hex-digit 
@tab xdigit 
@tab hex

@item ascii 
@tab (Gnu extension)

@end multitable

See the scsh character-set documentation or the @acronym{POSIX}
@code{isalpha(3)} man page for the exact definitions of these sets.

You can use either the long scsh name or the shorter @acronym{POSIX}
and alternate names to refer to these character classes. The standard
@acronym{POSIX} name ``@code{space}'' is provided, but deprecated,
since it is ambiguous. It means ``whitespace'', the set of whitespace
characters, not the singleton set of the @code{#\space} character. If
you want a short name for the set of whitespace characters, use the
char-class name @code{white} instead.

Character classes may be intersected with the operator @code{(&
@var{cset-sre} @dots{})}, and set-difference can be performed with
@code{(- @var{cset-sre} @dots{})}. These operators are particularly
useful when you want to specify a set by negation with respect to a
limited universe. For example, the set of all non-vowel letters is

@example
(- alpha ("aeiou") ("AEIOU"))
@end example

whereas writing a simple complement

@example
(~ ("aeiouAEIOU"))
@end example

gives a character class that will match any non-vowel---including
punctuation, digits, white space, control characters, and
@acronym{ASCII} @code{NUL}.

We can @emph{compute} a character class by writing the @acronym{SRE}

@example
,@var{cset-exp}
@end example

where @var{cset-exp} is a Scheme expression producing a value that can
be coerced to a character set: a character set, character,
one-character string, or char-class regexp value. This regexp matches
one character from the set.

The char-class @acronym{SRE} ,@var{@@cset-exp} is entirely equivalent
to ,@var{cset-exp} when @var{cset-exp} produces a character set (but
see below for the more general non-character-class context, where
there is a distinction between ,@var{exp} and ,@var{@@exp}.

As an example of character-class @acronym{SRE}s, an @acronym{SRE} that
matches a lower-case vowel, upper-case letter, or digit is

@example
(| ("aeiou") (/"AZ09"))
@end example

or, equivalently

@example
(| ("aeiou") upper-case numeric)
@end example

Boundary cases: the empty-complement char class

@example
(~)
@end example

matches any character; it is equivalent to @code{any}. The empty-union
char class

@example
(|)
@end example

never matches at all. This is rarely useful for human-written regexps,
but may be of occasional utility in machine-generated regexps, perhaps
produced by macros.

The rules for determining if an @acronym{SRE} is a simple, char-class
@acronym{SRE} or a more complex @acronym{SRE} form a little ``type
system'' for @acronym{SRE}s. See the summary section preceding this
one for a complete listing of these rules.

@emph{Note}: There is no way to include the @acronym{ASCII} @code{NUL}
character in a character set or search for it in any other way using
regular expressions. This is because the @acronym{POSIX} regexp
facility is based on the C language which uses @acronym{ASCII}
@code{NUL} to terminate strings.

@subsubsection Case sensitivity 

There are three forms that control case sensitivity:

@example
(uncase @var{sre} @dots{})
(w/case @var{sre} @dots{})
(w/nocase @var{sre} @dots{})
@end example

@code{Uncase} is a regexp operator producing a regexp that matches any
case permutation of any string that matches @code{(: @var{sre}
@dots{})}. For example, the regexp

@example
(uncase "foo")
@end example

matches the strings ``foo'', ``foO'', ``fOo'', ``fOO'', ``Foo'',
@dots{}

Expressions in @acronym{SRE} notation are interpreted in a lexical
case-sensitivity context. The forms @code{w/case} and @code{w/nocase}
are the scoping operators for this context, which controls how
constant strings and char-class forms are interpreted in their
bodies. So, for example, the regexp

@example
(w/nocase "abc"
          (* "FOO" (w/case "Bar"))
          ("aeiou"))
@end example

defines a case-insensitive match for all of its elements except for
the sub-element ``Bar'', which must match exactly capital-B, little-a,
little-r. The default, the outermost, top-level context is case
sensitive.

The lexical case-sensitivity context affects the interpretation of

@itemize
@item 
constant strings, such as ``foo'',

@item 
characters, such as @code{#\x},

@item 
character sets, such as @code{("abc")}, and

@item 
ranges, such as @code{(/"az")} that appear within that context. It
does not affect dynamically computed regexps---ones that are
introduced by ,@var{exp} and ,@var{@@exp} forms. It does not affect
named char-classes---presumably, if you wrote @code{lower}, you didn't
mean @code{alpha}.

@code{Uncase} is not the same as @code{w/nocase}. To point up one
distinction, consider the two regexps

@example
(uncase (~ "a"))
(w/nocase (~ "a"))
@end example
@end itemize

The regexp @code{(~ "a")} matches any character except ``a'', which
means it does match ``A''. Now, @code{(uncase @var{re})} matches any
case-permutation of a string that rematches.  @code{(~ "a")} matches
``A'', so @code{(uncase (~ "a"))} matches ``A'' and ``a''---and, for
that matter, every other character. So @code{(uncase (~ "a"))} is
equivalent to @code{any}.

In contrast, @code{(w/nocase (~ "a"))} establishes a case-insensitive
lexical context in which the ``a'' is interpreted, making the
@acronym{SRE} equivalent to @code{(~ ("aA"))}.

@subsubsection Dynamic regexps 

@acronym{SRE} notation allows you to compute parts of a regular
expression at run time. The @acronym{SRE}

@example
,@var{exp}
@end example

is a regexp whose body @var{exp} is a Scheme expression producing a
string, character, char-set, or regexp as its value. Strings and
characters are converted into constant regexps; char-sets are
converted into char-class regexps; and regexp values are substituted
in place. So we can write regexps like this

@example
(: "feeding the "
   ,(if (> n 1) "geese" "goose"))
@end example

This is how you can drop computed strings, such as someone's name, or
the decimal numeral for a computed number, into a complex regexp.

If we have a large, complex regular expression that is used multiple
times inssome other, containing regular expression, we can name it,
using the binding forms of the embedding language (e.g., Scheme), and
refer to it by name in the containing expression. For example,
consider the Scheme expression

@example
(let* ((ws (rx (+ whitespace))) ; Seq of whitespace
       ;; Something like "Mar 14"
       (date (rx (: (| "Jan" "Feb" "Mar" ...)
                    ,ws
                    (| ("123456789")            ; 1-9
                       (: ("12") digit)         ; 10-29
                       "30"                     ; 30
                       "31")))))                ; 31
  ;; Now we can use DATE several times:
  (rx @dots{} ,date @dots{} (* @dots{} ,date @dots{})
      @dots{} ,date @dots{}))
@end example

where the @code{(rx @var{sre} @dots{})} macro is the Scheme special
form that produces a Scheme regexp value given a body in @acronym{SRE}
notation.

As we saw in the char-class section, if a dynamic regexp is used in a
char-class context (e.g., as an argument to a @code{~} operation), the
expression must be coercable not merely to a general regexp, but to a
character sre--so it must be either a singleton string, a character, a
scsh char set, or a char-class regexp.

We can also define and use functions on regexps in the host
language. For example, consider the following Scheme expressions,
containing embedded @acronym{SRE}s (inside the @code{rx} macro
expressions) which in term contain embedded Scheme expressions
computing dynamic regexps:

@example
(define (csl re)
  ;; A comma-separated list of RE's is either
  (rx (| ""                   ; zero of them (empty string),
         (: ,re               ; or RE followed by
            (* ", " ,re)))))  ; zero or more comma-space-RE matches.

(rx @dots{} ,date @dots{}
    ,(csl (rx (| "John" "Paul" "George" "Ringo")))
    @dots{}
    ,(csl date)
    @dots{})
@end example

We leave the extension of @code{csl} to allow for an optional ``and''
between the last two matches as an exercise for the interested reader
(e.g., to match ``John, Paul, George and Ringo'').

Note, in passing, one of the nice features of @acronym{SRE} notation:
they can be commented, and indented in a fashion to show the lexical
extent of the subexpressions.

When we embed a computed regexp inside another regular expression with
the ,@var{exp} form, we must specify how to account for the submatches
that may be in the computed part. For example, suppose we have the
regexp

@example
(rx (submatch (* "foo"))
    (submatch (? "bar"))
   ,(f x)
   (submatch "baz"))
@end example

It's clear that the submatch for the @code{(* "foo")} part of the
regexp is submatch #1, and the @code{(? "bar")} part is submatch
#2. But what number submatch is the "baz" submatch? It's not
clear. Suppose the Scheme expression @code{(f x)} produces a regular
expression that itself has 3 subforms. Are these counted (making the
``baz'' submatch #6), or not counted (making the ``bar'' submatch #3)?

@acronym{SRE} notation provides for both possibilities. The
@acronym{SRE}

@example
,exp
@end example

does not contribute its submatches to its containing regexp; it has
zero submatches. So one can reliably assign submatch indices to forms
appearing after a ,@emph{exp} form in a regexp.

On the other hand, the @acronym{SRE}

@example
,@@exp
@end example

``splices'' its resulting regexp into place, exposing its submatches
to the containing regexp. This is useful if the computed regexp is
defined to produce a certain number of submatches---if that is part of
@var{exp}'s ``contract''.

@subsubsection String and line units 
The regexps @code{bos} and @code{eos} match the empty string at the
beginning and end of the string, respectively.

The regexps @code{bol} and @code{eol} match the empty string at the
beginning and end of a line, respectively. A line begins at the
beginning of the string, and just after every newline character. A
line ends at the end of the string, and just before every newline
character. The character class @code{nonl} matches any character
except newline, and is useful in conjunction with line-based pattern
matching.

@emph{Note}: @code{bol} and @code{eol} are not supported by scsh's
current regexp search engine, which is Spencer's @acronym{POSIX}
matcher. This is the only element of the notation that is not
supported by the current scsh reference implementation.

@subsubsection @acronym{POSIX} string notation 

The @acronym{SRE} @code{(posix-string @var{string})}, where
@var{string} is a string literal (not a general Scheme expression),
allows one to use @acronym{POSIX} string notation for a regexp. It's
intended for backwards compatibility and is deprecated. For example,
@code{(posix-string "[aeiou]+|x*|y@{3,5@}")} matches a string of vowels,
a possibly empty string of x's, or three to five y's.

Note that parentheses are used ambiguously in @acronym{POSIX}
notation---both for grouping and submatch marking. The
@code{(posix-string @var{string})} form makes the conservative
assumption: all parentheses introduce submatches.

@subsubsection Deleted submatches 

Deleted submatches, or @acronym{DSM}s, are a subtle feature that are
never required in expressions written by humans. They can be
introduced by the simplifier when reducing regular expressions to
simpler equivalents, and are included in the syntax to give it
expressibility spanning the full regexp @acronym{ADT}. They may appear
when unparsing simplified regular expressions that have been run
through the simplifier; otherwise you are not likely to see them. Feel
free to skip this section.

The regexp simplifier can sometimes eliminate entire sub-expressions
froma regexp. For example, the regexp

@example
(: "foo" (** 0 0 "apple") "bar")
@end example

can be simplified to

@example
"foobar"
@end example

since @code{(** 0 0 "apple")} will always match the empty string. The
regexp

@example
(| "foo"
   (: "Richard" (|) "Nixon")
   "bar")
@end example

can be simplified to

@example
(| "foo" "bar").
@end example

The empty choice @code{(|)} can't match anything, so the whole

@example
(: "Richard" (|) "Nixon")
@end example

sequence can't match, and we can remove it from the choice.

However, if deleting part of a regular expression removes a submatch
form, any following submatch forms will have their numbering changed,
which would be an error. For example, if we simplify

@example
(: (** 0 0 (submatch "apple"))
   (submatch "bar"))
@end example

to

@example
(submatch "bar"),
@end example

then the @code{"bar"} submatch changes from submatch #2 to submatch
#1---so this is not a legal simplification.

When the simplifier deletes a sub-regexp that contains submatches, it
introduces a special regexp form to account for the missing, deleted
submatches, thus keeping the submatch accounting correct.

@example
(dsm @var{pre} @var{post} @var{sre} @dots{})
@end example

is a regexp that matches the sequence @code{(: @var{sre}
@dots{})}. @var{Pre} and @var{post} are integer constants. The
@acronym{DSM} form introduces @var{pre} deleted submatches before the
body, and @var{post} deleted submatches after the body. If the body
@code{(: @var{sre} @dots{})}  itself has @var{body-sm} submatches,
then the total number of submatches for the @acronym{DSM} form is
@var{pre} + @var{body-sm} + @var{post}.

These extra, deleted submatches are never assigned string indices in
any match values produced when matching the regexp against a string.

As examples,

@example
(| (: (submatch "Richard") (|) "Nixon")
   (submatch "bar"))
@end example

can be simplified to

@example
(dsm 1 0 (submatch "bar")).
@end example

The regexp

@example
(: (** 0 0 (submatch "apple"))
   (submatch "bar"))
@end example

can be simplified to

@example
(dsm 1 0 (submatch "bar")).
@end example

@anchor{Embedding regexps within Scheme programs}
@subsection Embedding regexps within Scheme programs

@acronym{SRE}s can be placed in a Scheme program using the @code{(rx
@var{sre} @dots{})} Scheme form, which evaluates to a Scheme regexp
value.

@subsubsection Static and dynamic regexps

We separate @acronym{SRE} expressions into two classes: static and
dynamic expressions. A @emph{static} expression is one that has no
run-time dependencies; it is a complete, self-contained description of
a regular set. A @emph{dynamic} expression is one that requires
run-time computation to determine the particular regular set being
described. There are two places where one can embed run-time
computations in an @acronym{SRE}:

@itemize
@item 
The @var{from} or @var{to} repetition counts of @code{**}, @code{=}, and @code{>=} forms

@item 
@var{,exp} and @var{,@@exp} forms
@end itemize

A static @acronym{SRE} is one that does not contain any @var{,exp} or
@var{,@@exp} forms, and whose @code{**}, @code{=}, and @code{>=} forms
all contain constant repetition counts.

Scsh's @code{rx} macro is able, at macro-expansion time, to completely
parse, simplify and translate any static @acronym{SRE} into the
equivalent @acronym{POSIX} string which is used to drive the
underlying C-based matching engine; there is no run-time
overhead. Dynamic @acronym{SRE}s are partially simplified and then
expanded into Scheme code that constructs the regexp at run-time.

@anchor{Regexp functions}
@section Regexp functions

@anchor{Obsolete, deprecated procedures}
@subsection Obsolete, deprecated procedures

These two procedures are survivors from the previous, now-obsolete
scsh regexp interface. Old code must open the @code{re-old-funs}
package to access them. They should not be used in new code.

@deffn Procedure string-match posix-re-string string [start]
@deffnx Procedure make-regexp posix-re-string

These are old functions included for backwards compatibility with
previous releases. They are deprecated and will go away at some point
in the future.

Note that the new release has no ``regexp compiling'' procedure at
all---regexp values are compiled for the matching engine on-demand,
and the necessary data structures are cached inside the @acronym{ADT}
values.
@end deffn

@anchor{Standard procedures and syntax}
@subsection Standard procedures and syntax

@deffn Syntax rx sre @dots{}

This allows you to describe a regexp value with @acronym{SRE}
notation.
@end deffn

@deffn Procedure regexp? x

Returns true if the value is a regular expression.
@end deffn

@deffn Procedure regexp-search re string [start flags]
@deffnx Procedure regexp-search? re string [start flags]

Search @var{string} starting at position @var{start}, looking for a
match for regexp @var{re}. If a match is found, return a match
structure describing the match, otherwise @code{#f}. @var{Start}
defaults to 0.

@var{Flags} is the bitwise-or of @code{regexp/bos-not-bol} and
@code{regexp/eos-not-eol}. @code{Regexp/bos-not-bol} means the
beginning of the string isn't a line-begin. @code{Regexp/eos-not-eol}
is analogous. @emph{Note}: They're currently ignored because
begining/end-of-line anchors aren't supported by the current
implementation.

Use @code{regexp-search?} when you don't need submatch information, as
it has the potential to be significantly faster on submatch-containing
regexps.

There is no longer a separate regexp ``compilation'' function; regexp
values are compiled for the C engine on demand, and the resulting C
structures are cached in the regexp structure after the first use.
@end deffn

@deffn Procedure match:start m [i]
@deffnx Procedure match:end m [i]
@deffnx Procedure match:substring m [i]

@code{Match:start} returns the start position of the submatch denoted
by @var{match-number}. The whole regexp is 0; positive integers index
submatches in the regexp, counting left to right. @var{Match-number}
defaults to 0.

If the regular expression matches as a whole, but a particular
sub-expression does not match, then @code{match:start} returns
@code{#f}.

@code{Match:end} is analogous to @code{match:start}, returning the end
position of the indexed submatch.

@code{Match:substring} returns the substring matched by the regexp's
submatch at index @var{i}. If there was no match for the indexed
submatch, it returns @code{#f}.
@end deffn

@deffn Procedure regexp-substitute port-or-false match [items]

This procedure can be used to perform string substitutions based
on regular-expression matches. The results of the substitution can be
either output to a port or returned as a string.

The @var{match} argument is a regular-expression match structure that
controls the substitution. If @var{port} is an output port, the items are
written out to the port:

@itemize
@item
If an item is a string, it is copied directly to the port.

@item
If an item is an integer, the corresponding submatch from @var{match}
is written to the port.

@item
If an item is @code{'pre}, the prefix of the matched string (the text
preceding the match) is written to the port.

@item
If an item is @code{'post}, the suffix of the matched string is
written.
@end itemize

If @var{port} is @code{#f}, nothing is written, and a string is
constructed and returned instead.

@end deffn

@deffn Procedure regexp-substitute/global port-or-false re str . items

This procedure is similar to @code{regexp-substitute}, but can be used
to perform repeated match/substitute operations over a string. It has
the following differences with @code{regexp-substitute}:

@itemize
@item It takes a regular expression and string to be matched as
parameters, instead of a completed match structure.
@item If the regular expression doesn't match the string, this procedure
is the identity transform---it returns or outputs the string.
@item If an item is @code{'post}, the procedure recurses on the suffix
string (the text from @var{string} following the match). Including a
@code{'post} in the list of items is how one gets multiple match/substitution operations.
@item If an item is a procedure, it is applied to the match structure
for a given match. The procedure returns a string to be used in the result.
@end itemize

The @var{regexp} parameter can be either a compiled regular expression
or a string specifying a regular expression.

Some examples:

@example
;;; Replace occurrences of "Cotton" with "Jin".
(regexp-substitute/global #f (rx "Cotton") s
                                          'pre "Jin" 'post)

;;; mm/dd/yy -> dd/mm/yy date conversion.
(regexp-substitute/global #f (rx (submatch (+ digit)) "/" ; 1 = M
                                                    (submatch (+ digit)) "/" ; 2 = D
                                                    (submatch (+ digit))) ; 3 = Y
                                           s ; Source string
          'pre 2 "/" 1 "/" 3 'post)

;;; "9/29/61" -> "Sep 29, 1961" date conversion.
(regexp-substitute/global #f (rx (submatch (+ digit)) "/" ; 1 = M
                                                    (submatch (+ digit)) "/" ; 2 = D
                                                    (submatch (+ digit))) ; 3 = Y
                                           s ; Source string
        'pre

;; Sleazy converter -- ignores "year 2000" issue,
;; and blows up if month is out of range.
        (lambda (m)
            (let ((mon (vector-ref '#("Jan" "Feb" "Mar" "Apr" "May" "Jun"
                                                  "Jul" "Aug" "Sep" "Oct" "Nov" "Dec")
                                             (- (string->number (match:substring m 1)) 1)))
                   (day (match:substring m 2))
                   (year (match:substring m 3)))
               (string-append mon " " day ", 19" year)))
        'post)

;;; Remove potentially offensive substrings from string S.
(define (kill-matches re s)
   (regexp-substitute/global #f re s 'pre 'post))

(kill-matches (rx (| "Windows" "tcl" "Intel")) s)   ; Protect the children.
@end example
@end deffn

@deffn Procedure regexp-fold re kons knil s [finish start]

The following definition is a bit unwieldy, but the intuition is simple:
this procedure uses the regexp @var{re} to divide up string @var{s} into
non-matching/matching chunks, and then ``folds'' the procedure
@var{kons} across this sequence of chunks. It is useful when you wish to
operate on a string in sub-units defined by some regular expression, as
are the related @code{regexp-fold-right} and @code{regexp-for-each}
procedures.

Search from @var{start} (defaulting to 0) for a match to @var{re}; call
this match @var{m}. Let @var{i} be the index of the end of the match
(that is, @code{(match:end m 0)}). Loop as follows:

@example
(regexp-fold re kons (kons start m knil) s finish i)
@end example

If there is no match, return instead

@example
(finish start knil)
@end example

@var{Finish} defaults to

@example
(lambda (i knil) knil).
@end example

In other words, we divide up @var{s} into a sequence of
non-matching/matching chunks:

@math{NM_1 M_1 NM_2 M_2 @dots{} NM_k-1 M_k-1 NM_k}

where @math{NM_1} is the initial part of @var{s} that isn't matched by
the regexp @var{re}, @math{M_1} is the first match, @math{NM_2} is the
following part of @var{s} that isn't matched, @math{M_2} is the second
match, and so forth---@math{NM_k} is the final non-matching chunk of
@var{s}. We apply @var{kons} from left to right to build up a result,
passing it one non-matching/matching chunk each time: on an application
@code{(kons i m knil)}, the non-matching chunk goes from @var{i} to
@code{(match:begin @var{m} 0)}, and the following matching chunk goes
from @code{(match:begin @var{m} 0)} to @code{(match:end @var{m} 0)}. The
last non-matching chunk @math{NM_k} is processed by @var{k}. So the
computation we perform is @c TODO: Does K mean KONS?

@example
(final @math{Q} (@var{kons} @math{J_k} @math{M_k} @dots{} (@var{kons} @math{J_1} @math{M_1} @var{knil}) @dots{}))
@end example

where @math{J_i} is the index of the start of @math{NM_i}, @math{M_i} is
a match value describing @math{M_i}, and @math{Q} is the index of the
beginning of @math{NM_k}.

@emph{Hint}: The @code{let-match} macro is frequently useful for
operating on the match value @math{M} passed to the @var{kons} function.
@end deffn

@deffn Procedure regexp-fold-right re kons knil s [finish start]

The right-to-left variant of @code{regexp-fold}.

This procedure repeatedly matches regexp @var{re} across string
@var{s}. This divides @var{s} up into a sequence of matching/non-matching chunks:

@math{NM_1} @math{M_1} @math{NM_1} @math{M_2} @dots{} @math{NM_k-1} @math{M_k-1} @math{NM_k}

where @math{NM_1} is the initial part of @var{s} that isn't matched by
the regexp @var{re}, @math{M_1} is the first match, @math{NM_2} is the
following part of @var{s} that isn't matched, @math{M_2} is the second
match, and so forth---@math{NM_k} is the final non-matching chunkof
@var{s}. We apply @var{kons} from right to left to build up a result,
passing it one non-matching/matching chunk each time:

@example
(final Q (kons @math{M_1} @math{J_1} @dots{} (kons @math{M_k} @math{J_k} knil) ...))
@end example

where @math{MATCH_i} is a match value describing @math{M_i}, @math{J_i}
is the index of the endof @math{NM_i} (or, equivalently, the beginning
of @math{M_i+1}), and Q is the index of the beginning of @math{M_1}. In
other words, @var{kons} is passed a match, an index describing the
following non-matching text, and the value produced by folding the
following text. The @var{final} function ``polishes off'' the fold
operation by handling the initial chunk of non-matching text
(@math{NM_0}, above).  @var{Finish} defaults to @code{(lambda (i knil)
knil)}.

Example: To pick out all the matches to @var{re} in @var{s}, say

@example
(regexp-fold-right re
    (lambda (m i lis)
        (cons (match:substring m 0) lis))
    '() s)
@end example

@emph{Hint}: The @code{let-match} macro is frequently useful for
operating on the match value @var{m} passed to the @var{kons} function.
@end deffn

@deffn Procedure regexp-for-each re proc s [start]

Repeatedly match regexp @var{re} against string @var{s}. Apply
@var{proc} to each match that is produced. Matches do not overlap.

@emph{Hint}: The @code{let-match} macro is frequently useful for
operating on the match value @var{m} passed to @var{proc}.
@end deffn

@deffn Syntax let-match match-exp mvars body @dots{}
@deffnx Syntax if-match match-exp mvars on-match no-match

@var{Mvars} is a list of vars that is bound to the match and
submatches of the string; @code{#f} is allowed as a don't-care
element. For example,

@example
(let-match (regexp-search date s) (whole-date month day year)
   @dots{} body @dots{})
@end example

matches the regexp against string @var{s}, then evaluates the body of
the @code{let-match} in a scope where @code{whole-date} is bound to
the matched string, and @code{month}, @code{day} and @code{year} are
bound to the first, second and third sub-matches.

@code{If-match} is similar, but if the match expression is false, then
the @var{no-match} expression is evaluated; this would be an error in
@code{let-match}.
@end deffn

@deffn Syntax match-cond clause @dots{}

This macro allows one to conditionally attempt a sequence of pattern
matches, interspersed with other, general conditional tests. There are
four kinds of @code{match-cond} clause, one introducing a pattern
match, and the other three simply being regular @code{cond}-style
clauses, marked by the @code{test} and @code{else} keywords:

@example
(match-cond (match-exp match-vars body @dots{}) ; As in if-match
            (test exp body @dots{})             ; As in cond
            (test exp => proc)                 ; As in cond
            (else body @dots{}))                ; As in cond
@end example
@end deffn

@deffn Procedure flush-submatches re
@deffnx Procedure uncase re
@deffnx Procedure simplify-regexp re
@deffnx Procedure uncase-char-set cset
@deffnx Procedure uncase-string str

These functions map regexps and char sets to other regexps.
@code{Flush-submatches} returns a regexp which matches exactly what
its argument matches, but contains no submatches.

@code{Uncase} returns a regexp that matches any case-permutation of
its argument regexp.

@code{Simplify-regexp} applies the simplifier to its argument. This is
done automatically when compiling regular expressions, so this is only
useful for programmers that are directly examining the @acronym{ADT}
value with lower-level accessors.

@code{Uncase-char-set} maps a char set to a regular expression that
matches any character from that set, regardless of case. Similarly,
@code{uncase-string} returns a regexp that matches any
case-permutation of the string. For example, @code{(uncase-string
"Knight")} returns the same value as @code{(rx ("kK") ("nN") ("iI")
("gG") ("hH") ("tT"))} or @code{(rx (w/nocase "Knight"))}.
@end deffn

@deffn Procedure sre->regexp sre
@deffnx Procedure regexp->sre re

These are the @acronym{SRE} parser and unparser. That is,
@code{sre->regexp} maps an @acronym{SRE} to a regexp value, and
@code{regexp->sre} does the inverse. The latter function can be useful
for printing out regexps in a readable format.

@example
(sre->regexp '(: "Olin " (? "G. ") "Shivers"))
   ==> regexp

(define re (re-seq (re-string "Pete ")
                   (re-repeat 1 #f (re-string "Sz"))
                   (re-string "ilagyi")))

(regexp->sre (re-repeat 0 1 re))
   ==> '(? "Pete" (+ "Sz") "ilagyi")
@end example
@end deffn

@deffn Procedure posix-string->regexp string
@deffnx Procedure regexp->posix-string re

These two functions are the @acronym{POSIX} notation parser and
unparser. That is, @code{posix-string->regexp} maps a
@acronym{POSIX}-notation regular expression, such as
@code{"g(ee|oo)se"}, to a regexp value, and
@code{regexp->posix-string} does the inverse.

You can use these tools to map between scsh regexps and
@acronym{POSIX} regexp strings, which can be useful if you want to do
conversion between @acronym{SRE}s and @acronym{POSIX} form. For
example, you can write a particularly complex regexp in @acronym{SRE}
form, or compute it using the @acronym{ADT} constructors, then convert
to @acronym{POSIX} form, print it out, cut and paste it into a C or
Emacs Lisp program. Or you can import an old regexp from some other
program, parse it into an @acronym{ADT} value, render it to an
@acronym{SRE}, print it out, then cut and paste it into a scsh
program.

@emph{Note}: The string parser doesn't handle the exotica of character
class names such as @code{[[:alnum:]]}; the current implementation was
written in in three hours.
@end deffn

@anchor{The regexp @acronym{ADT}}
@section The regexp @acronym{ADT}

The following functions may be used to construct and examine scsh's
regexp abstract data type. They are in the following Scheme 48 packages:

@itemize
@item re-adt-lib
@item re-lib scsh
@end itemize

Each basic class of regexp has a predicate, a basic constructor, a
``smart'' consructor that performs limited ``peephole'' optimisation on
its arguments, and a set of accessors. The @code{@dots{}:tsm} accessor
returns the total number of sub-matches contained in the regular
expression.

@multitable @columnfractions .33 .33 .33
@headitem Procedure
@tab Returns
@tab Is of Type

@item @code{(re-seq? @var{x})}
@tab boolean 
@tab Type predicate

@item @code{(make-re-seq @var{re-list})}
@tab re
@tab Basic constructor

@item @code{(re-seq @var{re-list})}
@tab re
@tab Smart constructor

@item @code{(re-seq:elts @var{re})}
@tab re-list
@tab Accessor

@item @code{(re-seq:tsm @var{re})}
@tab integer
@tab Accessor

@item @code{(re-choice? @var{x})}
@tab boolean
@tab Type predicate

@item @code{(make-re-choice @var{re-list})}
@tab re
@tab Basic constructor

@item @code{(re-choice @var{re-list})}
@tab re
@tab Smart constructor

@item @code{(re-choice:elts @var{re})}
@tab re-list
@tab Accessor

@item @code{(re-choice:tsm @var{re})}
@tab integer
@tab Accessor

@item @code{(re-repeat? @var{x})}
@tab boolean
@tab Type predicate

@item @code{(make-re-repeat @var{from} @var{to} @var{body})}
@tab re
@tab Accessor

@item @code{(re-repeat:from @var{re})}
@tab integer
@tab Accessor

@item @code{(re-repeat:to @var{re})}
@tab integer
@tab Accessor

@item @code{(re-repeat:tsm @var{re})}
@tab integer
@tab Accessor

@item @code{(re-submatch? @var{x})}
@tab boolean
@tab Type predicate

@item @code{(make-re-submatch @var{body} [@var{pre-dsm post-dsm}])}
@tab re
@tab Accessor

@item @code{(re-submatch:pre-dsm @var{re})}
@tab integer
@tab Accessor

@item @code{(re-submatch:post-dsm @var{re})}
@tab integer
@tab Accessor

@item @code{(re-submatch:tsm @var{re})}
@tab integer
@tab Accessor

@item @code{(re-string? @var{x})}
@tab boolean
@tab Type predicate

@item @code{(make-re-string @var{chars})}
@tab re
@tab Basic constructor

@item @code{(re-string @var{chars})}
@tab re
@tab Basic constructor

@item @code{(re-string:chars @var{re})}
@tab string
@tab Accessor

@item @code{(re-char-set? @var{x})}
@tab boolean
@tab Type predicate

@item @code{(make-re-char-set @var{cset})}
@tab re
@tab Basic constructor

@item @code{(re-char-set @var{cset})}
@tab re
@tab Basic constructor

@item @code{(re-char-set:cset @var{re})}
@tab char-set
@tab Accessor

@item @code{(re-dsm? @var{x})}
@tab boolean
@tab Type predicate

@item @code{(make-re-dsm @var{body} @var{pre-dsm} @var{post-dsm})}
@tab re
@tab Basic constructor

@item @code{(re-dsm @var{body} @var{pre-dsm} @var{post-dsm})}
@tab re
@tab Smart constructor

@item @code{(re-dsm:body @var{re})}
@tab re
@tab Accessor

@item @code{(re-dsm:pre-dsm @var{re})}
@tab integer
@tab Accessor

@item @code{(re-dsm:post-dsm @var{re})}
@tab integer
@tab Accessor

@item @code{(re-dsm:tsm @var{re})}
@tab integer
@tab Accessor
@end multitable

@deffn Variable re-bos
@deffnx Variable re-eos
@deffnx Variable re-bol
@deffnx Variable re-eol

These variables are bound to the primitive anchor regexps.
@end deffn

@deffn Procedure re-bos? object
@deffnx Procedure re-eos? object
@deffnx Procedure re-bol? object
@deffnx Procedure re-eol? object

These predicates recognise the associated primitive anchor regexp.
@end deffn

@deffn Variable re-trivial
@deffnx Procedure re-trivial? re

The variable @code{re-trivial} is bound to a regular expression that
matches the empty string (corresponding to the @acronym{SRE} @code{""}
or @code{(:)}); it is recognised by the associated predicate. Note that
the predicate is only guaranteed to recognise this particular trivial
regexp; other trivial regexps built using other constructors may or may
not produce a true value.
@end deffn

@deffn Variable re-empty
@deffnx Procedure re-empty? re

The variable @code{re-empty} is bound to a regular expression that never
matches (corresponding to the @acronym{SRE} @code{(|)}); it is
recognised by the associated predicate. Note that the predicate is only
guaranteed to recognise this particular empty regexp; other empty
regexps built using other constructors may or may not produce a true
value.
@end deffn

@deffn Variable re-any
@deffnx Procedure re-any? re

The variable re-any is bound to a regular expression that matches
anycharacter (corresponding to the @acronym{SRE} @code{any}); it is
recognised by the associated predicate. Note that the predicate is only
guaranteed to recognise this particular any-character regexp value;
other any-character regexps built using other constructors may or may
not produce a true value.
@end deffn

@deffn Variable re-nonl

The variable @code{re-nonl} is bound to a regular expression that
matches any non-newline character (corresponding to the @acronym{SRE}
@code{(~ #\newline)}).
@end deffn

@deffn Procedure regexp? object

Is the object a regexp?
@end deffn

@deffn Procedure re-tsm re

Return the total number of submatches contained in the regexp.
@end deffn

@deffn Procedure clean-up-cres

The current scsh implementation should call this function periodically
to release C-heap storage associated with compiled regexps. Hopefully,
this procedure will be removed at a later date.
@end deffn

@anchor{Syntax-hacking tools}
@section Syntax-hacking tools

The Scheme 48 package @code{sre-syntax-tools} exports several tools for
macro writers who want to use @acronym{SRE}s in their macros. In the
functions defined below, @var{compare} and @var{rename} parameters are
as passed to Clinger-Rees explicit-renaming low-level macros.

@deffn Syntax if-sre-form form conseq-form alt-form

If @var{form} is a legal @acronym{SRE}, this is equivalent to the
expression @var{conseq-form}, otherwise it expands to @var{alt-form}.

This is useful for high-level macro authors who want to write a macro
where one field in the macro can be an @acronym{SRE} or possibly
something else.  For example, we might have a conditional form wherein
if the test part of one arm is an @acronym{SRE}, it expands to a regexp
match on some implied value, otherwise the form is evaluated as a
boolean Scheme expression. For example, a conditional macro might expand
into code containing the following form, which in turn would have one of
two possible expansions:

@example
(if-sre-form test-exp                  ; If TEST-EXP is @acronym{SRE},
   (regexp-search? (rx test-exp) line) ; match it w/the line,
   test-exp)                           ; otw it's a text exp.
@end example
@end deffn

@deffn Procedure sre-form? form rename compare

This procedure is for low-level macros doing things equivalent to
@code{if-sre-form}. It returns true if the form is a legal
@acronym{SRE}.

Note that neither @code{sre-form} nor @code{if-sre-form} does a deep
recursion over the form in the case where the form is a list. They
simply check the @code{car} of the form for one of the legal
@acronym{SRE} keywords.
@end deffn

@deffn Procedure parse-sre sre-form compare rename
@deffnx Procedure parse-sres sre-forms compare rename

Parse @var{sre-form} into an @acronym{ADT}. Note that if the
@acronym{SRE} is dynamic---contains @var{,exp} or @var{,@@exp} forms, or
has repeat operators whose from/to counts are not constants---then the
returned @acronym{ADT} will have Scheme expressions in the corresponding
slots of the regexp records instead of the corresponding integer,
char-set, or regexp. In other words, we use the @acronym{ADT} as its own
@acronym{AST}. It's called a "hack."

@code{Parse-sres} parses a list of @acronym{SRE} forms that comprise an
implicit sequence.
@end deffn

@deffn Procedure regexp->scheme re rename

Returns a Scheme expression that will construct the regexp @var{re}
using @acronym{ADT} constructors such as @code{make-re-sequence},
@code{make-re-repeat}, and so forth. If the regexp is static, it will be
simplified and pre-translated to a @acronym{POSIX} string as well, which
will be part of the constructed regexp value.
@end deffn

@deffn Procedure static-regexp? re

Is the regexp a static one?
@end deffn

@node Reading delimited strings, Awk record I/O and field parsing, Pattern-matching strings with regular expressions, Top
@chapter Reading delimited strings

Scsh provides a set of procedures that read delimited strings from
input ports. There are procedures to read a single line of text
(terminated by a newline character), a single paragraph (terminated by
a blank line), and general delimited strings (terminated by a
character belonging to an arbitrary character set).

These procedures can be applied to any Scheme input port. However, the
scsh virtual machine has native-code support for performing delimited
reads on UNIX ports, and these input operations should be particularly
fast---much faster than doing the equivalent character-at-a-time
operation from Scheme code.

All of the delimited input operations described below take a
@code{handle-delim} parameter, which determines what the procedure does
with the terminating delimiter character. There are four possible
choices for a @code{handle-delim} parameter:

@multitable @columnfractions .50 .50
@headitem @code{handle-delim}
@tab Meaning

@item @code{'trim}
@tab Ignore delimiter character.

@item @code{'peek}
@tab Leave delimiter character in input stream.

@item @code{'concat}
@tab Append delimiter character to returned value.
@item 'split 
@tab Return delimiter as second value.
@end multitable

The first case, @code{'trim}, is the standard default for all the
routines described in this section. The last three cases allow the
programmer to distinguish between strings that are terminated by a
delimiter character, and strings that are terminated by an
end-of-file.

@deffn Procedure read-line [port handle-newline]

Reads and returns one line of text; on @acronym{eof}, returns the
@acronym{eof} object. A line is terminated by newline or
@acronym{eof}.

@var{Handle-newline} determines what @code{read-line} does with the
newline or @acronym{eof} that terminates the line; it takes the
general set of values described for the general @code{handle-delim}
case above, and defaults to @code{'trim} (discard the newline). Using
this argument allows one to tell whether or not the last line of input
in a file is newline-terminated.
@end deffn

@deffn Procedure read-paragraph [port handle-delim]

This procedure skips blank lines, then reads text from a port until a
blank line or @acronym{eof} is found. A "blank line" is a (possibly
empty) line composed only of white space. The @var{handle-delim}
parameter determines how the terminating blank line is handled. It is
described above, and defaults to @code{'trim}. The @code{'peek} option
is not available.
@end deffn

The following procedures read in strings from ports delimited by
characters belonging to a specific set. For information on character
set manipulation, @xref{Deprecated character-set procedures}.

@deffn Procedure read-delimited char-set [port handle-delim]

Read until we encounter one of the chars in @var{char-set} or
@acronym{eof}. The @var{handle-delim} parameter determines how the
terminating character is handled. It is described above, and defaults
to @code{'trim}.

The @var{char-set} argument may be a charset, a string, or a
character; it is coerced to a charset.
@end deffn

@deffn Procedure read-delimited! char-set buf [port handle-delim start end]

A side-effecting variant of @code{read-delimited}.

The data is written into the string @code{buf} at the indices in the
half-open interval [@var{start}, @var{end}]. The default interval is
the whole string, such that @var{start} is equal to @code{0} and
@var{end} is equal to @code{(string-length @var{buf})}. The values of
@var{start} and @var{end} must specify a well-defined interval in
@var{buf}, @emph{i.e.}, 0 @math{<=} @var{start} <= @var{end} <=
@code{(string-length @var{buf})}.

It returns @var{nbytes}, the number of bytes read. If the buffer
filled up without a delimiter character being found, @code{#f} is
returned. If the port is at @acronym{eof} when the read starts, the
@acronym{eof} object is returned.

If an integer is returned (@emph{i.e.}, the read is successfully terminated
by reading a delimiter character), then the @var{handle-delim} parameter
determines how the terminating character is handled. It is described
above, and defaults to @code{'trim}.
@end deffn

@deffn Procedure %read-delimited! char-set buf gobble? [port start end]

This low-level delimited reader uses an alternate interface. It
returns two values: @var{terminator} and @var{num-read}.

@itemize
@item @var{terminator}
A value describing why the read was terminated. If the buffer was
filled without finding a delimiter, return @code{#f}. Otherwise,
return the character or @acronym{eof} object that terminated the read.

@item @var{num-read}
Number of characters read into @var{buf}.
@end itemize

If the read is successfully terminated by reading a delimiter
character, then the @var{gobble?} parameter determines what to do with
the terminating character. If true, the character is removed from the
input stream; if false, the character is left in the input stream
where a subsequent read operation will retrieve it. In either case,
the character is also the first value returned by the procedure call.
@end deffn

@deffn Procedure skip-char-set skip-chars [port]

Skip characters occurring in the set @var{skip-chars}; return the
number of characters skipped. The @var{skip-chars} argument may be a
charset, a string, or a character; it is coerced to a charset.
@end deffn

@node Awk record I/O and field parsing, Concurrent system programming, Reading delimited strings, Top
@chapter Awk record I/O and field parsing

UNIX programs frequently process streams of records, where each record
is delimited by a newline, and records are broken into fields with
other delimiters (for example, the colon character in
@code{/etc/passwd}). Scsh has procedures that allow the programmer to
easily do this kind of processing. Scsh's field parsers can also be
used to parse other kinds of delimited strings, such as
colon-separated @code{$PATH} lists. These routines can be used with
scsh's awk loop construct to conveniently perform pattern-directed
computation over streams of records.

@anchor{Record I/O and field parsing}
@section Record I/O and field parsing

The procedures in this section are used to read records from I/O
streams and parse them into fields. A record is defined as text
terminated by some delimiter (usually a newline). A record can be
split into fields by using regular expressions in one of several ways:
to @emph{match} fields, to @emph{separate} fields, or to
@emph{terminate} fields. The field parsers can be applied to arbitrary
strings (one common use is splitting environment variables such as
@emph{$PATH} at colons into its component elements).

The general delimited-input procedures described in @ref{Reading
delimited strings} are also useful for reading simple records, such as
single lines, paragraphs of text, or strings terminated by specific
characters.

@anchor{Reading records}
@subsection Reading records

@deffn Procedure record-reader [delims elide-delims? handle-delim])

Returns a procedure that reads records from a port. The procedure
is invoked as follows:

@example
(@var{reader} [@var{port}])
@end example

A record is a sequence of characters terminated by one of the
characters in @var{delims} or @acronym{eof}. If @var{elide-delims?}
is true, then a contiguous sequence of delimiter chars are taken as a
single record delimiter. If @var{elide-delims?} is false, then a
delimiter char coming immediately after a delimiter char produces an
empty-string record. The reader consumes the delimiting char(s) before
returning from a read.

The @var{delims} set defaults to the set @{newline@}. It may be a
charset, string, character, or character predicate, and is coerced to
a charset. The @var{elide-delims?} flag defaults to #f. The
@var{handle-delim} argument controls what is done with the record's
terminating delimiter.

@table @code
@item 'trim 
Delimiters are trimmed. (The default.)

@item 'split 
Reader returns delimiter string as a second argument. If record is
terminated by @acronym{eof}, then the @acronym{eof} object isreturned
as this second argument.

@item 'concat
The record and its delimiter are returned as a single string.
@end table

The reader procedure returned takes one optional argument, the port
from which to read, which defaults to the current input port. It
returns a string or @acronym{eof}.
@end deffn

@anchor{Parsing fields}
@subsection Parsing fields

@deffn Procedure field-splitter [field num-fields])
@deffnx Procedure infix-splitter [delim num-fields handle-delim])
@deffnx Procedure suffix-splitter [delim num-fields handle-delim])
@deffnx Procedure sloppy-suffix-splitter [delim num-fields handle-delim])

These functions return a parser function that can be used as follows:

@example
(@var{parser} @var{string} [@var{start}])
@end example

The returned parsers split strings into fields defined by regular
expressions. You can parse by specifying a pattern that
@emph{separates} fields, a pattern that @emph{terminates} fields, or a
pattern that @emph{matches} fields:

@multitable @columnfractions .50 .50
@headitem Procedure 
@tab Pattern

@item @code{field-splitter}
@tab matches fields

@item @code{infix-splitter}
@tab separates fields

@item @code{suffix-splitter}
@tab terminates fields

@item @code{sloppy-suffix-splitter}
@tab terminates fields
@end multitable

These parser generators are controlled by a range of options, so that
you can precisely specify what kind of parsing you want. However,
these options default to reasonable values for general use:

@multitable @columnfractions .33 .33 .33
@headitem Option
@tab Default
@tab Description

@item @var{delim}
@tab @code{(rx (| (+ white) eos))}
@tab suffix delimiter: white space or eos

@item 
@tab @code{(rx (+ white))}
@tab infix delimiter: white space

@item @var{field}
@tab @code{(rx (+ (~ white)))}
@tab non-white-space

@item @var{num-fields}
@tab @code{#f}
@tab as many fields as possible

@item @var{handle-delim}
@tab @code{'trim }
@tab discard delimiter chars, which means: break the string at white space, discarding the white space, and parse as many fields as possible.
@end multitable

The @var{delim} parameter is a regular expression matching the text
that occurs between fields. For information on regular expressions,
and the @code{rx} form used to specify them, @xref{Pattern-matching
strings with regular expressions}. In the separator case, it defaults
to a pattern matching whitespace; in the terminator case, it defaults
to whitespace or the end of the string.

The @var{field} parameter is a regular expression used to match
fields. It defaults to non-whitespace.

The @var{delim} patterns may also be given as a string, character, or
char-set; these are coerced to regular expressions. This means that
the following expressions are equivalent, each producing a function
that splits strings apart at colons:

@example
(infix-splitter (rx ":"))
(infix-splitter ":")
(infix-splitter #\:)
(infix-splitter (char-set #\:))
@end example

The boolean @var{handle-delim} determines what to do with delimiters:

@table @code
@item 'trim 
Delimiters are thrown away after parsing (default).

@item 'concat 
Delimiters are appended to the field preceding them.

@item 'split 
Delimiters are returned as separate elements in the field list.
@end table

The @var{num-fields} argument used to create the parser specifies how
many fields to parse. If @code{#f} (the default), the procedure parses
them all. If a positive integer @math{n}, exactly that many fields are
parsed; it is an error if there are more or fewer than @math{n} fields
in the record. If @var{num-fields} is a negative integer or zero, then
@math{|n|} fields are parsed, and the remainder of the string is
returned in the last element of the field list; it is an error if
fewer than @math{|n|} fields can be parsed.

The field parser produced is a procedure that can be employed as
follows:

@example
(@var{parse} @var{string} [@var{start}])
@end example

The optional @var{start} argument (default 0) specifies where in the
string to begin the parse. It is an error if @var{start} @math{>}
@code{(string-length @var{string})}.

The parsers returned by the four parser generators implement different
kinds of field parsing:

@table @code
@item field-splitter
The regular expression specifies the actual field.

@item suffix-splitter
Delimiters are interpreted as element @emph{terminators}. If the
vertical bar character is the delimiter, then the string @code{""} is
the empty record @code{()}, @code{"foo|"} produces a one-field record
@code{("foo")}, and @code{"foo"} returns an error.

The syntax of suffix-delimited records is:

@example
@emph{<record>} ::= "" (Empty record)
                | @emph{<element>} @emph{<delim>} @emph{<record>}
@end example

It is an error if a non-empty record does not end with a delimiter. To
make the last delimiter optional, make sure the delimiter regexp
matches the end of the string (@acronym{SRE} notation: @code{eos}).

@item infix-splitter

Delimiters are interpreted as element @emph{separators}. If comma is
the delimiter, then the string @code{"foo,"} produces a two-field
record @code{("foo" "")}.

The syntax of infix-delimited records is:

@example
@emph{<record>} ::= "" (Forced to be empty record)
                | @emph{<real-infix-record>}
@emph{<real-infix-record>} ::= @emph{<element>} @emph{<delim>} @emph{<real-infix-record>}
                | @emph{<element>}
@end example

Note that separator semantics doesn't really allow for empty
records---the straightforward grammar (i.e.,
@emph{<real-infix-record>}) parses an empty string as a singleton list
whose one field is the empty string, @code{("")}, not as the empty
record @code{()}. This is unfortunate, since it means that infix
string parsing doesn't make @code{string-append} and @code{append}
isomorphic. For example,

@example
((infix-splitter ":") (string-append x ":" y))
@end example

doesn't always equal

@example
(append ((infix-splitter ":") x)
        ((infix-splitter ":") y))
@end example

It fails when @code{x} or @code{y} are the empty string. Terminator
semantics does preserve a similar isomorphism.  However, separator
semantics is frequently what other UNIX software uses, so to parse
their strings, we need to use it. For example, UNIX @code{$PATH} lists
have separator semantics. The path list @code{"/bin:"} is broken up
into @code{("/bin" "")}, not @code{("/bin")}. Comma-separated lists
should also be parsed this way.

@item sloppy-suffix 

The same as the @code{suffix} case, except that the parser will skip an
initial delimiter string if the string begins with one instead of
parsing an initial empty field. This can be used, for example, to
field-split a sequence of English text at whitespace boundaries, where
the string may begin or end with white space, by using the regexp

@example
(rx (| (+ white) eos))
@end example

(But you would be better off using @code{field-splitter} in this case.)
@end table
@end deffn

This figure shows how the different parser grammars split apart the same
strings.

@example
Record          : suffix        :|$ suffix      : infix         non-: field
""              ()              ()              ()              ()
":"             ("")            ("")            ("" "")         ()
"foo:"          ("foo")         ("foo")         ("foo" "")      ("foo")
":foo"          error           ("" "foo")      ("" "foo")      ("foo")
"foo:bar"       error           ("foo" "bar")   ("foo" "bar")   ("foo" "bar")
@end example

@anchor{Figure 6}

@emph{Figure 6}: Using different grammars to split records into fields.

Having to choose between the different grammars requires you to decide
what you want, but at least you can be precise about what you are
parsing. Take fifteen seconds and think it out. Say what you mean;
mean what you say.

@deffn Procedure join-strings string-list [delimiter grammar]

This procedure is a simple unparser---it pastes strings together using
the delimiter string.

The @var{grammar} argument is one of the symbols @code{infix} (the default)
or @code{suffix}; it determines whether the delimiter string is used
as a separator or as a terminator.

The @var{delimiter} is the string used to delimit elements; it
defaults to a single space @code{" "}.

Example:
@example
(join-strings '("foo" "bar" "baz") ":")

==> "foo:bar:baz"
@end example
@end deffn

@anchor{Field readers}
@subsection Field readers

@deffn Procedure field-reader [field-parser rec-reader]

This utility returns a procedure that reads records with field
structure from a port. The reader's interface is designed to make it
useful in the @code{awk} loop macro. (@xref{Awk}.) The reader is used
as follows:

@example
(@var{reader} [@var{port}])

==> [@var{raw-record} @var{parsed-record}]
or
==> [@acronym{eof}]
@end example

When the reader is applied to an input port (default: the current
inputport), it reads a record using @var{rec-reader}. If this record
isn't the @acronym{eof} object, it is parsed with
@var{field-parser}. These two values---the record, and its parsed
representation---are returned as multiple values from the reader.

When called at @acronym{eof}, the reader returns the @acronym{eof} object.

Although the record reader typically returns a string, and the
field-parser typically takes a string argument, this is not
required. The record reader can produce, and the field-parser consume,
values of any type. However, the empty list returned as the parsed
value on @acronym{eof} is hardwired into the field reader.

For example, if port @code{p} is open on @code{/etc/passwd}, then

@example
((field-reader (infix-splitter ":" 7)) p)
@end example

returns two values:

@example
"dalbertz:mx3Uaqq0:107:22:David Albertz:/users/dalbertz:/bin/csh"

("dalbertz" "mx3Uaqq0" "107" "22" "David Albertz" "/users/dalbertz" "/bin/csh")
@end example

The @var{field-parser} defaults to the value of
@code{(field-splitter)}, a parser that picks out sequences of
non-whitespace strings.

The @var{rec-reader} defaults to @code{read-line}.

This figure shows @code{field-reader} being used to read different kinds of UNIX records.

@anchor{Figure 7}

@example
;;; /etc/passwd reader
(field-reader (infix-splitter ":" 7))

; wandy:3xuncWdpKhR.:73:22:Wandy Saetan:/usr/wandy:/bin/csh

;;; Two ls -l output readers
(field-reader (infix-splitter (rx (+ white)) 8))
(field-reader (infix-splitter (rx (+ white)) -7))

; -rw-r--r-- 1 shivers 22880 Sep 24 12:45 scsh.scm

;;; Internet hostname reader
(field-reader (field-splitter (rx (+ (~ ".")))))

; stat.sinica.edu.tw

;;; Internet IP address reader
(field-reader (field-splitter (rx (+ (~ "."))) 4))

; 18.24.0.241

;;; Line of integers
(let ((parser (field-splitter (rx (? ("+-")) (+ digit)))))
   (field-reader (* (s) (map string->number (parser s))))

; 18 24 0 241

;;; Same as above.
(let ((reader (field-reader (field-splitter (rx (? ("+-"))
                                              (+ digit))))))
    (lambda maybe-port (map string->number (apply reader maybe-port))))

; Yale beat harvard 26 to 7.
@end example

@emph{Figure 7}: Some examples of @code{field-reader}.
@end deffn

@anchor{Forward-progress guarantees and empty-string matches}
@subsection Forward-progress guarantees and empty-string matches

A loop that pulls text off a string by repeatedly matching a regexp
against that string can conceivably get stuck in an infinite loop if
the regexp matches the empty string. For example, the @acronym{SRE}s
@code{bos}, @code{eos}, @code{(* any)}, and @code{(| "foo" (* ("f")))}
can all match the empty string.

The routines in this package that iterate through strings with regular
expressions are careful to handle this empty-string case. If a regexp
matches the empty string, the next search starts, not from the end of
the match (which inthe empty string case is also the
beginning---that's the problem), but from the next character
over. This is the correct behaviour. Regexps match the longest
possible string at a given location, so if the regexp matched the
empty string at location @var{i}, then it is guaranteed it could not
have matched a longer pattern starting with character @var{i}. So we
can safely begin our search for the next match at char @var{i} + 1.

With this provision, every iteration through the loop makes some
forward progress, and the loop is guaranteed to terminate.

This has the effect you want with field parsing. For example, if you
split a string with the empty pattern, you will explode the string
into its individual characters:

@example
((suffix-splitter (rx)) "foo") =) ("" "f" "o" "o")
@end example

However, even though this boundary case is handled correctly, we don't
recommend using it. Say what you mean---just use a field splitter:

@example
((field-splitter (rx any)) "foo") =) ("f" "o" "o")
@end example

Or, more efficiently,

@example
((* (s) (map string (string->list s))) "foo")
@end example

@anchor{Reader limitations}
@subsection Reader limitations

Since all of the readers in this package require the ability to peek
ahead one char in the input stream, they cannot be applied to raw
integer file descriptors, only Scheme input ports. This is because
UNIX doesn't support peeking ahead into input streams.
     
@anchor{Awk}
@section Awk

Scsh provides a loop macro and a set of field parsers that can be used
to perform text processing very similar to the Awk programming
language. The basic functionality of Awk is factored in scsh into its
component parts. The control structure is provided by the @code{awk}
loop macro; the text I/O and parsers are provided by the field-reader
subroutine library (@xref{Record I/O and field parsing}.) This factoring
allows the programmer to compose the basic loop structure with any
parser or input mechanism at all. If the parsers provided by the
field-reader package are insufficient, the programmer can write a custom
parser in Scheme and use it with equal ease in the awk framework.

Awk-in-scheme is given by a loop macro called @code{awk}. It looks like
this:

@verbatim
    (awk <next-record> <record&field-vars>
           [<counter>] <state-var-decls>
         <clause1> ...)
@end verbatim

The body of the loop is a series of clauses, each one representing a
kind of condition/action pair. The loop repeatedly reads a record, and
then executes each clause whose condition is satisfied by the record.

Here's an example that reads lines from port @emph{p} and prints the
line number and line of every line containing the string
``Church-Rosser'':

@example
(awk (read-line) (ln) lineno ()
  ("Church-Rosser" (format #t "~d: ~s~%" lineno ln)))
@end example

This example has just one clause in the loop body, the one that tests
for matches against the regular expression ``Church-Rosser''.

The @emph{<next-record>} form is an expression that is evaluated each
time through the loop to produce a record to process. This expression
can return multiple values; these values are bound to the variables
given in the @emph{<record&field-vars>} list of variables. The first
value returned is assumed to be the record; when it is the end-of-file
object, the loop terminates.

For example, let's suppose we want to read items from
@code{/etc/password}, and we use the @code{field-reader} procedure to
define a record parser for @code{/etc/passwd} entries:

@example
(define read-passwd (field-reader (infix-splitter ":" 7)))
@end example

binds @code{read-passwd} to a procedure that reads in a line of text
when it is called, and splits the text at colons. It returns two values:
the entire line read, and a seven-element list of the split-out
fields. (For more on @code{field-reader} and @code{infix-splitter},
@xref{Record I/O and field parsing}.)

So if the @emph{<next-record>} form in an @code{awk} expression is
@code{(read-passwd)}, then @emph{<record&field-vars>} must be a list of
two variables, @emph{e.g.},

@example
(record field-vec)
@end example

since @code{read-passwd} returns two values.

Note that awk allows us to use any record reader we want in the loop,
returning whatever number of values we like. These values don't have to
be strings or string lists. The only requirement is that the record
reader return the @acronym{eof} object as its first value when the loop
should terminate.

The @code{awk} loop allows the programmer to have loop variables. These
are declared and initialised by the @emph{<state-var-decls>} form, a

@example
((@var{var} @var{init-exp}) (@var{var} @var{init-exp}) @dots{})
@end example

list rather like the @code{let} form. Whenever a clause in the loop body
executes, it evaluates to as many values as there are state variables,
updating them.

The optional @emph{<counter>} variable is an iteration counter. It is
bound to 0 when the loop starts. The counter is incremented each time a
non-@acronym{eof} record is read.

There are several kinds of loop clause. When evaluating the body of the
loop, @code{awk} evaluates @emph{all} the clauses sequentially. Unlike
@code{cond} , it does not stop after the first clause is satisfied; it
checks them all.

@itemize
@item @code{(@var{test} @var{@math{body_1}} @var{@math{body_2}} @dots{})}

If @var{test} is true, execute the body forms. The last body form is the
value of the clause. The test and body forms are evaluated in the scope
of the record and state variables.

The @var{test} form can be one of:

@table @var
@item integer:

The test is true for that iteration of the loop. The first iteration is
#1.

@item sre:
A regular expression in @acronym{SRE} notation can be used as a test.
(@xref{Pattern-matching strings with regular expressions}.) The test is
successful if the pattern matches the record. In particular, note that
any string is an @acronym{SRE}.

@item @code{(when @var{expr})}:

The body of a @code{when} test is evaluated as a Scheme boolean
expression in the inner scope of the @code{awk} form.

@item expr:
If the form is none of the above, it
is treated as a Scheme expression--in practice, the
when keyword is onlyneeded in cases where @acronym{SRE}/Scheme
expression ambiguity might occur.
@end table

@item @code{(range @var{start-test} @var{stop-test} @var{@math{body_1}} @dots{})}

@code{(:range @var{start-test} @var{stop-test} @var{@math{body_1}} @dots{})}
@code{(range: @var{start-test} @var{stop-test} @var{@math{body_1}} @dots{})}
@code{(:range: @var{start-test} @var{stop-test} @var{@math{body_1}} @dots{})}

These clauses become activated when @var{start-test} is true; they stay
active on all further iterations until @var{stop-test} is true.

So, to print out the first ten lines of a file, we use the clause:

@example
(:range: 1 10 (display record))
@end example

The colons control whether or not the start and stop lines are processed
by the clause. For example:

@example
(range 1 5 @dots{})     ; Lines 2 3 4
(:range 1 5 @dots{})    ; Lines 1 2 3 4
(range: 1 5 @dots{})    ; Lines 2 3 4 5
(:range: 1 5 @dots{})   ; Lines 1 2 3 4 5
@end example

A line can trigger both tests, either simultaneously starting and
stopping an active region, or simultaneously stopping one and starting a
new one, so ranges can abut seamlessly.

@item @code{(else @var{@math{body_1}} @var{@math{body_2}} @dots{})}

If no other clause has executed since the top of the loop, or since the
last @code{else} clause, this clause executes.

@item @code{(@var{test} => @var{exp})}

If evaluating @var{test} produces a true value, apply @var{exp} to that
value. If @var{test} is a regular expression, then @var{exp} is applied
to the match data structure returned by the regexp match routine.

@item @code{(after @var{@math{body_1}} @dots{})}

This clause executes when the loop encounters @acronym{eof}. The body
forms execute in the scope of the state vars and the record-count var,
if there are any. The value of the last body form is the value of the
entire @code{awk} form.

If there is no @code{after} clause, @code{awk} returns the loop's state
variables as multiple values.
@end itemize

@anchor{Awk Examples}
@subsection Awk Examples

Here are some examples of awk being used to process various types of inputstream.

@example
(define $ list-ref) ; Saves typing.

;;; Print out the name and home-directory of everyone in /etc/passwd:

(let ((read-passwd (field-reader (infix-splitter ":" 7))))
    (call-with-input-file "/etc/passwd"
      (lambda (port)
	(awk (read-passwd port) (record fields) ()
	  (#t (format #t "~a's home directory is ~a~%"
		      ($ fields 0)
		      ($ fields 5)))))))

;;; Print out the user-name and home-directory of everyone whose
;;; name begins with "S"

(let ((read-passwd (field-reader (infix-splitter ":" 7))))
    (call-with-input-file "/etc/passwd"
      (lambda (port)
	(awk (read-passwd port) (record fields) ()
	  ((: bos "S")
	   (format #t "~a's home directory is ~a~%"
		   ($ fields 0)
		   ($ fields 5)))))))

;;; Read a series of integers from stdin. This expression evaluates
;;; to the number of positive numbers that were read. Note our
;;; "record-reader" is the standard Scheme READ procedure.

(awk (read) (i) ((npos 0))
   ((> i 0) (+ npos 1)))

;;; Filter -- pass only lines containing my name.

(awk (read-line) (line) ()
   ("Olin" (display line) (newline)))

;;; Count the number of non-comment lines of code in my Scheme source.

(awk (read-line) (line) ((nlines 0))
    ((: bos (* white) ";") nlines)	; A comment line.
    (else (+ nlines 1)))		; Not a comment line.

;;; Read numbers, counting the evens and odds.

(awk (read) (val) ((evens 0) (odds 0))
    ((> val 0) (display "pos ") (values evens odds)) ; Tell me about
    ((< val 0) (display "neg ") (values evens odds)) ; sign, too.
    (else (display "zero ") (values evens odds))

    ((even? val) (values (+ evens 1) odds))
    (else (values evens (+ odds 1))))

;;; Determine the max length of all the lines in the file.

(awk (read-line) (line) ((max-len 0))
   (#t (max max-len (string-length line))))

;;; (This could also be done with PORT-FOLD:)

(port-fold (current-input-port) read-line
	     (lambda (line maxlen) (max (string-length line) maxlen))
	     0)

;;; Print every line longer than 80 chars.
;;; Prefix each line with its line #.

(awk (read-line) (line) lineno ()
     ((> (string-length line) 80)
      (format #t "~d: ~s~%" lineno line)))

;;; Strip blank lines from input.

(awk (read-line) (line) ()
     ((~ white) (display line) (newline)))

;;; Sort the entries in /etc/passwd by login name.

(for-each (lambda (entry) (display (cdr entry)) (newline)) ; Out
          (sort (lambda (x y) (string<? (car x) (car y)))  ; Sort
                (let ((read (field-reader (infix-splitter ":" 7)))) ; In
                     (awk (read) (line fields) ((ans '()))
                          (#t (cons (cons ($ fields 0) line) ans))))))

;;; Prefix line numbers to the input stream.

(awk (read-line) (line) lineno ()
     (#t (format #t "~d:\t~a~%" lineno line)))
@end example

@anchor{Backwards compatibility}
@section Backwards compatibility

Previous scsh releases provided an @code{awk} form with a different
syntax, designed around regular expressions written in @acronym{POSIX}
notation as strings, rather than @acronym{SRE}s.

This form is still available in a separate module for old code. It'll be
documented in the next release of this manual. Dig around in the sources
for it.

@node Concurrent system programming, Miscellaneous routines, Awk record I/O and field parsing, Top
@chapter Concurrent system programming

The Scheme Shell provides the user with support for concurrent
programming. The interface consists of several parts:

@itemize
@item The thread system

@item Synchronization vehicles

@item Process state abstractions
@end itemize

Whereas the user deals with threads and synchronization explicitly, the
process state abstractions are built into the rest of the system, almost
transparent to the user. For a description of the interaction between
process state and threads, @xref{Interaction between threads and process
state}.

@anchor{Threads}
@section Threads

A thread can be thought of as a procedure that can run independently of
and concurrent to the rest of the system. The calling procedure fires
the thread up and forgets about it.

The current thread interface is completely taken from Scheme 48. This
documentation is an extension of the file @code{doc/threads.txt}
included with the Scsh distribution.

The thread structure is named @code{threads}; it has to be opened
explicitly.

@deffn Procedure spawn thunk [name]

Create and schedule a new thread that will execute @var{thunk}, a
procedure with no arguments. Note that Scsh's @code{spawn} does not
return a reference to a thread object. The optional argument @var{name}
is used when printing the thread.

The new thread will not inherit the values for the process state from
its parent; to create a thread with semantics similar to process
forking, use the procedure @code{fork-thread}. (@xref{Interaction
between threads and process state}.)
@end deffn

@deffn Procedure relinquish-timeslice

Let other threads run for a while.
@end deffn

@deffn Procedure sleep time

Puts the current thread to sleep for @var{time} milliseconds. The time
at which the thread is run again may be longer of course.
@end deffn

@deffn Procedure terminate-current-thread

Kill the current thread.

Mainly for debugging purposes; there is also an interface to the
internal representation of thread objects using @code{current-thread}.
@end deffn

@deffn Procedure current-thread

Return the object to which the current thread internally
corresponds. Note that this procedure is exported by the package
@code{threads-internal} only.
@end deffn

@deffn Procedure thread? thing

Returns true if and only if @var{thing} is a thread object.
@end deffn

@deffn Procedure thread-name thread

@var{Name} corresponds to the second parameter that was given to
@code{spawn} when @var{thread} was created.
@end deffn

@deffn Procedure thread-uid thread

Returns a unique identifier for the current thread.
@end deffn

@anchor{Locks}
@section Locks

Locks are a simple means for mutual exclusion. They implement a concept
commonly known as semaphores. Threads can obtain and release locks. If a
thread tries to obtain a lock which is held by another thread, the first
thread is blocked. To access the following procedures, you must open the
structure @code{locks}.

@deffn Procedure make-lock

Creates a lock.
@end deffn

@deffn Procedure lock? thing

Returns true if and only if @var{thing} is a lock.
@end deffn

@deffn Procedure obtain-lock lock

Obtain @var{lock}. Causes the thread to block if the lock is held by a
thread.
@end deffn

@deffn Procedure maybe-obtain-lock lock

Tries to obtain @var{lock}, but returns false if the lock cannot be
obtained.
@end deffn

@deffn Procedure release-lock lock

Releases @var{lock}. Returns true if the lock immediately got a new owner, false otherwise.
@end deffn

@deffn Procedure lock-owner-uid lock

Returns the uid of the thread that currently holds @var{lock} or false
if the lock is free.
@end deffn

@anchor{Placeholders}
@section Placeholders

Placeholders combine synchronization with value delivery. They can be
thought of as special variables. After creation, the value of the
placeholder is undefined. If a thread tries to read the placeholder's
value, this thread is blocked. Multiple threads are allowed to block on
a single placeholder. They will continue running after another thread
sets the value of the placeholder. Now all reading threads receive the
value and continue executing. Setting a placeholder to two different
values causes an error. The structure @code{placeholders} features the
following procedures:

@deffn Procedure make-placeholder

Creates a new placeholder.
@end deffn

@deffn Procedure placeholder? thing

Returns true if and only if @var{thing} is a placeholder.
@end deffn

@deffn Procedure placeholder-set! placeholder value

Sets the placeholder's value to @var{value}. If the placeholder is
already set to a different value, an exception is raised.
@end deffn

@deffn Procedure placeholder-value placeholder

Returns the value of the @var{placeholder}. If the valuse of
@var{placeholder} hasn't been set yet, the current thread is blocked
until another thread sets the value using @code{placeholder-set!}.
@end deffn

@anchor{The event interface to interrupts}
@section The event interface to interrupts

Scsh provides a synchronous interface to the asynchronous signals
delivered by the operating system@footnote{Olin Shivers' paper
``Automatic management of operating-system resources'' describes this
system in detail. For Shivers' complete technical bibliography, see
@uref{http://www.ccs.neu.edu/home/shivers/citations.html}}. The key
element in this system is an object called @emph{sigevent} which
corresponds to the single occurrence of a signal. A sigevent has two
fields: the UNIX signal that occurred and a pointer to the sigevent
that happened or will happen. That is, events are kept in a linked
list in increasing-time order. Scsh's structure @code{sigevents}
provides various procedures to access this list:

@deffn Procedure most-recent-sigevent

Returns the most recent sigevent --- the head of the sigevent list.
@end deffn

@deffn Procedure sigevent? object

The predicate for sigevents.
@end deffn

@deffn Procedure next-sigevent pre-event type

Returns the next sigevent of type @var{type} after sigevent
@var{pre-event}. If no such event exists, the procedure blocks.
@end deffn

@deffn Procedure next-sigevent-set pre-event set

Returns the next sigevent whose type is in @var{set} after @var{pre-event}. If no such event exists, the procedure blocks.
@end deffn

@deffn Procedure next-sigevent/no-wait pre-event type

Same as @code{next-sigevent}, but returns false if no appropriate event
exists.
@end deffn

@deffn Procedure next-sigevent-set/no-wait set pre-event

Same as @code{next-sigevent-set}, but returns false if no appropriate
event exists.

As a small example, consider this piece of code that toggles the
variable state by @code{USR1} and @code{USR2}:

@example
(define (state #t)
    (let lp ((sigevent (most-recent-sigevent)))
      (let ((next (next-sigevent sigevent interrupt/usr1)))
	(set! state #f)
	(let ((next (next-sigevent next interrupt/usr2)))
	  (set! state #t)
	  (lp next)))))
@end example
@end deffn

@emph{Warning}: The current version of scsh also defines asynchronous
handlers for interrupts (@xref{Signal system}.). The default action of
some of these handlers is to terminate the process, in which case you
will most likely not see an effect of the synchronous event interface
described here. It is therefore recommended to disable the corresponding
interrupt handler using @code{(set-interrupt-handler interrupt #f)}.

@anchor{Interaction between threads and process state}
@section Interaction between threads and process state

In UNIX, a number of resources are global to the process: signal
handlers, working directory, umask, environment, user and group
IDs. Modular programming is difficult in the context of this global
state, and for concurrent programming things get even worse. (For more
information about how scsh turns the global, asynchronous signals
handlers into modular, synchronous sigevents, @xref{The event interface
to interrupts}.) Concurrent programming also benefits from sigevents as
every thread may chase down the sigevent chain separately.

Scsh treats the working directory, umask, environment, and the effective
user/group ID as thread-local resources. The initial value of the
resources is determined by the way a thread is started: @code{spawn}
assigns the initial values whereas @code{fork-thread} adopts the values
of its parent. Here is a detailed description of the whole facility:

@itemize
@item 
The procedures to access and modify the resources remain as described in
the previous chapters (@code{cwd}, @code{chdir}, @code{umask},
@code{set-umask}, @code{getenv}, @code{putenv}).

@item 
Every thread receives its own copy of each resource.

@item 
If @code{spawn} is used to start a new thread, the values of the
resources are the same as they where when scsh started.

@item The procedure
@deffn Procedure fork-thread thunk

from the structure @code{thread-fluids} starts a thread which inherits
the values of all resources from its parent. This behaviour is similar
to what happens at process forking.
@end deffn

@item
The actual process state is updated only when necessary, @emph{i.e.}, on
access or modification but not on context switch from one thread to
another.
@end itemize

@deffn Procedure spoon thunk

This is just an alias for @code{fork-thread} suggested by Alan Bawden.
For user and group identities, arbitrary changing is not
possible. Therefore they remain global process state: If a thread
changes one of these values, all other threads see the new
value. Consequently, scsh does not provide @code{with-uid} and friends.
@end deffn

@node Miscellaneous routines, Running scsh, Concurrent system programming, Top
@chapter Miscellaneous routines

@anchor{Integer bitwise ops}
@section Integer bitwise ops

@deffn  Procedure arithmetic-shift i j
@deffnx Procedure bitwise-and i j
@deffnx Procedure bitwise-ior i j
@deffnx Procedure bitwise-not i
@deffnx Procedure bitwise-xor i j

These operations operate on integers representing semi-infinite
bitstrings, using a 2's-complement encoding.

@code{arithmetic-shift} shifts @var{i} by @var{j} bits. A left shift is
@math{@var{j}> 0}; a right shift is @math{@var{j} < 0}.
@end deffn

@anchor{Password encryption}
@section Password encryption

@deffn Procedure crypt key salt

Decrypts @var{key} by directly calling the @code{crypt} function using
@var{salt} to perturb the hashing algorithm. @var{Salt} must be a
two-character string consisting of digits, alphabetic characters, ``.'',
or ``\''. The length of @var{key} may be at most eight.
@end deffn

@anchor{Dot-Locking}
@section Dot-Locking

@ref{File locking} already points out that @acronym{POSIX}'s file locks
are almost useless in practice. To bypass this restriction, other
advisory locking mechanisms, based only on standard file operations,
were invented. One of them is the so-called @emph{dot-locking} scheme
where the lock of @var{filename} is represented by the file
@var{filename.lock}. Care is taken that only one process may generate
the lock for a given file.

Here is scsh's interface to dot-locking:

@deffn Procedure obtain-dot-lock filename [interval retry-number stale-time]

Tries to obtain the lock for @var{filename}. If the file is already
locked, the thread sleeps for @var{interval} seconds (default is 1)
before it retries.  If the lock cannot be obtained after
@var{retry-number} attempts, the procedure returns @code{#f}, otherwise
@code{#t}. The default value of @var{retry-number} is @code{#f} which
corresponds to an infinite number of retries.

If @var{stale-time} is non-@code{#f}, it specifies the minimum age a
lock may have (in seconds) before it is considered stale.
@code{Obtain-dot-lock} attempts to delete stale locks. If it was
succcessful at obtaining a lock after breaking it,
@code{obtain-dot-lock} returns @code{broken}. If @var{stale-time} is
@code{#f}, @code{obtain-dot-lock} never considers a lock stale. The
default value of @var{stale-time} is 300.

Note that it is possible that @code{obtain-dot-lock} breaks a lock but
nevertheless fails to obtain it otherwise. If it is necessary to handle
this case specially, use @code{break-dot-lock} directly (see below)
rather than specifying a non-@code{#f} @var{stale-time}.
@end deffn

@deffn Procedure break-dot-lock filename

Breaks the lock for @var{filename} if one exists. Note that breaking a
lock does not imply a subsequent @code{obtain-dot-lock} will succeed, as
another party may have acquired the lock between @code{break-dot-lock}
and @code{obtain-dot-lock}.
@end deffn

@deffn Procedure release-dot-lock filename

Releases the lock for @var{filename}. On success,
@code{release-dot-lock} returns @code{#t}, otherwise @code{#f}. Note
that this procedure can also be used to break the lock for
@var{filename}.
@end deffn

@deffn Procedure with-dot-lock* file-name thunk
@deffnx Syntax with-dot-lock file-name body @dots{} 

The procedure @code{with-dot-lock*} obtains the requested lock, and then
calls @var{thunk}. When @var{thunk} returns, the lock is released. A
non-local exit (@emph{e.g.}, throwing to a saved continuation or raising
an exception) also causes the lock to be released.

After a normal return from @var{thunk}, its return values are returned
by @var{with-dot-lock*}. The @code{with-dot-lock} special form is
equivalent syntactic sugar.
@end deffn

@anchor{Syslog facility}
@section Syslog facility

(@emph{Note}: the functionality presented in this section is still
somewhat experimental and thus subject to interface changes.)

The procedures in this section provide access to the 4.2BSD syslog
facility present in most @acronym{POSIX} systems. The functionality is
in a structure called @code{syslog}. There's an additional structure
@code{syslog-channels}, documented below.The scsh interface to the
syslog facility differs significantly from that of the UNIX library
functionality in order to support multiple simultaneous connections to
the syslog facility.

Log messages carry a variety of parameters beside the text of the
message itself, namely a set of options controlling the output format
and destination, the facility identifying the class of programs the
message is coming from, an identifier specifying the concrete program,
and the level identifying the importance of the message. Moreover, a log
mask can prevent messages at certain levels from actually being sent to
the syslog daemon.

@anchor{Log options}
@subsection Log options

A log option specifies details of the I/O behavior of the syslog
facility. A syslog option is an element of a finite type constructed by
the @code{syslog-option} macro. The syslog facility works with sets of
options which are represented as enum sets.

For more information about the terms ``element of a finite type'' and
``enum sets'', see the Scheme 48 manual.

@deffn  Syntax syslog-option option-name
@deffnx Procedure syslog-option? x
@deffnx Procedure make-syslog-options list
@deffnx Syntax syslog-options option-name @dots{}
@deffnx Procedure syslog-options? x

@code{Syslog-option} constructs a log option from the name of an option.
(The possible names are listed below.)

@code{Syslog-option?} is a predicate for log options. Options are
comparable using @code{eq?}. @code{Make-syslog-options} constructs a set
of options from a list of options.

@code{Syslog-options} is a macro which expands into an expression
returning a set of options from names.

@code{Syslog-options?} is a predicate for sets of options.
@end deffn

Here is a list of possible names of syslog options:

@table @code
@item console 

If syslog cannot pass the message to @code{syslogd} it will attempt to
write the message to the console.

@item delay
 
Delay opening the connection to @code{syslogd} immediately until the
first message is logged.

@item no-delay

Open the connection to @code{syslogd} immediately. Normally the
@code{open} is delayed until the first message is logged. Useful for
programs that need to manage the order in which file descriptors are
allocated.

@emph{N.B.}: The @code{delay} and @code{no-delay} options are included
for completeness, but do not have the expected effect in the present
Scheme interface: Because the Scheme interface has to multiplex multiple
simultaneous connections to the syslog facility over a single one,
@code{open} and @code{close} operations on that facility happen at
unpredictable times.

@item log-pid

Log the process ID with each message; useful for identifying
instantiations of daemons.
@end table

@anchor{Log facilities}
@subsection Log facilities

A log facility identifies the originator of a log message from a
finite set known to the system. Each originator is identified by a
name:

@deffn Syntax syslog-facility facility-name
@deffnx Procedure syslog-facility? x

@code{Syslog-facility} is macro that expands into an expression
returning a facility for a given name.  @code{Syslog-facility?} is a
predicate for facilities. Facilities are comparable via @code{eq?}.
@end deffn

Here is a list of possible names of syslog facilities:

@table @strong

@item authorization
The authorization system: @code{login}, @code{su}, @code{getty}, etc.

@item cron
The @code{cron} daemon.

@item daemon
System daemons, such as @code{routed}, that are not provided for
explicitly by other facilities.

@item kernel
Messages generated by the kernel.

@item lpr
The line printer spooling system: @code{lpr}, @code{lpc}, @code{lpd},
etc.

@item mail 
The mail system.

@item news
The network news system.

@item user
Messages generated by random user processes.

@item uucp
The @code{uucp} system.

@item local0 local1 local2 local3 local4 local5 local6 local7
Reserved for local use.
@end table

@anchor{Log levels}
@subsection Log levels

A log level identifies the importance of a message from a fixed set of possible levels.

@deffn Syntax syslog-level level-name
@deffnx Procedure syslog-level? x

@code{Syslog-level} is macro that expands into an expression returning
a facility for a given name.  @code{Syslog-level?} is a predicate for
facilities. Levels are comparable via eq?.
@end deffn

Here is a list of possible names of syslog levels:

@table @strong
@item emergency
A panic condition. This is normally broadcast to all users.

@item alert
A condition that should be corrected immediately, such as a
corrupted system database.

@item critical
Critical conditions, @emph{e.g.}, hard device errors.

@item error
Errors.

@item warning
Warning messages.

@item notice
Conditions that are not error conditions, but should possibly be
handled specially.

@item info
Informational messages.

@item debug
Messages that contain information normally of use only when debugging
a program.
@end table

@anchor{Log masks}
@subsection Log masks
Log masks can mask out log messages at a set of levels. A log mask is
an enum set of log levels. @c TODO: Replace `enum' with `enumerated'?

@deffn Procedure make-syslog-mask list
@deffnx Syntax syslog-mask level-name
@deffnx Variable syslog-mask-all
@deffnx Procedure syslog-mask-upto level
@deffnx Procedure syslog-mask? x

@code{Make-syslog-mask} constructs a mask from a list of
levels. @code{Syslog-mask} is a macro which constructs a mask from
names of levels. @code{Syslog-mask-all} is a predefined log mask
containing all levels.  @code{Syslog-mask-upto} returns a mask
consisting of all levels up to and including a certain level, starting
with @code{emergency}.
@end deffn

@anchor{Logging}
@subsection Logging

Scheme 48 dynamically maintains implicit connections to the syslog
facility specifying a current identifier, current options, a current
facility and a current log mask. This implicit connection is held in a
thread fluid. (@xref{Interaction between threads and process
state}.) Hence, every thread maintains its own implicit connection to
syslog. Note that the connection is not implicitly preserved across a
@code{spawn}, but it is preserved across a @code{fork-thread}:

@deffn Procedure with-syslog-destination string options facility mask thunk
@deffnx Procedure set-syslog-destination! string options facility mask

@code{With-syslog-destination} dynamically binds parameters of the
implicit connection to the syslog facility and runs @var{thunk} within
those parameter bindings, returning what @var{thunk} returns. Each of
the parameters may be @code{#f}, in which case the previous values
will be used.  @code{Set-syslog-destination!} sets the parameters of
the implicit connection of the current thread.
@end deffn

@deffn Procedure syslog level message
@deffnx Procedure syslog level message [string options syslog-facility]

@code{Syslog} actually logs a message. Each of the parameters of the
implicit connection (except for the log mask) can be explicitly
specified as well for the current call to @code{syslog}, overriding
the parameters of the channel. The parameters revert to their original
values after the call.
@end deffn

@anchor{Syslog channels}
@subsection Syslog channels

The @code{syslog-channels} structure allows direct manipulation of
syslog channels, the objects that represent connections to the syslog
facility. Note that it is not necessary to explicitly open a syslog
channel to do logging.

@deffn Procedure open-syslog-channel string options facility mask
@deffnx Procedure close-syslog-channel channel
@deffnx Procedure syslog level message channel

@code{Open-syslog-channel} and @code{close-syslog-channel} create and
destroy a connection to the syslog facility, respectively. The
specified form of calling @code{syslog} logs to the specified channel.
@end deffn

@anchor{MD5 interface}
@section MD5 interface

Scsh provides a direct interface to the MD5 functions to compute the
"fingerprint" or "message digest" of a file or string. It uses the C
library written by Colin Plum.

@c TODO: Check the spelling of Mr. Plum's name (it appears on the
@c interwebs as both `Plum' and `Plumb'.

@deffn Procedure md5-digest-for-string string
Calculates the MD5 digest for the given @var{string}.
@end deffn

@deffn Procedure md5-digest-for-port port [buffer-size]
Reads the contents of the port and calculates the MD5 digest for
it. The optional argument @var{buffer-size} determines the size of the
port's input buffer in bytes. It defaults to 1024 bytes.
@end deffn

@deffn Procedure md5-digest? thing
The type predicate for MD5 digests; @code{md5-digest?} returns true if
and only if @var{thing} is an MD5 digest.
@end deffn

@deffn Procedure md5-digest->number md5-digest
Returns the number corresponding to the MD5 digest.
@end deffn

@deffn Procedure number->md5-digest number
Creates an MD5 digest from a number.
@end deffn

@deffn Procedure make-md5-context
@deffnx Procedure md5-context? thing
@deffnx Procedure update-md5-context! md5-context string
@deffnx Procedure md5-context->md5-digest md5-context
These procedures provide a low-level interface to the library. An
@var{md5-context} stores the state of an MD5 computation; it is
created by @code{make-md5-context}, and its type predicate is
@code{md5-context?}. The procedure @code{update-md5-context!} extends
the @var{md5-context} by the given @var{string}. Finally,
@code{md5-context->md5-digest} returns the md5-digest for the
@var{md5-context}. With these procedures, it is possible to
incrementally add strings to an @var{md5-context} before computing the
digest.
@end deffn

@anchor{Configuration variables}
@section Configuration variables

This section describes procedures to access the configuration
parameters used to compile scsh, and the flags needed to build C
extensions for scsh.

@deffn Procedure host
@deffnx Procedure machine
@deffnx Procedure vendor
@deffnx Procedure os
These procedures return the description of the host scsh was built on,
as determined by the script @code{config.guess}.
@end deffn

@deffn Procedure prefix
@deffnx Procedure exec-prefix
@deffnx Procedure bin-dir
@deffnx Procedure lib-dir
@deffnx Procedure include-dir
@deffnx Procedure man-dir
These procedures return the various directories of the scsh installation.
@end deffn

@deffn Procedure lib-dirs-list
Returns the default list of library directories. For more information
about the library search facility, @xref{Switches}.
@end deffn

@deffn Procedure libs
@deffnx Procedure defs
@deffnx Procedure cflags
@deffnx Procedure cppflags
@deffnx Procedure ldflags
The values returned by these procedures correspond to the values
@code{make} used to compile scsh's C files.
@end deffn

@deffn Procedure compiler-flags
The procedure @code{compiler-flags} returns flags suitable for running
the C compiler when compiling a C file that uses scsh's foreign
function interface.
@end deffn

@deffn Procedure linker-flags
Scsh also comes as a library that can be linked into other
programs. The procedure @code{linker-flags} returns the appropriate
flags to link the scsh library to another program.
@end deffn

@node Running scsh, Index, Miscellaneous routines, Top
@chapter Running scsh

Scsh is currently implemented on top of Scheme 48, a freely-available
Scheme implementation written by Jonathan Rees and Richard
Kelsey. Scheme 48 uses a byte-code interpreter for good code density,
portability and medium efficiency. It is R5RS. It also has a module
system designed by Jonathan Rees.

Scsh's design is not Scheme 48 specific, although the current
implementation is necessarily so. Scsh is intended to be implementable
in other Scheme implementations. The Scheme 48 virtual machine that
scsh uses is a specially modified version; standard Scheme 48 virtual
machines cannot be used with the scsh heap image.

There are several different ways to invoke scsh. You can run it as an
interactive Scheme system, with a standard read-eval-print interaction
loop.

Scsh can also be invoked as the interpreter for a shell script by
putting the following line at the top of the shell script:

@example
#!/usr/local/bin/scsh -s
@end example

Descending a level, it is also possible to invoke the underlying
virtual machine byte-code interpreter directly on dumped heap
images. Scsh programs can be precompiled to byte-codes and dumped as
raw, binary heap images. Writing heap images strips out unused
portions of the scsh runtime (such as the compiler, the debugger, and
other complex subsystems), reducing memory demands and saving loading
and compilation times. The heap image format allows for an initial
@code{#!/usr/local/lib/scsh/scshvm} trigger on the first line of the
image, making heap images directly executable as another kind of shell
script.

Finally, scsh's static linker system allows dumped heap images to be
compiled to a raw UNIX @code{a.out(5)} format, which can be linked
into the text section of the vm binary. This produces a true UNIX
executable binary file. Since the byte codes comprising the program
are in the file's text section, they are not traced or copied by the
garbage collector, do not occupy space in the vm's heap, and do not
need to be loaded and linked at startup time. This reduces the
program's startup time, memory requirements, and paging overhead.

This chapter will cover these various ways of invoking scsh programs.

@anchor{Scsh command-line switches}
@section Scsh command-line switches

When the scsh top-level starts up, it scans the command line for
switches that control its behaviour. These arguments are removed from
the command line; the remaining arguments can be accessed as the value
of the scsh variable @code{command-line-arguments}.

@anchor{Scripts and programs}
@subsection Scripts and programs

The scsh command-line switches provide sophisticated support for the
authors of shell scripts and programs; they also allow the programmer
to write programs that use the Scheme 48 module system.

There is a difference between a script, which performs its action as
it is loaded, and a program, which is loaded/linked, and then performs
its action by having control transferred to an entry point
(@emph{e.g.}, the @code{main()} function in C programs) that was
defined by the load/link operation.

A script, by the above definition, cannot be compiled by the simple
mechanism of loading it into a scsh process and dumping out a heap
image---it executes as it loads. It does not have a top-level
@code{main()}-type entry point.

It is more flexible and useful to implement a system as a program than
as a script. Programs can be compiled straightforwardly; they can also
export procedural interfaces for use by other Scheme
packages. However, scsh supports both the script and the program style
of programming.

@anchor{Inserting interpreter triggers into scsh programs}
@subsection Inserting interpreter triggers into scsh programs

When UNIX tries to execute an executable file whose first 16 bits are
the character pair ``@code{#!}'', it treats the file not as
machine-code to be directly executed by the native processor, but as
source code to be executed by some interpreter. The interpreter to use
is specified immediately after the ``@code{#!}'' sequence on the first
line of the source file (along with one optional initial
argument). The kernel reads in the name of the interpreter, and
executes that instead. The interpreter is passed the source filename
as its first argument, with the original arguments following. Consult
the UNIX man page for the @code{exec} system call for more
infor-mation.

Scsh allows Scheme programs to have these triggers placed on their
first line. Scsh treats the character sequence ``@code{#!}'' as a
block-comment sequence,@footnote{Why a block-comment instead of an
end-of-line delimited comment? See the section on meta-args.} and
skips all following characters until it reads the comment-terminating
sequence newline/exclamation-point/sharp-sign/newline (@emph{i.e.},
the sequence ``@code{!#}'' occurring on its own line).

In this way, the programmer can arrange for an initial

@example
#!/usr/local/bin/scsh -s
!#
@end example

header appearing in a Scheme program to be ignored when the program is
loaded into scsh.

@anchor{Module system}
@subsection Module system

Scsh uses the Scheme 48 module system, which defines @emph{packages},
@emph{structures}, and @emph{interfaces}.

@table @strong

@item Package 

A package is an environment---that is, a set of variable/value
bindings. You can evaluate Scheme forms inside a package, or load a
file into a package. Packages export sets of bindings; these sets are
called @emph{structures}.

@item Structure

A structure is a named view on a package---a set of bindings. Other
packages can open the structure, importing its bindings into their
environment. Packages can provide more than one structure, revealing
different portions of the package's environment.

@item Interface

An interface is the ``type'' of a structure. An interface is the set
of names exported by a structure. These names can also be marked with
other static information (@emph{e.g.}, advisory type declarations, or
syntax information).
@end table

More information on the the Scheme 48 module system can be found in
the file @code{doc/src/module.tex} in the scsh distribution.

Programming Scheme with a module system is different from programming
in older Scheme implementations, and the associated development
problems are consequently different. In Schemes that lack modular
abstraction mechanisms, everything is accessible; the major problem is
preventing namespace conflicts. In Scheme 48, namespace conflicts
vanish; the major problem is that not all bindings are accessible from
every place. It takes a little extra work to specify what packages
export which values.

It may take you a little while to get used to the new style of program
development. Although scsh can be used without referring to the module
system at all, we recommend taking the time to learn and use it. The
effort will pay off in the construction of modular, factorable
programs.

@subsubsection Module warning

Most scsh programs will need to import from the @code{scheme} structure
as well as from the @code{scsh} structure. However, putting both of
these structures in the same @code{open} clause is a bad idea because
the structures @code{scheme} and @code{scsh} export some names of I/O
functions in common but with different definitions. The current
implementation of the module system does not recognize this as an error
but silently overwrites the exports of one structure with the exports of
the other. If the @code{scheme} structure overwrites the exports of the
@code{scsh} structures the program will access the @math{R^5RS}
definitions of the I/O functions which is not what you want.

Previous versions of this manual suggested to list @code{scheme} and
@code{scsh} in a specific order in the @code{open} clause of a structure
to ensure that the definitions from @code{scsh} overwrite the ones from
@code{scheme}. This approach is error-prone and fragile: A simple change
in the implementation of the module system will render thousands of
programs useless. Starting with release 0.6.3 scsh provides a better
means to deal with this problem: the structure @code{scheme-with-scsh}
provides all the exports of the modules @code{scheme} and @code{scsh}
but exports the right denotations for the I/O functions in question.

To make a long story short: Scsh programs should open the structure
@code{scheme-with-scsh} if they need access to the exports of
@code{scheme} and @code{scsh}.

For programs which should run in versions of scsh prior to release
0.6.3, programmers should make sure to always put the scsh reference
first.

@anchor{Library directories search facility}
@subsection Library directories search facility

Scsh's command line switches allow loading of code not present in the
script file or the heap image at startup. To relieve the user from
specifying full path names and to improve flexibility, scsh offers the
library directories path list. This list contains directories in which
scsh searches automatically for a file name argument of the @code{-ll}
or @code{-le} switch.

This section describes the programmatic interface to the library
directories search facility. In addition, various command line
switches for scsh modify the library directories path list. For a
description of these switches and the switches to actually load files,
@xref{Switches}.

Another way to change the library directories path list is the
environment variable @code{$SCSH_LIB_DIRS}. If this variable is set,
scsh uses it to set library directories path list. The value of this
environment variable is treated as a sequence of s-expressions, which
are ``read'' from the string as follows:

@itemize
@item 
A string is treated as a directory.

@item
@code{#f} is replaced with the default list of directories.
@end itemize

For example, a @code{$SCSH_LIB_DIRS} assignment of the form

@example
SCSH_LIB_DIRS='"." "/usr/contrib/lib/scsh/" #f "/home/shivers/lib/scsh"'
@end example

would produce this list of strings for the @emph{library-directories}
list:

@example
("." "/usr/contrib/lib/scsh/"
"/usr/local/lib/scsh/modules/"
"/home/shivers/lib/scsh")
@end example

It is a startup error if reading the @code{$SCSH_LIB_DIRS} environment
variable causes a read error, or produces a value that isn't a list of
strings or @code{#f}.

@deffn Variable default-lib-dirs

The default list of library directories. The original value of this
variable is @code{("$prefix/lib/scsh/modules/")}. Starting with version
0.6.5 the option @code{--with-lib-dirs-list} of the @code{configure}
script changes for a new installation.
@end deffn

@deffn Procedure find-library-file file lib-dirs script-file

Searches the list of library directories @emph{lib-dirs} for @var{file}
and returns the full path. The variable @var{script-file} is used to
resolve references to the directory of the current script.

When searching for a directory containing a given library module,
nonexistent or read-protected directories are silently ignored; it is
not an error to have them in the @var{library-directories} list.

Directory search can be recursive. A directory name that ends with a
slash is recursively searched.
@end deffn

@deffn Procedure lib-dirs

Returns the current library directories path list.
@end deffn

@deffn Procedure lib-dirs-prepend-script-dir!
@deffnx Procedure lib-dirs-append-script-dir!

Add the directory of the current script file to the beginning or end of
the @emph{library-directories} path list, respectively.
@end deffn

@deffn Procedure lib-dirs-append! dir
@deffnx Procedure lib-dirs-prepend! dir

Add directory @var{lib-dir} to the beginning or end of the
@emph{library-directories} pathlist, respectively.
@end deffn

@deffn Procedure clear-lib-dirs!

Set the @emph{library-directories} path list to the empty list.
@end deffn

@deffn Procedure reset-lib-dirs!

Set the @emph{library-directories} path list to system default,
@emph{i.e.}, to the value of @code{default-lib-dirs}.
@end deffn

@anchor{Switches}
@subsection Switches

The scsh top-level takes command-line switches in the following format:

@example
scsh [meta-arg] [switchi ...] [end-option arg1 ... argn]
@end example

where

@example
@emph{meta-arg}:  \ script-file-name

@emph{switch}: -e entry-point        Specify top-level entry-point.
               -o structure          Open structure in current package.
               -m structure          Switch to package.
               -n new-package        Switch to new package.
               -lm module-file-name  Load module into config package.
               -le exec-file-name    Load module into exec package.
               -l file-name          Load file into current package.
               -ll module-file-name  As in -lm, but search the library path list.
               -lel exec-file-name   As in -le, but search the library path list.
               +lp dir               Add dir to front of library path list.
               lp+ dir               Add dir to end of library path list.
               +lpe dir              +lp, with env var and ~user expansion.
               lpe+ dir              lp+, with env var and ~user expansion.
               +lpsd                 Add script-file's dir to front of path list.
               lpsd+                 Add script-file's dir to end of path list.
               -lp-clear             Clear library path list to ().
               -lp-default           Reset library path list to system default.
               -ds                   Do script.
               -dm                   Do script module.
               -de                   Do script exec.

@emph{end-option}: -s      script
                   -sfd    num
                   -c      exp
                   --
@end example

These command-line switches essentially provide a little linker
language for linking a shell script or a program together with Scheme
48 modules or Scheme 48 exec programs@footnote{See the Section
``Command programs'' in the Scheme 48 manual for a description of the
exec language.}. The command-line processor serially opens structures
and loads code into a given package. Switches that side-effect a
package operate on a particular ``current'' package; there are
switches to change this package. (These switches provide functionality
equivalent to the interactive @code{,open} @code{,load} @code{,in} and
@code{,new} commands.) Except where indicated, switches specify
actions that are executed in a left-to-right order. The initial
current package is the user package, which is completely empty and
opens (imports the bindings of) the @math{R^5RS} scsh structures.

If the Scheme process is started up in an interactive mode, then the
current package in force at the end of switch scanning is the one
inside which the interactive read-eval-print loop is started.

The command-line switch processor works in two passes: it first parses
the switches, building a list of actions to perform, then the actions
are performed serially. The switch list is terminated by one of the
@emph{end-option} switches. The @math{arg_i} arguments occurring after
an @emph{end-option} switch are passed to the scsh program as the
value of @code{command-line-arguments} and the tail of the list
returned by @code{(command-line)}. That is, an @emph{end-option}
switch separates switches that control the scsh ``machine'' from the
actual arguments being passed to the scsh program that runs on that
machine.

The following switches and end options are defined:

@itemize
@item @code{-o} @var{struct}

Open the structure in the current package.
@item @code{-n} @var{package}

Make and enter a new package. The package has an associated structure
named @var{package} with an empty export list. If @var{package} is
the string @code{"#f"}, the new package is anonmyous, with no
associated named structure.

The new package initially opens no other structures, not even the
@math{R^5RS} bindings. You must follow a ``@code{-n foo}'' switch with
``@code{-o scheme}'' to access the standard identifiers such as
@code{car} and @code{define}.

@item @code{-m} @var{struct}

Change the current package to the package underlying structure
@var{struct}. (The -m stands for ``module''.)

@item @code{-lm} @var{module-file-name}

Load the specified file into scsh's config package --- the file must
contain source written in the Scheme 48 module language (``load
module''). Does not alter the current package.

@item @code{-le} @var{exec-file-name} 

Load the specified file into scsh's exec package --- the file must
contain source written in the Scheme 48 exec language (``load
exec''). Does not alter the current package.

@item @code{-l} @var{file-name}

Load the specified file into the current package.

@item @code{-c} @var{exp}

Evaluate expression @var{exp} in the current package and exit. This
is called @code{-c} after a common shell convention (see sh and
csh). The expression is evaluated in the the current package (and
hence is affected by @code{-m} and @code{-n}.)

When the scsh top-level constructs the scsh command-line in this case,
it takes ``@code{scsh}'' to be the program name. This switch
terminates argument scanning; following args become the tail of the
command-line list.

@item @code{-e} @var{entry-point}

Specify an entry point for a program. The entry-point is a variable
that is taken from the current package in force at the end of switch
evaluation. The entry point does not have to be exported by the
package in a structure; it can be internal to the package. The top
level passes control to the entry point by applying it to the
command-line list (so programs executing in private packages can
reference their command-line arguments without opening the @code{scsh}
package to access the @code{(command-line)} procedure). Note that,
like the list returned by the @code{(command-line)} procedure, the
list passed to the entry point includes the name of the program being
executed (as the first element of the list), not just the arguments to
the program.

A @code{-e} switch can occur anywhere in the switch list, but it is
the last action performed by switch scanning if it occurs. (We violate
ordering here as the shell-script @code{#!} mechanism prevents you
from putting the @code{-e} switch last, where it belongs.)
@item @code{-s} @var{script}

Specify a file to load. A @code{-ds} (do-script), @code{-dm}
(do-module), or @code{-de} (do-exec) switch occurring earlier in the
switch list gives the place where the script should be loaded. If
there is no @code{-ds} , @code{-dm} , or @code{-de} switch, then the
script is loaded at the end of switch scanning, into the module that
is current at the end of switch scanning.

We use the @code{-ds} switch to violate left-to-right switch execution
order as the @code{-s} switch is required to be last (because of the
@code{#!} machinery), independent of when/where in the
switch-processing order it should be loaded.

When the scsh top-level constructs the scsh command-line in this case,
it takes @var{script} to be the program name. This switch terminates
switch parsing; following args are ignored by the switch-scanner and
are passed through to the program as the tail of the command-line
list.

@item @code{-sfd} @var{num}

Loads the script from file descriptor @var{num} . This switch is like
the @code{-s} switch, except that the script is loaded from one of the
process's open input file descriptors. For example, to have the script
loaded from standard input, specify ``@code{-sfd 0}''.

@item @code{--}

Terminate argument scanning and start up scsh in interactive mode.

If the argument list just runs out, without either a terminating
@code{-s} or @code{--} arg, then scsh also starts up in interactive
mode, with an empty @code{command-line-arguments} list (for example,
simply entering scsh at a shell prompt with no args at all).

When the scsh top-level constructs the scsh command-line in this case,
it takes ``@code{scsh}'' to be the program name. This switch
terminates switch parsing; following args are ignored by the
switch-scanner and are passed through to the program as the tail of
the command-line list.

@item @code{-ds}

Specify when to load the script (``do-script''). If this switch
occurs, the switch list must be terminated by a @code{-s} script
switch. The script is loaded into the package that is current at the
@code{-ds} switch.

@item @code{-dm}

As above, but the current module is ignored. The script is loaded into
the config package (``do-module''), and hence must be written in the
Scheme48 module language. This switch doesn't affect the current
module --- after executing this switch, the current module is the same
as as it was before.

This switch is provided to make it easy to write shell scripts in the
Scheme48 module language.

@item @code{-de}

As above, but the current module is ignored. The script is loaded into
the exec package (``do-exec''), and hence must be written in the
Scheme 48 exec language.

This switch is provided to make it easy to write shell scripts in the
Scheme48 exec language.

@item @code{-ll} @var{module-file-name}

Load library module into config package. This is just like the
@code{-lm} switch, except that it searches the library-directory path
list. (For the file to load, @xref{Library directories search
facility}.)

Specifically, it means: search through the library-directories list of
directories looking for a module file of the given name, and load it
in. Scsh uses the procedure @code{find-library-file} to perform the
search.

@item @code{-lel} @var{exec-file-name}

As above, but load the specified file into scsh's exec package. This
is just like the @code{-le} switch, except that it searches the
library-directory path list for the file to load.

@item @code{+lp} @var{lib-dir}, @code{lp+} @var{lib-dir}

Add directory @var{lib-dir} to the beginning or end of the
library-directories path list, respectively.

@var{Lib-dir} is a single directory. It is not split at colons or
otherwise processed. These switches correspond to the procedures
@code{lib-dirs-prepend!} and @code{lib-dirs-append!}.

@item @code{+lpe}, @code{lpe+}

As above, except that @code{~} home-directory syntax and environment
variables are expanded out.

@item @code{+lpsd}, @code{lpsd+}

Add script-file's directory to the beginning or end of the
library-directories path list, respectively. These switches correspond
to the procedures @code{lib-dirs-prepend-script-dir!} and
@code{lib-dirs-append-script-dir!}.

@item @code{-lp-clear}, @code{-lp-default}

Set the library-directories path list to the empty list and the system
default, respectively. These switches correspond to the procedures
@code{clear-lib-dirs!} and @code{reset-lib-dirs!}.

The two switches are useful if you would like to protect your script
from influence by the @code{$SCSH_LIB_DIRS} variable.

In these cases, the @code{$SCSH_LIB_DIRS} environment variable is
never even parsed, so a bogus value will not affect the script's
execution at all.
@end itemize

@anchor{The meta argument}
@subsection The meta argument

The scsh switch parser takes a special command-line switch, a single
backslash called the ``meta-argument'', which is useful for shell
scripts. If the initial command-line argument is a ``\'', followed by a
filename argument @var{fname}, scsh will open the file @var{fname} and
read more arguments from the second line of this file. This list of
arguments will then replace the ``\'' argument---@emph{i.e.}, the new arguments
are inserted in front of @var{fname}, and the argument parser resumes
scanning. This is used to overcome a limitation of the @code{#!} feature: the @code{#!}
line can only specify a single argument after the interpreter.
For example, we might hope the following scsh script, @code{ekko}, would
implement a simple-minded version of the UNIX echo program:

@example
#!/usr/local/bin/scsh -e main -s
!#
(define (main args)
   (map (lambda (arg) (display arg) (display " "))
        (cdr args))
   (newline))
@end example

The idea would be that the command

@example
ekko Hi there.
@end example

would by expanded by the @code{exec(2)} kernel call into

@example
/usr/local/bin/scsh -e main -s ekko Hi there.
@end example

In theory, this would cause scsh to start up, load in file @code{ekko},
call the entry point on the command-line list

@example
(main '("ekko" "Hi" "there."))
@end example

and exit.

Unfortunately, the UNIX @code{exec(2)} syscall's support for scripts is
not very general or well-designed. It will not handle multiple
arguments; the @code{#!} line is usually required to contain no more
than 32 characters; it is not recursive.  If these restrictions are
violated, most UNIX systems will not provide accurate error reporting,
but either fail silently, or simply incorrectly implement the desired
functionality. These are the facts of UNIX life.

In the ekko example above, our @code{#!} trigger line has three
arguments @code{("-e"," main", and "-s")}, so it will not work. The
meta-argument is how we work around this problem. We must instead invoke
the scsh interpreter with the single ``\'' argument, and put the rest of
the arguments on line two of the program. Here's the correct program:

@example
#!/usr/local/bin/scsh \
-e main -s
!#
(define (main args)
   (map (lambda (arg) (display arg) (display " "))
        (cdr args))
   (newline))
@end example

Now, the invocation starts as

@example
ekko Hi there.
@end example

and is expanded by @code{exec(2)} into

@example
/usr/local/bin/scsh \ ekko Hi there.
@end example

When scsh starts up, it expands the ``\'' argument into the arguments read
from line two of @code{ekko}, producing this argument list:

@example
-e main -s ekko Hi there.
@end example

With this argument list, processing proceeds as we intended.

@subsubsection Secondary argument syntax

Scsh uses a very simple grammar to encode the extra arguments on the
second line of the scsh script. The only special characters are space,
tab, newline, and backslash.

@itemize

@item
Each space character terminates an argument. This means that two spaces
in a row introduce an empty-string argument.

@item 
The tab character is not permitted (unless you quote it with the
backslash character described below). This is to prevent the insidious
bug where you believe you have six space characters, but you really have
a tab character, and vice versa.

@item
The newline character terminates an argument, like the space
character,and also terminates the argument sequence. This means that an
empty line parses to the singleton list whose one element is the empty
string: @code{("")}. The grammar doesn't admit the empty list.

@item
The backslash character is the escape character. It escapes backslash,
space, tab, and newline, turning off their special functions, and
allowing them to be included in arguments. The @acronym{ANSI} C escape
sequences (@code{\b}, @code{\n}, @code{\r} and @code{\t}) are also
supported; these also produce argument-constituents--- @code{\n} doesn't
act like a terminating newline. The escape sequence @emph{\nnn} for
exactly three octal digits reads as the character whose @acronym{ASCII}
code is @emph{nnn}. It is an error if a backslash is followed by just
one or two octal digits: @code{\3Q} is an error. Octal escapes are
always constituent characters. Backslash followed by other characters is
not allowed (so we can extend the escape-code space later if we like).
@end itemize

You have to construct these line-two argument lines carefully. In
particular, beware of trailing spaces at the end of the line---they'll
give you extra trailing empty-string arguments. Here's an example:

@example
#!/bin/interpreter \
foo bar quux\ yow
@end example

would produce the arguments

@example
("foo" "bar" "" "quux yow")
@end example

@anchor{Argument Examples}
@subsection Argument Examples

@itemize

@item @code{scsh -dm -m myprog -e top -s myprog.scm}

Load @code{myprog.scm} into the @code{config} package, then shift to
the @code{myprog} package and call @code{(top '("myprog.scm"))}, then
exit. This sort of invocation is typically used in @code{#!} script
lines (see below).

@item @code{scsh -c '(display "Hello, world.")'}

A simple program.

@item @code{scsh -o bigscheme}

Start up interactively in the user package after opening structure
@code{bigscheme}.

@item @code{scsh -o bigscheme - Three args passed}

Start up interactively in the user package after opening
@code{bigscheme}. The @code{command-line-args} variable in the
@code{scsh} package is bound to the list @code{("Three" "args"
"passed")}, and the @code{(command-line)} procedure returns the list
@code{("scsh" "Three" "args" "passed")}.

@item Program @code{ekko}

This shell script, called @code{ekko}, implements a version of the UNIX
@code{echo} program:

@example
#!/usr/local/bin/scsh -s
!#

(for-each (lambda (arg) (display arg) (display " "))
          command-line-args)
@end example

This short program is an example of a @emph{script} --- it executes as
it loads. The UNIX rule for executing @code{#!} shell scripts causes

@example
ekko Hello, world.
@end example

to expand as

@example
/usr/local/bin/scsh -s ekko Hello, world.
@end example

@item Program @code{ekko}

This is the same program, not as a script. Writing it this way makes
it possible to compile the program (and then, for instance, dump it
out as a heap image).

@example
#!/usr/local/bin/scsh \
-e top -s
!#

(define (top args)
  (for-each (lambda (arg) (display arg) (display " "))
            (cdr args)))
@end example

The @code{exec(2)} expansion of the @code{#!} line together with the
scsh expansionof the ``@code{\ ekko}'' meta-argument gives the
following command-line expansion:

@example
ekko Hello, world.

    ==> /usr/local/bin/scsh \ ekko Hello, world.
    ==> /usr/local/bin/scsh -e top -s ekko Hello, world.
@end example

@item Program @code{sort}

This is a program to replace the UNIX @code{sort} utility --- sorting
lines read from standard input, and printing the results on standard
output. Note that the source code defines a general sorting package,
which is useful (1) as a Scheme module exporting sort procedures to
other Scheme code, and (2) as a standalone program invoked from the
@code{top} procedure.

@example
#!/usr/local/bin/scsh \
-dm -m sort-toplevel -e top -s
!#

;;; This is a sorting module. TOP procedure exports the functionality
;;; as a UNIX program akin to sort(1).

(define-structures ((sort-struct (export sort-list
                                         sort-vector!))
                    (sort-toplevel (export top)))
  (open scheme)

  (begin (define (sort-list elts <=) ...)
         (define (sort-vec! vec <=) ...)

         ;; Parse the command line and
         ;; sort stdin to stdout.

         (define (top args)
           ...)))
@end example

The expansion below shows how the command-line scanner (1) loads
theconfig file @code{sort} (written in the Scheme 48 module language),
(2) switches to the package underlying the @code{sort-toplevel}
structure, (3) calls @code{(top '("sort" "foo" "bar"))} in the
package, and finally (4) exits.

@example
sort foo bar
==> /usr/local/bin/scsh \ sort foo bar
==> /usr/local/bin/scsh -dm -m sort-toplevel -e top -s sort foo bar
@end example

An alternate method would have used a

@example
-n #f -o sort-toplevel
@end example

sequence of switches to specify a top-level package.
@end itemize

Note that the sort example can be compiled into a UNIX program by
loading the file into a scsh process, and dumping a heap with
top-level @code{top}. Even if we don't want to export the sort's
functionality as a subroutine library, it is still useful to write the
sort program with the module language. The command line design allows
us to run this program as either an interpreted script (given the
@code{#!} args in the header) or as a compiled heap image.

@anchor{Process exit values}
@subsection Process exit values

Scsh ignores the value produced by its top-level computation when
determining its exit status code. If the top-level computation
completed with no errors, scsh dies with exit code 0. For example, a
scsh process whose top-level is specified by a @code{-c} @var{exp} or
a @code{-e} @var{entry} entry point ignores the value produced by
evaluating @var{exp} and calling @var{entry}, respectively. If these
computations terminate with no errors, the scsh process exits with an
exit code of 0.

To return a specific exit status, use the @code{exit} procedure
explicitly, @emph{e.g.},

@example
scsh -c \

"(exit (status:exit-val (run (| (fmt) (mail shivers)))))"
@end example

@anchor{The scsh virtual machine}
@section The scsh virtual machine

To run the Scheme 48 implementation of scsh, you run a specially
modified copy of the Scheme 48 virtual machine with a scsh heap
image. The scsh binary is actually nothing but a small cover program
that invokes the byte-code interpreter on the scsh heap image for
you. This allows you to simply start up an interactive scsh from a
command line, as well as write shell scripts that begin with the
simple trigger

@example
#!/usr/local/bin/scsh -s
@end example

You can also directly execute the virtual machine, which takes its own
set of command-line switches. For example, this command starts the VM
up with a 1 Mword heap (split into two semispaces):

@example
scshvm -o scshvm -h 1000000 -i scsh.image arg1 arg2 ...
@end example

The VM peels off initial VM arguments up to the @code{-i} heap image
argument, which terminates VM argument parsing. The rest of the
arguments are passed off to the scsh top-level. Scsh's top-level
removes scsh switches, as discussed in the previous section; the rest
show up as the value of @code{command-line-arguments}.

Directly executing the VM can be useful to specify non-standard
switches, or to invoke the virtual machine on special heap images,
which can contain precompiled scsh programs with their own top-level
procedures.

@anchor{VM arguments}
@subsection VM arguments

The VM takes arguments in the following form:

@example
scshvm [@var{meta-arg}] [@var{vm-options+}] [@var{end-option} @var{scheme-args}]
@end example

where

@example
meta-arg:    \ filename

vm-option:  -h heap-size-in-words
            -s stack-size-in-words
            -o object-file-name

end-option: -i image-file-name
             -
@end example

The VM's meta-switch ``\ @var{filename}'' is handled the same as
scsh's meta-switch, and serves the same purpose.

@anchor{VM options}
@subsubsection VM options

The @code{-o} @var{object-file-name} switch tells the VM where to find
relocation information for its foreign-function calls. Scsh will use a
pre-compiled default if it is not specified. Scsh must have this
information to run, since scsh's syscall interfaces are done with
foreign-function calls.

The @code{-h} and @code{-s} options tell the VM how much space to
allocate for the heap and stack. The heap size value is the total
number of words allocated for the heap; this space is then split into
two semi-spaces for Scheme 48's stop-and-copy collector.

@anchor{End options}
@subsubsection End options

End options terminate argument parsing. The @code{-i} switch is
followed by the name of a heap image for the VM to execute. The
@var{image-file-name} string is also taken to be the name of the
program being executed by the VM; this name becomes the head of the
argument list passed to the heap image's top-level entry point. The
tail of the argument list is constructed from all following arguments.

The @code{-} switch terminates argument parsing without giving a
specific heap image; the VM will start up using a default heap (whose
location is compiled into the VM). All the following arguments
comprise the tail of the list passed off to the heap image's top-level
procedure.

Notice that you are not allowed to pass arguments to the heap image's
top-level procedure (@emph{e.g.}, scsh) without delimiting them with
@code{-i} or @code{-} flags.

@anchor{Stripped image}
@subsection Stripped image

Besides the standard image @code{scsh.image} scsh also ships with the
much smaller image @code{stripped-scsh.image}. This image contains the
same code as the standard image but has almost all debugging
information removed. @code{Stripped-scsh.image} is intended to be used
with standalone programs where startup time and memory consumption
count but debugging the Scheme code is not that important. To use the
image the VM has to be called directly and the path to the image must
be given after the @code{-i} argument.

@anchor{Inserting interpreter triggers into heap images}
@subsection Inserting interpreter triggers into heap images

Scheme 48's heap image format allows for an informational header: when
the VM loads in a heap image, it ignores all data occurring before the
first control-L character (@acronym{ASCII} 12). This means that you
can insert a @code{#!} trigger line into a heap image, making it a
form of executable shell script. Since the VM requires multiple
arguments to be given on the command line, you must use the
meta-switch. Here's an example heap-image header:

@example
#!/usr/local/lib/scsh/scshvm \
-o /usr/local/lib/scsh/scshvm -i
... @emph{Your heap image goes here} ...
@end example

@anchor{Inserting a double-level trigger into Scheme programs}
@subsection Inserting a double-level trigger into Scheme programs

If you're a nerd, you may enjoy doing a double-level machine shift in
the trigger line of your Scheme programs with the following magic:

@example
#!/usr/local/lib/scsh/scshvm \
-o /usr/local/lib/scsh/scshvm -i /usr/local/lib/scsh/scsh.image -s
!#
... @emph{Your Scheme program goes here} ...
@end example

@anchor{Compiling scsh programs}
@section Compiling scsh programs

Scsh allows you to create a heap image with your own top-level
procedure. Adding the pair of lines

@example
#!/usr/local/lib/scsh/scshvm \
-o /usr/local/lib/scsh/scshvm -i
@end example

to the top of the heap image will turn it into an executable UNIX file.

You can create heap images with the following two procedures:

@deffn Procedure dump-scsh-program main fname

This procedure writes out a scsh heap image. When the heap image is
executed by the Scheme 48 VM, it will call the @code{main} procedure,
passing it the VM's argument list. When main returns an integer value
@var{i}, the VM exits with exit status @var{i}. The Scheme VM will
parse command-line switches (@pxref{VM options});
remaining arguments form the tail of the command-line list that is
passed to @code{main}. (The head of the list is the name of the
program being executed by the VM.) Further argument parsing (as
described in @pxref{Switches}) is not performed.  The heap image
created by @code{dump-scsh-program} has unused code and data pruned
out, so small programs compile to much smaller heap images.
@end deffn

@deffn Procedure dump-scsh fname

This procedure writes out a heap image with the standard scsh
top-level. When the image is resumed by the vm, it will parse and
execute scsh command-line switches. (@xref{Switches}.) You can use
this procedure to write out custom scsh heap images that have specific
packages preloaded and start up in specific packages.
@end deffn

Unfortunately, Scheme 48 does not support separate compilation of
Scheme files or Scheme modules. The only way to compile is to load
source and then dump out a heap image. One occasionally hears rumours
that this is being addressed by the Scheme 48 development team.

@anchor{Standard file locations}
@section Standard file locations

Because the @code{scshvm} binary is intended to be used for writing
shell scripts, it is important that the binary be installed in a
standard place, so that shell scripts can dependably refer to it. The
standard directory for the scsh tree should be
@code{/usr/local/lib/scsh/}. Whenever possible, the VM should be
located in

@example
/usr/local/lib/scsh/scshvm
@end example

and a scsh heap image should be located in

@example
/usr/local/lib/scsh/scsh.image
@end example

The top-level @code{scsh} program should be located in

@example
/usr/local/lib/scsh/scsh
@end example

with a symbolic link to it from

@example
/usr/local/bin/scsh
@end example

The Scheme 48 image format allows heap images to have @code{#!}
triggers, so @code{scsh.image} should have a @code{#!} trigger of the
following form:

@example
#!/usr/local/lib/scsh/scshvm \
-o /usr/local/lib/scsh/scshvm -i
... @emph{heap image goes here} ...
@end example

@node Index, , Running scsh, Top
@unnumbered Index

@printindex cp
@printindex fn
@printindex vr

@bye 
