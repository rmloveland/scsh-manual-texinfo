\input texinfo  @c -*-texinfo-*-
@c %**start of header
@setfilename scsh.info
@settitle Scsh Reference Manual
@synindex vr fn @c Use `@vindex' and `@findex', respectively.
@c %**end of header


@c Part 2: Summary Description and Copyright
@c -----------------------------------------

@copying
This manual is for scsh, release 0.6.7.

Copyright @copyright{} 2006 Olin Shivers, Brian D. Carlstrom, Martin Gasbichler, and Mike Sperber
@end copying


@c Part 3: Titlepage, Contents, Copyright
@c --------------------------------------

@titlepage
@title Scsh Reference Manual
@subtitle For scsh release 0.6.7

@author Olin Shivers
@author Brian D. Carlstrom
@author Martin Gasbichler
@author Mike Sperber

@c The following two commands start the copyright page.
@page
@vskip 0pt plus 1filll
@insertcopying
@end titlepage

@c Output the table of contents at the beginning.
@contents

@c Part 4: `Top' Node and Master Menu
@c ----------------------------------

@ifnottex
@node Top
@top Scsh Reference Manual

For scsh release 0.6.7

Olin Shivers, Brian D. Carlstrom, Martin Gasbichler, and Mike Sperber
@end ifnottex

@menu
* Acknowledgements::
* Introduction::
* Process notation::
* System Calls::
* Networking::
* Strings and characters::
* Pattern-matching strings with regular expressions::
* Reading delimited strings::
* Awk, record I/O, and field parsing::
* Concurrent system programming::
* Miscellaneous routines::
* Running scsh::
* Index::               Complete index.

@detailmenu
--- The Detailed Node Listing ---

Introduction

* Copyright & source-code license::
* Obtaining scsh::
* Building scsh::
* Caveats::
* Naming conventions::
* Lexical issues::
* Record types and the define-record form::
* A word about Unix standards::

Process notation

* Extended process forms and I/O redirections::
* Process forms::
* Using extended process forms in Scheme::
* More complex process operations::
* Conditional process sequencing forms::
* Process filters::

System Calls

* Errors::
* I/O::
* File system::
* Processes::
* Process state::
* User and group database access::
* Accessing command-line arguments::
* System parameters::
* Signal system::
* Time::
* Environment variables::
* Terminal device control::

Networking

* High-level interface::
* Sockets::
* Socket addresses::
* Socket primitives::
* Performing input and output on sockets::
* Socket options::
* Database-information entries::

Strings and characters

* Manipulating file names::
* Other string manipulation facilities::
* ASCII encoding::
* Character predicates::
* Deprecated character-set procedures::

Pattern-matching strings with regular expressions

* Summary SRE syntax::
* Examples::
* A short tutorial::
* Regexp functions::
* The regexp ADT::
* Syntax-hacking tools::

Reading delimited strings

Awk, record I/O, and field parsing

* Record I/O and field parsing::
* Awk::
* Backwards compatibility::

Concurrent system programming

* Threads::
* Locks::
* Placeholders::
* The event interface to interrupts::
* Interaction between threads and process state::

Miscellaneous routines

* Integer bitwise ops::
* Password encryption::
* Dot-Locking::
* Syslog facility::
* MD5 interface::
* Configuration variables::

Running scsh

* Scsh command-line switches::
* The scsh virtual machine::
* Compiling scsh programs::
* Standard file locations::

@end detailmenu
@end menu


@c Part 5: The Body of the Document
@c --------------------------------

@node Acknowledgements
@chapter Acknowledgements

Who should I thank? My so-called ``colleagues'', who laugh at me
behind my back, all the while becoming famous on @emph{my} work? My
worthless graduate students, whose computer skills appear to be
limited to downloading bitmaps off of netnews? My parents, who are
still waiting for me to quit ``fooling around with computers'', go to
med school, and become a radiologist? My department chairman, a
manager who gives one new insight into and sympathy for disgruntled
postal workers?

My God, no one could blame me--no one!--if I went off the edge and
just lost it completely one day. I couldn't get through the day as it is
without the Prozac and Jack Daniels I keep on the shelf, behind my
Tops-20 JSYS manuals. I start getting the shakes real bad around 10am,
right before my advisor meetings. A 10 oz. Jack 'n Zac helps me get
through the meetings without one of my students winding up with his
severed head in a bowling-ball bag. They look at me funny; they think I
twitch a lot. I'm not twitching. I'm controlling my impulse to snag my
9mm Sig-Sauer out from my day-pack and make a few strong points about
the quality of undergraduate education in Amerika.

If I thought anyone cared, if I thought anyone would even be reading
this, I'd probably make an effort to keep up appearances until the last
possible moment. But no one does, and no one will. So I can pretty much
say exactly what I think.

Oh, yes, the @emph{acknowledgements}. I think not. I did it. I did it
all, by myself.

@flushright
Olin Shivers
Cambridge
September 4, 1994
@end flushright

@node Introduction
@c    Node name, Next, Previous, Up
@chapter Introduction

This is the reference manual for scsh, a Unix shell that is embedded
within Scheme. Scsh is a Scheme system designed for writing useful
standalone Unix programs and shell scripts---it spans a wide range of
application, from ``script'' applications usually handled with perl or
sh, to more standard systems applications usually written in C.

Scsh comes built on top of Scheme 48, and has two components: a
process notation for running programs and setting up pipelines and
redirections, and a complete syscall library for low-level access to the
operating system. This manual gives a complete description of scsh. A
general discussion of the design principles behind scsh can be found in
a companion paper, ``A Scheme Shell''.

@section Copyright & source-code license
Scsh is open source. The complete sources come with the standard
distribution, which can be downloaded off the net. Scsh has an
ideologically hip, BSD-style license.

We note that the code is a rich source for other Scheme implementations
to mine. Not only the @emph{code}, but the @emph{APIs} are available for
implementors working on Scheme environments for systems
programming. These APIs represent years of work, and should provide a
big head-start on any related effort. (Just don't call it ``scsh'',
unless it's @emph{exactly} compliant with the scsh interfaces.)

Take all the code you like; we'll just write more.

@section Obtaining scsh
Scsh is distributed via net publication. We place new releases at
well-known network sites, and allow them to propagate from there. We
currently release scsh to the following Internet sites:

@flushleft
@url{ftp://ftp.scsh.net/pub/scsh}
@url{http://prdownloads.sourceforge.net/scsh/}
@end flushleft

Each should have a compressed tar file of the entire scsh release, which
includes all the source code and the manual, and a separate file
containing just this manual in Postscript form, for those who simply
wish to read about the system.

However, nothing is certain for long on the Net. Probably the best way
to get a copy of scsh is to use a network resource-discovery tool, such
as archie, to find ftp servers storing scsh tar files. Take the set of
sites storing the most recent release of scsh, choose one close to your
site, and download the tar file.

@section Building scsh
Scsh currently runs on a fairly large set of Unix systems, including
Linux, FreeBSD, OpenBSD, NetBSD, MacOS X, SunOS, Solaris, AIX, NeXTSTEP,
Irix, and HP-UX. We use the Gnu project's autoconfig tool to generate
self-configuring shell scripts that customise the scsh Makefile for
different OS variants. This means that if you use one of the common Unix
implementations, building scsh should require exactly the following
steps:

@example
gunzip scsh.tar.gz      # Uncompress the release tar file.
untar xfv scsh.tar      # Unpack the source code.
cd scsh-0.6.x           # Move to the source directory.
./configure             # Examine host; build Makefile.
make                    # Build system.
@end example

When you are done, you should have a virtual machine compiled in file
`scshvm', and a heap image in file `scsh/scsh.image'. Typing

@example
make install
@end example

will install these programs in your installation directory (by default,
@code{/usr/local}), along with a small stub startup binary, @code{scsh}.

If you don't have the patience to do this, you can start up a Scheme
shell immediately after the initial make by simply saying

@example
./scshvm -o ./scshvm -i scsh/scsh.image
@end example

See @ref{Running scsh} for full details on installation locations and
startup options.

It is not too difficult to port scsh to another Unix platform if your OS
is not supported by the current release. See the release notes for more
details on how to do this.

@section Caveats
It is important to note what scsh is not, as well as what it is. Scsh,
in the current release, is primarily designed for the writing of shell
scripts---programming.  It is not a very comfortable system for
interactive command use: the current release lacks job control,
command-line editing, a terse, convenient command syntax, and it does
not read in an initialisation file analogous to @code{.login} or
@code{.profile}. We hope to address all of these issues in future
releases; we even have designs for several of these features; but the
system as-released does not currently provide these features.

@section Naming conventions
Scsh follows a general naming scheme that consistently employs a set of
abbreviations. This is intended to make it easier to remember the names
of things.  Some of the common ones are:

@defvr fdes
Means ``file descriptor'', a small integer used in Unix to represent I/O
channels.
@end defvr

@defvr ...*
A given bit of functionality sometimes comes in two related forms,
the first being a special form that contains a body of Scheme code to be
executed in some context, and the other being a procedure that takes a
procedural argument (a ``thunk'') to be called in the same context. The
procedure variant is named by taking the name of the special form, and
appending an asterisk. For example:

@example
;;; Special form:
(with-cwd "/etc"
  (for-each print-file (directory-files))
  (display "All done"))

;;; Procedure:
(with-cwd* "/etc"
  (lambda ()
    (for-each print-file (directory-files))
    (display "All done")))
@end example
@end defvr

@defvr @emph{action/modifier}
The infix ``/'' is pronounced ``with'', as in @code{exec/env}---
``exec with environment''.
@end defvr

@defvr call/...
Procedures that call their argument on some computed value are usually
named @code{call/@dots{}}, e.g., @code{(call/fdes port proc)}, which
calls @code{proc} on @code{port}'s file descriptor, returning whatever
@code{proc} returns. The abbreviated name means ``call with file
descriptor''.
@end defvr

@defvr with-...
Procedures that call their argument, and special forms that execute
their bodies in some special dynamic context frequently have names of
the form @code{with-@dots{}}. For example, @code{(with-env env
@math{body_1} @dots{})} and @code{(with-env* env thunk)}. These forms
set the process environment body, execute their body or thunk, and
then return after resetting the environment to its original state.
@end defvr

@defvr create-...
Procedures that create objects in the file system (files,
directories,temp files, fifos, etc.), begin with
@code{create-@dots{}}.
@end defvr

@defvr delete-...
Procedures that delete objects from the file system (files,
directories,temp files, fifos, etc.), begin with
@code{delete-@dots{}}.
@end defvr

@defvr @emph{record:field}
Procedures that access fields of a record are usually written with a
colon between the name of the record and the name of the field, as in
@code{user-info:home-dir}.
@end defvr

@defvr %...
A percent sign is used to prefix lower-level scsh primitives that are
not commonly used.
@end defvr

@defvr ...-info
Data structures packaging up information about various OS entities
frequently end in @dots{}@code{-info}. Examples: @code{user-info},
@code{file-info}, @code{group-info}, and @code{host-info}.
@end defvr

Enumerated constants from some set @code{s} are usually named
@code{s/@math{const_1}}, @code{s/@math{const_2}}, @dots{}. For
example, the various Unix signal integers have the names
@code{signal/cont}, @code{signal/kill}, @code{signal/int},
@code{signal/hup}, and so forth.

@section Lexical issues
Scsh's lexical syntax is just R5RS Scheme, with the following exceptions.

@subsection Extended symbol syntax
Scsh's symbol syntax differs from R5RS Scheme in the following ways:

@itemize @bullet
@item
In scsh, symbol case is preserved by @code{read} and is significant on
symbol comparison. This means

@example
(run (less Readme))
@end example

displays the right file.

@item
``-'' and ``+'' are allowed to begin symbols. So the following are
legitimate symbols:

@example
-O2 -geometry +Wn
@end example

@item
``|'' and ``.'' are symbol constituents. This allows @code{|} for the
pipe symbol, and @code{..} for the parent-directory symbol. (Of course,
``.'' alone is not a symbol, but a dotted-pair marker.)

@item
A symbol may begin with a digit. So the following are legitimate symbols:

@example
9x15 80x36-3+440
@end example
@end itemize

@subsection Extended string syntax
Scsh strings are allowed to contain the @acronym{ANSI} C escape sequences such as
@code{\n} and @code{\161}.

@subsection Block comments and executable interpreter-triggers
Scsh allows source files to begin with a header of the form

@example
#!/usr/local/bin/scsh -s
@end example

The Unix operating system treats source files beginning with the headers
of this form specially; they can be directly executed by the operating
system (see @ref{Running scsh} for information on how to use this
feature). The scsh interpreter ignores this special header by treating
@code{#!} as a comment marker similar to @code{;}. When the scsh reader
encounters @code{#!}, it skips characters until it finds the closing
sequence newline/exclamation-point/sharp-sign/newline.

Although the form of the @code{#!} read-macro was chosen to support
interpreter-triggers for executable Unix scripts, it is a general
block-comment sequence and can be used as such anywhere in a scsh
program.

@subsection Here-strings
The read macro @code{#<} is used to introduce ``here-strings'' in
programs, similar to the @code{<<} ``here document'' redirections
provided by sh and csh. There are two kinds of here-string,
character-delimited and line-delimited; they are both introduced by the
@code{#<} sequence.

@subsubsection Character-delimited here-strings
A character-delimited here-string has the form

@example
#<x ... stuff ... x
@end example

where @emph{x} is any single character (except @code{<}, see below),
which is used to delimit the string bounds. Some examples of
here-strings and their Scheme equivalents:

@table @code
@item #<|Hello, world.|
@code{"Hello, world."}
@item #<!"Ouch," he said.!
@code{"\"Ouch,\" he said."}
@end table

There is no interpretation of characters within the here-string; the
characters are all copied verbatim.

@subsubsection Line-delimited here-strings
If the sequence begins ``@code{#<<}'' then it introduces a line-delimited
here-string. These are similar to the ``here documents'' of @code{sh} and
@code{csh}. Line-delimited here-strings are delimited by the rest of the text
line that follows the @code{#<<} sequence. For example:

@example
#<<FOO
Hello, there.
This is read by Scheme as a string,
terminated by the first occurrence
of newline-F-O-O-newline or newline-F-O-O-@acronym{eof}.
FOO
@end example

Thus,

@example
#<<foo
Hello, world.
foo
@end example

is the same thing as

@example
"Hello, world."
@end example

Line-delimited here-strings are useful for writing down long, constant
strings---such as long, multi-line @code{format} strings, or arguments
to Unix programs, e.g.,

@example
;; Free up some disk space for my netnews files.
(run (csh -c #<<EOF
cd /urops
rm -rf *
echo All done.

EOF
))
@end example

The advantage they have over the double-quote syntax (e.g., "@code{Hello,
world.}") is that there is no need to backslash-quote special characters
internal to the string, such as the double-quote or backslash
characters.

The detailed syntax of line-delimited here-strings is as follows. The
characters ``@code{#<<}'' begin the here-string. The characters
between the ``@code{#<<} '' and the next newline are the delimiter
line. All characters between the ``@code{#<<}'' and the next newline
comprise the delimiter line---including any white space. The body of
the string begins on the following line, and is terminated by a line
of text which exactly matches the delimiter line. This terminating
line can be ended by either a newline or end-of-file. Absolutely no
interpretation is done on the input string. Control characters, white
space, quotes, backslash---everything is copied as-is. The newline
immediately preceding the terminating delimiter line is not included
in the result string (leave an extra blank line if you need to put a
final newline in the here-string---see the example above). If @acronym{eof} is
encountered before reading the end of the here-string, an error is
signalled.

@subsection Dot
It is unfortunate that the single-dot token, ``.'', is both a
fundamental Unix filename and a deep, primitive syntactic token in
Scheme -- it means the following will not parse correctly in scsh:

@example
(run/strings (find . -name *.c -print))
@end example

You must instead quote the dot:

@example
(run/strings (find "." -name *.c -print))
@end example

When you write shell scripts that manipulate the file system, keep in
mind the special status of the dot token.

@section Record types and the define-record form
@cindex define-record

Scsh's interfaces occasionally provide data in structured record types;
an example is the @code{file-info} record whose various fields describe
the size, protection, last date of modification, and other pertinent
data for a particular file. These record types are described in this
manual using the @code{define-record} notation, which looks like the
following:

@example
(define-record ship
  x
  y
  (size 100))
@end example

This form defines a @emph{ship} record, with three fields: its x and y
coordinates, and its size. The values of the @code{x} and @code{y} fields
are specified as parameters to the ship-building procedure,
@code{(make-ship x y)}, and the @emph{size} field is initialised to
100. All told, the @code{define-record} form above defines the following
procedures:

@table @code
@item (make-ship x y)
Create a new @emph{ship} record.
@item (ship:x ship)
Retrieve the @emph{x} field.
@item (ship:y ship)
Retrieve the @emph{y} field.
@item (ship:size ship)
Retrieve the @emph{size} field.
@item (set-ship:x ship new-x)
Assign the @emph{x} field.
@item (set-ship:y ship new-y)
Assign the @emph{y} field.
@item (set-ship:size ship new-size)
Assign the @emph{size} field.
@item (modify-ship:x ship xfun)
Modify @emph{x} field with @emph{xfun}.
@item (modify-ship:y ship yfun)
Modify @emph{y} field with @emph{yfun}.
@item (modify-ship:size ship sizefun)
Modify @emph{size} field with @emph{sizefun}.
@item (ship? object)
Type predicate.
@item (copy-ship ship)
Shallow-copy of the record.
@end table

An implementation of @code{define-record} is available as a macro for
Scheme programmers to define their own record types; the syntax is
accessed by opening the package @code{defrec-package}, which exports the
single syntax form @code{define-record}. See the source code for the
@code{defrec-package} module for further details of the macro.

You must open this package to access the form. Scsh does not export a
record-definition package by default as there are several from which to
choose. Besides the @code{define-record} macro, which Shivers
prefers@footnote{He wrote it.}, you might instead wish to employ the
notationally-distinct @code{define-record-type} macro that Jonathan Rees
prefers@footnote{He wrote it.}. It can be found in the
@code{define-record-types} structure.

Alternatively, you may define your own, of course.

@section A word about Unix standards
``The wonderful thing about Unix standards is that there are so many to
choose from''. You may be totally bewildered about the multitude of
various standards that exist. Rest assured that nowhere in this manual
will you encounter an attempt to spell it all out for you; you could not
read and internalise such a twisted account without bleeding from the
nose and ears.

However, you might keep in mind the following simple fact: of all the
standards, @acronym{POSIX} is the least common denominator. So when
this manual repeatedly refers to @acronym{POSIX}, the point is ``the
thing we are describing should be portable just about anywhere''. Scsh
sticks to @acronym{POSIX} when at all possible; its major departure is
symbolic links, which aren't in @acronym{POSIX} (see---it really
@emph{is} a least common denominator).

@node Process notation, System Calls, Introduction, Top
@c    Current,          Next,         Previous,     Up
@chapter Process notation

Scsh has a notation for controlling Unix processes that takes the form
of s-expressions; this notation can then be embedded inside of
standard Scheme code. The basic elements of this notation are
@emph{process forms}, @emph{extended process forms}, and
@emph{redirections}.

@section Extended process forms and I/O redirections
An extended process form is a specification of a Unix process to run,
in a particular I/O environment:

@example
@emph{epf} ::= (@emph{pf} @math{redir_1 ... redir_n})
@end example

where @emph{pf} is a process form and the @math{redir_i} are
redirection specs. A @emph{redirection spec} is one of:

@table @code
@item (< @emph{[fdes]} @emph{file-name})
Open file for read.
@item (> @emph{[fdes]} @emph{file-name})
Open file create/truncate.
@item (<< @emph{[fdes]} @emph{object})
Use @emph{object}'s printed representation.
@item (>> @emph{[fdes]} @emph{file-name})
Open file for append.
@item (= @emph{fdes} @emph{fdes/port})
Dup2
@item (- fdes/port)
Close @emph{fdes/port}.
@item stdports
0,1,2 dup'd from standard ports.
@end table

The input redirections default to file descriptor 0; the output
redirections default to file descriptor 1.

The subforms of a redirection are implicitly backquoted, and symbols
stand for their print-names. So @code{(> ,x)} means ``output to the
file named by Scheme variable @emph{x}'', and @code{(<
/usr/shivers/.login)} means ``read from @code{/usr/shivers/.login}''.

Here are two more examples of I/O redirection:

@example
(< ,(vector-ref fv i))
(>> 2 /tmp/buf)
@end example

These two redirections cause the file @code{fv[i]} to be opened on
stdin, and @code{/tmp/buf} to be opened for append writes on stderr.

The redirection @code{(<< @emph{object})} causes input to come from
the printed representation of @emph{object}. For example,

@example
(<< "The quick brown fox jumped over the lazy dog.")
@end example

causes reads from stdin to produce the characters of the above
string. The object is converted to its printed representation using
the @code{display} procedure, so

@example
(<< (A five element list))
@end example

is the same as

@example
(<< "(A five element list)")
@end example

is the same as

@example
(<< ,(reverse '(list element five A))).
@end example

(Here we use the implicit backquoting feature to compute the list to
be printed.)

The redirection @code{(= @emph{fdes} @emph{fdes/port})} causes
@emph{fdes/port} to be dup'd into file descriptor @emph{fdes}. For
example, the redirection

@example
(= 2 1)
@end example

causes stderr to be the same as stdout. @emph{Fdes/port} can also be a
port, for code:

@example
(= 2 ,(current-output-port))
@end example

causes stderr to be @code{dup}'d from the current output port. In this case, it
is an error if the port is not a file port (e.g., a string port). More
complex redirections can be accomplished using the @code{begin} process
form, discussed below, which gives the programmer full control of I/O
redirection from Scheme.

@subsection Port and file descriptor sync
It's important to remember that rebinding Scheme's current I/O ports
(e.g.,using @code{call-with-input-file} to rebind the value of
@code{(current-input-port)}) does @emph{not} automatically ``rebind''
the file referenced by the Unix stdio file descriptors 0, 1, and
2. This is impossible to do in general, since some Scheme ports are
not representable as Unix file descriptors. For example, many Scheme
implementations provide ``string ports'', that is, ports that collect
characters sent to them into memory buffers. The accumulated string
can later be retrieved from the port as a string. If a user were to
bind @code{(current-output-port)} to such a port, it would be
impossible to associate file descriptor 1 with this port, as it cannot
be represented in Unix. So, if the user subsequently forked off some
other program as a subprocess, that program would of course not see
the Scheme string port as its standard output.

To keep stdio synced with the values of Scheme's current I/O ports,
use the special redirection @code{stdports}. This causes 0, 1, 2 to be
redirected from the current Scheme standard ports. It is equivalent to
the three redirections:

@example
(= 0 ,(current-input-port))
(= 1 ,(current-output-port))
(= 2 ,(error-output-port))
@end example

The redirections are done in the indicated order. This will cause an
error if one of the current I/O ports isn't a Unix port (e.g., if one is
a string port). This Scheme/Unix I/O synchronisation can also be had in
Scheme code (as opposed to a redirection spec) with the
@code{(stdports->stdio)} procedure.

@section Process forms
A @emph{process form} specifies a computation to perform as an
independent Unix process. It can be one of the following:

@table @code 
@item (begin . @emph{scheme-code})
Run @emph{scheme-code} in a fork.
@item (| @math{pf_1} @dots{} @math{pf_n})
Simple pipeline.
@item (|+ @emph{connect-list} @math{pf_1} @dots{} @math{pf_n})
Complex pipeline.
@item (epf . @emph{epf})
An extended process form.
@item (prog @math{arg_1} @dots{} @math{arg_n})
Default: exec the program.
@end table

The default case @code{(@emph{prog} @math{arg_1} @dots{}
@math{arg_n})} is also implicitly backquoted. That is, it is
equivalent to:

@example
(begin (apply exec-path `(@emph{prog} @math{arg_1} @dots{} @math{arg_n})))
@end example

@code{Exec-path} is the version of the @code{exec(3)} system call that
uses scsh's path list to search for an executable. The program and the
arguments must be either strings, symbols, or integers. Symbols and
integers are coerced to strings. A symbol's print-name is
used. Integers are converted to strings in base 10. Using symbols
instead of strings is convenient, since it suppresses the clutter of
the surrounding ``@dots{}''  quotation marks. To aid this purpose,
scsh reads symbols in a case-sensitive manner, so that you can say

@example
(more Readme)
@end example

and get the right file.

A @emph{connect-list} is a specification of how two processes are to
be wired together by pipes. It has the form @code{((@math{from_1}
@math{from_2} @dots{} @emph{to}) @dots{})} and is implicitly
backquoted. For example,

@example
(|+ ((1 2 0) (3 1)) @math{pf_1} @math{pf_2})
@end example

runs @math{pf_1} and @math{pf_2}. The first clause @code{(1 2 0)}
causes @math{pf_1}'s stdout (1) and stderr (2) to be connected via
pipe to @math{pf_2}'s stdin (0). The second clause @code{(3 1)} causes
@math{pf_1}'s file descriptor 3 to be connected to @math{pf_2}'s file
descriptor 1.The @code{begin} process form does a
@code{stdio->stdports} synchronisation in the child process before
executing the body of the form. This guarantees that the @code{begin}
form, like all other process forms, "sees" the effects of any
associated I/O redirections.

Note that R5RS does not specify whether or not @code{|} and @code{|+}
are readable symbols. Scsh does.

@section Using extended process forms in Scheme
Process forms and extended process forms are not Scheme. They are a
different notation for expressing computation that, like Scheme, is
based upon s-expressions. Extended process forms are used in Scheme
programs by embedding them inside special Scheme forms. There are
three basic Scheme forms that use extended process forms:
@code{exec-epf}, @code{&}, and @code{run}.

@deffn Macro exec-epf . epf
The @code{(exec-epf . @var{epf})} form nukes the current process: it
establishes the I/O redirections and then overlays the current process
with the requested computation.
@end deffn

@deffn Macro & . epf
The @code{(& . @var{epf})} form is similar to @code{exec-epf}, except
that the process is forked off in background. The form returns the
subprocess' process object.
@end deffn

@deffn Macro run . epf
The @code{(run . @var{epf})} form runs the process in foreground:
after forking off the computation, it waits for the subprocess to
exit, and returns its exit status.
@end deffn

These special forms are macros that expand into the equivalent series
of system calls. The definition of the @code{exec-epf} macro is
non-trivial, as it produces the code to handle I/O redirections and
set up pipelines. However, the definitions of the @code{&} and
@code{run} macros are very simple:

@table @code
@item (& . @emph{epf})
@equiv{} @code{(fork (lambda () (exec-epf . @emph{epf})))}
@item (run . @emph{epf})
@equiv{} @code{(wait (& . @emph{epf}))}
@end table

@subsection Procedures and special forms
It is a general design principle in scsh that all functionality made
available through special syntax is also available in a
straightforward procedural form.  So there are procedural equivalents
for all of the process notation. In this way, the programmer is not
restricted by the particular details of the syntax. Here are some of
the syntax/procedure equivalents:

@table @code
@item |
@code{fork/pipe}
@item |+
@code{fork/pipe+}
@item exec-epf
@code{exec-path}
@item @emph{redirection}
@code{open}, @code{dup}
@item &
@code{fork}
@item run
@code{wait} + @code{fork}
@end table

Having a solid procedural foundation also allows for general
notational experimentation using Scheme's macros. For example, the
programmer can build his own pipeline notation on top of the
@code{fork} and @code{fork/pipe} procedures. @ref{System Calls} for
the full story on all the procedures in the syscall library.

@subsection Interfacing process output to Scheme
There is a family of procedures and special forms that can be used to
capture the output of processes as Scheme data.

@deffn Macro run/port . epf        
Value is a port open on process' stdout. Returns immediately after
forking child.
@end deffn

@deffn Macro run/file . epf        
Value is name of a temp file containing process' output. Returns when
process exits.
@end deffn

@deffn Macro run/string . epf      
Value is a string containing process' output. Returns when @acronym{eof} read.
@end deffn

@deffn Macro run/strings . epf     
Splits process' output into a list of newline-delimited
strings. Returns when @acronym{eof} read.
@end deffn

@deffn Macro run/sexp . epf        
Reads a single object from process' stdout with @code{read}. Returns
as soon as the read completes.
@end deffn

@deffn Macro run/sexps . epf       
Repeatedly reads objects from process' stdout with
@code{read}. Returns accumulated list upon @acronym{eof}.
@end deffn

These forms all fork off subprocesses, collecting the process' output
to stdout in some form or another. The subprocess runs with file
descriptor 1 and the current output port bound to a pipe.

The delimiting newlines are not included in the strings returned by
@code{run/strings}.

These special forms just expand into calls to the following analogous
procedures.

@ftable @code
@item (run/port* @emph{thunk})       
-> @code{port} (procedure)
@item (run/file* @emph{thunk})       
-> @code{string} (procedure)
@item (run/string* @emph{thunk})     
-> @code{string} (procedure)
@item (run/strings* @emph{thunk})    
-> @code{string list} (procedure)
@item (run/sexp* @emph{thunk})       
-> @code{object} (procedure)
@item (run/sexps* @emph{thunk})      
-> @code{object list} (procedure)
@end ftable

For example, @code{(run/port . epf)} expands into

@code
(run/port* (* () (exec-epf . epf))).
@end code

The following procedures are also of utility for generally parsing
input streams in scsh:

@ftable @code
@item (@emph{port}->string @emph{port})             
-> @emph{string} (procedure)
@item (@emph{port}->sexp-list @emph{port})          
-> @emph{list} (procedure)
@item (@emph{port}->string-list @emph{port})        
-> @emph{string list}  (procedure)
@item (@emph{port}->list @emph{reader} @emph{port})        
-> @emph{list} (procedure)
@end ftable

@code{Port->string} reads the port until @acronym{eof}, then returns the
accumulated string. @code{Port->sexp-list} repeatedly reads data from
the port until @acronym{eof}, then returns the accumulated list of
items. @code{Port->string-list} repeatedly reads newline-terminated
strings from the port until @acronym{eof}, then returns the accumulated list of
strings. The delimiting newlines are not part of the returned
strings. @code{Port->list} generalises these two procedures. It uses
@emph{reader} to repeatedly read objects from a port. It accumulates
these objects into a list, which is returned upon @acronym{eof}. The
@code{port->string-list} and @code{port->sexp-list} procedures are
trivial to define, being merely @code{port->list} curried with the
appropriate parsers:

@example
(port->string-list port) @equiv{} (port->list read-line port)
(port->sexp-list port)   @equiv{} (port->list read port)
@end example

The following compositions also hold:

@example
run/string*     @equiv{} port->string            run/port*
run/strings*    @equiv{} port->string-list       run/port*
run/sexp*       @equiv{} read                    run/port*
run/sexps*      @equiv{} port->sexp-list         run/port*
@end example

@ftable @code
@item (port-fold @emph{port} @emph{reader} @emph{op} . @emph{seeds})
-> @emph{object*}      (procedure)
@end ftable

This procedure can be used to perform a variety of iterative
operations over an input stream. It repeatedly uses @emph{reader} to
read an object from @emph{port}. If the first read returns @acronym{eof}, then
the entire @code{port-fold} operation returns the seeds as multiple
values. If the first read operation returns some other value @emph{v},
then @emph{op} is applied to @emph{v} and the seeds:
@code{(@emph{op} @emph{v} . @emph{seeds})}. This should return a new
set of seed values, and the reduction then loops, reading a new value
from the port, and so forth. (If multiple seed values are used, then
@emph{op} must return multiple values.)

For example, @code{(port->list @emph{reader} @emph{port})} could be
defined as

@code
(reverse (port-fold @emph{port} @emph{reader} cons '()))
@end code

An imperative way to look at @code{port-fold} is to say that it
abstracts the idea of a loop over a stream of values read from some
port, where the seed values express the loop state.

@emph{Remark}: This procedure was formerly named
@code{reduce-port}. The old binding is still provided, but is
deprecated and will probably vanish in a future release.

@section More complex process operations
The procedures and special forms in the previous section provide for
the common case, where the programmer is only interested in the output
of the process. These special forms and procedures provide more
complicated facilities for manipulating processes.

@subsection Pids and ports together
@ftable @code 
@item (run/port+proc . @emph{epf})
-> @emph{[port proc]}          (syntax)
@item (run/port+proc* @emph{thunk})
-> @emph{[port proc]}          (procedure)
@end ftable

This special form and its analogous procedure can be used if the
programmer also wishes access to the process' pid, exit status, or
other information. They both fork off a subprocess, returning two
values: a port open on the process' stdout (and current output port),
and the subprocess's process object. A process object encapsulates the
subprocess' process id and exit code; it is the value passed to the
@code{wait} system call.

For example, to uncompress a tech report, reading the uncompressed
data into scsh, and also be able to track the exit status of the
decompression process, use the following:

@code
(receive (port child) (run/port+proc (zcat tr91-145.tex.Z))
  (let* ((paper (port->string port))
    (status (wait child)))
      @dots{} @emph{use paper, status, and child here} @dots{} ))
@end code

Note that you must @emph{first} do the @code{port->string} and
@emph{then} do the @code{wait} -- the other way around may lock up
when the @code{zcat} fills up its output pipe buffer.

@subsection Multiple stream capture
Occasionally, the programmer may want to capture multiple distinct
output streams from a process. For instance, he may wish to read the
stdout and stderr streams into two distinct strings. This is
accomplished with the @code{run/collecting} form and its analogous
procedure, @code{run/collecting*}.

@ftable @code
@item (run/collecting @emph{fds . epf} )
-> @emph{[status port @dots{}]}  (syntax)
@item (run/collecting* @emph{fds thunk})
-> @emph{[status port @dots{}]}  (procedure)
@end ftable

@code{Run/collecting} and @code{run/collecting*} run processes that
produce multiple output streams and return ports open on these
streams. To avoid issues of deadlock, @code{run/collecting} doesn't use
pipes. Instead, it first runs the process with output to temp files,
then returns ports open on the temp files. For example,

@code
(run/collecting (1 2) (ls))
@end code

runs @code{ls} with stdout (fd 1) and stderr (fd 2)
redirected to temporary files. When the @code{ls} is done,
@code{run/collecting} returns three values: the @code{ls} process' exit
status, and two ports open on the temporary files. The files are deleted
before @code{run/collecting} returns, so when the ports are closed, they
vanish. The @emph{fds} list of file descriptors is implicitly backquoted
by the special-form version.

For example, if Kaiming has his mailbox protected, then

@code
(receive (status out err)
         (run/collecting (1 2) (cat /usr/kmshea/mbox))
   (list status (port->string out) (port->string err)))
@end code

might produce the list

@code
(256 "" "cat: /usr/kmshea/mbox: Permission denied")
@end code

What is the deadlock hazard that causes @code{run/collecting} to use
tempfiles? Processes with multiple output streams can lock up if they
use pipes to communicate with Scheme I/O readers. For example, suppose
some Unix program @code{myprog} does the following:

@enumerate
@item
First, outputs a single "(" to stderr.
@item
Then, outputs a megabyte of data to stdout.
@item
Finally, outputs a single ")" to stderr, and exits.
@end enumerate

Our scsh programmer decides to run @code{myprog} with stdout and
stderr redirected via Unix pipes to the ports @emph{port1} and
@emph{port2}, respectively. He gets into trouble when he subsequently
says @code{(read @emph{port2})}. The Scheme @code{read} routine reads
the open paren, and then hangs in a @code{read(2)} system call trying
to read a matching close paren. But before @code{myprog} sends the
close paren down the stderr pipe, it first tries to write a megabyte
of data to the stdout pipe. However, Scheme is not reading that pipe
-- it's stuck waiting for input on stderr. So the stdout pipe quickly
fills up, and @code{myprog} hangs, waiting for the pipe to drain. The
@code{myprog} child is stuck in a stdout/@emph{port1} write; the
Scheme parent is stuck in a stderr/@emph{port2} read. Deadlock.

Here's a concrete example that does exactly the above:

@code
(receive (status port1 port2)
         (run/collecting (1 2)
         (begin
                ;; Write an open paren to stderr.
                (run (echo "(") (= 1 2))
                ;; Copy a lot of stuff to stdout.
                (run (cat /usr/dict/words))
                ;; Write a close paren to stderr.
                (run (echo ")") (= 1 2))))

         ;; OK. Here, I have a port PORT1 built over a pipe
         ;; connected to the BEGIN subproc's stdout, and
         ;; PORT2 built over a pipe connected to the BEGIN
         ;; subproc's stderr.
         (read port2) ; Should return the empty list.
         (port->string port1)) ; Should return a big string.
@end code

In order to avoid this problem, @code{run/collecting} and
@code{run/collecting*} first run the child process to completion,
buffering all the output streams in temp files (using the
@code{temp-file-channel} procedure, see below). When the child process
exits, ports open on the buffered output are returned. This approach
has two disadvantages over using pipes:

@itemize @bullet
@item
The total output from the child output is temporarily written to the
disk before returning from @code{run/collecting}. If this output is
some large intermediate result, the disk could fill up.
@item
The child producer and Scheme consumer are serialised; there is no
concurrency overlap in their execution.
@end itemize

However, it remains a simple solution that avoids deadlock. More
sophisticated solutions can easily be programmed up as
needed---@code{run/collecting*} itself is only 12 lines of simple
code.

See @code{temp-file-channel} for more information on creating temp
files as communication channels.

@section Conditional process sequencing forms
These forms allow conditional execution of a sequence of processes.

@ftable @code
@item (|| @math{pf_1} @dots{} @math{pf_n})
-> @emph{boolean} (syntax)
@end ftable

Run each proc until one completes successfully (i.e., exit status
zero). Return true if some proc completes successfully; otherwise
@code{#f}.

@ftable @code
@item (&& pf1 . . . pfn)
-> @emph{boolean} (syntax)
@end ftable

Run each proc until one fails (i.e., exit status non-zero). Return
true if all procs complete successfully; otherwise @code{#f}.

@section Process filters
These procedures are useful for forking off processes to filter text
streams.

@ftable @code
@item (make-char-port-filter @emph{filter})
-> @emph{procedure} (procedure)
@end ftable

The @emph{filter} argument is a character->character
procedure. Returns a procedure that when called, repeatedly reads a
character from the current input port, applies @emph{filter} to the
character, and writes the result to the current output port. The
procedure returns upon reaching @acronym{eof} on the input port.  For example,
to downcase a stream of text in a spell-checking pipeline, instead of
using the Unix @code{tr A-Z a-z} command, we can say:

@code
(run (| (delatex)
        (begin ((char-filter char-downcase))) ; tr A-Z a-z
        (spell)
        (sort)
        (uniq))
     (< scsh.tex)
     (> spell-errors.txt))
@end code

@ftable @code
@item (make-string-port-filter @emph{filter [buflen]})
-> @emph{procedure} (procedure)
@end ftable

The @emph{filter} argument is a string->string procedure. Returns a
procedure that when called, repeatedly reads a string from the current
input port, applies @emph{filter} to the string, and writes the result
to the current output port.The procedure returns upon reaching @acronym{eof} on
the input port.

The optional @emph{buflen} argument controls the number of characters
each internal read operation requests; this means that @emph{filter}
will never be applied to a string longer than @emph{buflen} chars. The
default @emph{buflen} value is 1024.

@node System Calls, Networking, Process notation, Top
@c    Current,      Next,       Previous,         Up
@chapter System Calls

Scsh provides (almost) complete access to the basic Unix kernel
services: pro-cesses, files, signals and so forth. These procedures
comprise a Scheme binding for @acronym{POSIX}, with a few of the more
standard extensions thrown in (e.g., symboliclinks, @code{fchown},
@code{fstat}, @code{sockets}).

@section Errors
Scsh syscalls never return error codes, and do not use a global
@code{errno} variable to report errors. Errors are consistently
reported by raising exceptions. This frees up the procedures to return
useful values, and allows the programmer toassume that @emph{if a
syscall returns, it succeeded}. This greatly simplifies the flow of
the code from the programmer's point of view.

Since Scheme does not yet have a standard exception system, the scsh
definition remains somewhat vague on the actual form of exceptions and
exception handlers. When a standard exception system is defined, scsh
will move to it.For now, scsh uses the Scheme 48 exception system,
with a simple sugaring on top to hide the details in the common case.

System call error exceptions contain the Unix @code{errno} code
reported by the system call. Unlike C, the @code{errno} value is a
part of the exception packet, it is not accessed through a global
variable.

For reference purposes, the Unix @code{errno} numbers are bound to the
variables @code{errno/perm}, @code{errno/noent}, etc. System calls
never return @code{error/intr}---they automatically retry.

@ftable @code
@item (errno-error @emph{errno syscall . data})
-> @emph{no return value} (procedure)
@end ftable

Raises a Unix error exception for Unix error number @code{errno}. The
syscall and data arguments are packaged up in the exception packet
passed to the exception handler.

(with-errno-handler* handler thunk) -! value(s) of thunk procedure
(with-errno-handler handler-spec . body) -! value of body syntax

Unix syscalls raise error exceptions by calling errno-error. Programscan use

with-errno-handler* to establish handlers for these exceptions.

If a Unix error arises while thunk is executing, handler is called on twoarguments like this:

(handler errno packet)
packet is a list of the form

packet = (errno-msg syscall . data),
where errno-msg is the standard Unix error message for the error, syscallis the procedure that generated the error, and data is a list of information
generated by the error, which varies from syscall to syscall.
If handler returns, the handler search continues upwards. Handler canacquire the exception by invoking a saved continuation. This procedure

can be sugared over with the following syntax:

(with-errno-handler

((errno packet) clause ...)body1

body2
...)

This form executes the body forms with a particular errno handler in-stalled. When an errno error is raised, the handler search machinery

will bind variable errno to the error's integer code, and variable packetto the error's auxiliary data packet. Then, the clauses will be checked for
a match. The first clause that matches is executed, and its value is thevalue of the entire

with-errno-handler form. If no clause matches, thehandler search continues.

Error clauses have two forms

((errno ...) body ...)
(else body ...)

In the first type of clause, the errno forms are integer expressions. Theyare evaluated and compared to the error's errno value. An else clause matches any errno value. Note that the errno and data variables are lexi-cally visible to the error clauses.

Example:

(with-errno-handler

((errno packet) ; Only handle 3 particular errors.

((errno/wouldblock errno/again)

(loop))
((errno/acces)

(format #t "Not allowed access!")
#f))

(foo frobbotz)
(blatz garglemumph))

It is not defined what dynamic context the handler executes in, so fluidvariables cannot reliably be referenced.
Note that Scsh system calls always retry when interrupted, so that the
errno/intr exception is never raised. If the programmer wishes to aborta system call on an interrupt, he should have the interrupt handler explicitly raise an exception or invoke a stored continuation to throw out ofthe system call.

@subsection Interactive mode and error handling
Scsh runs in two modes: interactive and script mode. It starts up in interac-tive mode if the scsh interpreter is started up with no script argument. Otherwise, scsh starts up in script mode. The mode determines whether scsh printsprompts in between reading and evaluating forms, and it affects the default error handler. In interactive mode, the default error handler will report the error,and generate an interactive breakpoint so that the user can interact with the
system to examine, fix, or dismiss from the error. In script mode, the defaulterror handler causes the scsh process to exit.

When scsh forks a child with (fork), the child resets to script mode. Thiscan be overridden if the programmer wishes.


@section I/O
@subsection Standard R5RS I/O procedures
In scsh, most standard R5RS I/O operations (such as display or read-char)work on both integer file descriptors and Scheme ports. When doing I/O with
a file descriptor, the I/O operation is done directly on the file, bypassing anybuffered data that may have accumulated in an associated port. Note that
character-at-a-time operations such as read-char are likely to be quite slowwhen performed directly upon file descriptors.

The standard R5RS procedures read-char, char-ready?, write, display,
newline, and write-char are all generic, accepting integer file descriptor ar-guments as well as ports. Scsh also mandates the availability of

format, andfurther requires
format to accept file descriptor arguments as well as ports.

The procedures peek-char and read do not accept file descriptor argu-ments, since these functions require the ability to read ahead in the input

stream, a feature not supported by Unix I/O.

@subsection Port manipulation and standard ports
(close-after port consumer) -! value(s) of consumer procedure

Returns (consumer port), but closes the port on return. No dynamic-wind magic.

Remark: Is there a less-awkward name?
(error-output-port) -! port procedure

This procedure is analogous to current-output-port, but produces aport used for error messages--the scsh equivalent of stderr.

(with-current-input-port* port thunk) -! value(s) of thunk procedure
(with-current-output-port* port thunk) -! value(s) of thunk procedure
(with-error-output-port* port thunk) -! value(s) of thunk procedure

These procedures install port as the current input, current output, anderror output port, respectively, for the duration of a call to thunk.

(with-current-input-port port . body) -! value(s) of body syntax
(with-current-output-port port . body) -! value(s) of body syntax
(with-error-output-port port . body) -! value(s) of body syntax

These special forms are simply syntactic sugar for the with-currentinput-port* procedure and friends.

(set-current-input-port! port) -! undefined procedure
(set-current-output-port! port) -! undefined procedure
(set-error-output-port! port) -! undefined procedure

These procedures alter the dynamic binding of the current I/O port pro-cedures to new values.

(close fd/port) -! boolean procedure

Close the port or file descriptor.
If fd/port is a file descriptor, and it has a port allocated to it, the port isshifted to a new file descriptor created with

(dup fd/port) before clos-ing
fd/port. The port then has its revealed count set to zero. This reflectsthe design criteria that ports are not associated with file descriptors, but

with open files.
To close a file descriptor, and any associated port it might have, you mustinstead say one of (as appropriate):

(close (fdes->inport fd))
(close (fdes->outport fd))

The procedure returns true if it closed an open port. If the port was al-ready closed, it returns false; this is not an error.

(stdports->stdio) -! undefined procedure
(stdio->stdports) -! undefined procedure

These two procedures are used to synchronise Unix' standard I/O filedescriptors and Scheme's current I/O ports.

(stdports->stdio) causes the standard I/O file descriptors (0, 1, and 2)to take their values from the current I/O ports. It is exactly equivalent to
the series of redirections:1

(dup (current-input-port) 0)
(dup (current-output-port) 1)
(dup (error-output-port) 2)

stdio->stdports causes the bindings of the current I/O ports to bechanged to ports constructed over the standard I/O file descriptors. It

is exactly equivalent to the series of assignments

(set-current-input-port! (fdes->inport 0))
(set-current-output-port! (fdes->outport 1))
(set-error-output-port! (fdes->outport 2))

1 Why not move->fdes? Because the current output port and error port might be the same port.

However, you are more likely to find the dynamic-extent variant,
with-stdio-ports*, below, to be of use in general programming.

(with-stdio-ports* thunk) -! value(s) of thunk procedure
(with-stdio-ports body . . . ) -! value(s) of body syntax

with-stdio-ports* binds the standard ports (current-input-port),
(current-output-port), and (error-output-port) to be ports on filedescriptors 0, 1, 2, and then calls thunk. It is equivalent to:

(with-current-input-port (fdes->inport 0)

(with-current-output-port (fdes->inport 1)

(with-error-output-port (fdes->outport 2)

(thunk))))

The with-stdio-ports special form is merely syntactic sugar.

@subsection String ports
Scheme 48 has string ports, which you can use. Scsh has not committed tothe particular interface or names that Scheme 48 uses, so be warned that the
interface described herein may be liable to change.
(make-string-input-port string) -! port procedure

Returns a port that reads characters from the supplied string.

(make-string-output-port) -! port procedure
(string-output-port-output port) -! string procedure

A string output port is a port that collects the characters given toit into a string. The accumulated string is retrieved by applying

string-output-port-output to the port.
(call-with-string-output-port procedure) -! string procedure

The procedure value is called on a port. When it returns,
call-with-string-output-port returns a string containing the charac-ters that were written to that port during the execution of procedure.

@subsection Revealed ports and file descriptors
The material in this section and the following one is not critical for most appli-cations. You may safely skim or completely skip this section on a first reading.

Dealing with Unix file descriptors in a Scheme environment is difficult. InUnix, open files are part of the process environment, and are referenced by small integers called file descriptors. Open file descriptors are the fundamen-tal way I/O redirections are passed to subprocesses, since file descriptors are
preserved across fork's and exec's.

Scheme, on the other hand, uses ports for specifying I/O sources. Ports aregarbage-collected Scheme objects, not integers. Ports can be garbage collected;

when a port is collected, it is also closed. Because file descriptors are just in-tegers, it's impossible to garbage collect them--you wouldn't be able to close
file descriptor 3 unless there were no 3's in the system, and you could furtherprove that your program would never again compute a 3. This is difficult at
best.

If a Scheme program only used Scheme ports, and never actually used filedescriptors, this would not be a problem. But Scheme code must descend to

the file descriptor level in at least two circumstances:

* when interfacing to foreign code

* when interfacing to a subprocess.

This causes a problem. Suppose we have a Scheme port constructed on topof file descriptor 2. We intend to fork off a program that will inherit this file
descriptor. If we drop references to the port, the garbage collector may prema-turely close file 2 before we fork the subprocess. The interface described below
is intended to fix this and other problems arising from the mismatch betweenports and file descriptors.

The Scheme kernel maintains a port table that maps a file descriptor to theScheme port allocated for it (or,

#f if there is no port allocated for this filedescriptor). This is used to ensure that there is at most one open port for each

open file descriptor.

The port data structure for file ports has two fields besides the descriptor:revealed and closed?. When a file port is closed with

(close port), the port'sfile descriptor is closed, its entry in the port table is cleared, and the port's

closed? field is set to true.

When a file descriptor is closed with (close fdes), any associated portis shifted to a new file descriptor created with

(dup fdes). The port has itsrevealed count reset to zero (and hence becomes eligible for closing on GC).

See discussion below. To really put a stake through a descriptor's heart withoutwaiting for associated ports to be GC'd, you must say one of

(close (fdes->inport fdes))
(close (fdes->output fdes))

The revealed field is an aid to garbage collection. It is an integer semaphore.If it is zero, the port's file descriptor can be closed when the port is collected.

Essentially, the revealed field reflects whether or not the port's file descriptorhas escaped to the Scheme user. If the Scheme user doesn't know what file descriptor is associated with a given port, then he can't possibly retain an "inte-ger handle" on the port after dropping pointers to the port itself, so the garbage
collector is free to close the file.

Ports allocated with open-output-file and open-input-file are unre-vealed ports--i.e., revealed is initialised to 0. No one knows the port's file descriptor, so the file descriptor can be closed when the port is collected.

The functions fdes->output-port, fdes->input-port, port->fdes areused to shift back and forth between file descriptors and ports. When

port->fdes reveals a port's file descriptor, it increments the port's revealedfield. When the user is through with the file descriptor, he can call
(release-port-handle port), which decrements the count. The func-tion

(call/fdes fd/port proc) automates this protocol. call/fdes uses
dynamic-wind to enforce the protocol. If proc throws out of the call/fdes ap-plication, the unwind handler releases the descriptor handle; if the user subsequently tries to throw back into proc's context, the wind handler raises anerror. When the user maps a file descriptor to a port with

fdes->outport or
fdes->inport, the port has its revealed field incremented.

Not all file descriptors are created by requests to make ports. Some are in-herited on process invocation via

exec(2), and are simply part of the globalenvironment. Subprocesses may depend upon them, so if a port is later allocated for these file descriptors, is should be considered as a revealed port.For example, when the Scheme shell's process starts up, it opens ports on
file descriptors 0, 1, and 2 for the initial values of (current-input-port),
(current-output-port), and (error-output-port). These ports are ini-tialised with revealed set to 1, so that stdin, stdout, and stderr are not closed

even if the user drops the port.

Unrevealed file ports have the nice property that they can be closed whenall pointers to the port are dropped. This can happen during gc, or at an

exec()--since all memory is dropped at an exec(). No one knows the filedescriptor associated with the port, so the exec'd process certainly can't refer
to it.

This facility preserves the transparent close-on-collect property for file portsthat are used in straightforward ways, yet allows access to the underlying Unix

substrate without interference from the garbage collector. This is critical, sinceshell programming absolutely requires access to the Unix file descriptors, as
their numerical values are a critical part of the process interface.

A port's underlying file descriptor can be shifted around with dup(2) whenconvenient. That is, the actual file descriptor on top of which a port is constructed can be shifted around underneath the port by the scsh kernel when necessary. This is important, because when the user is setting up file descrip-tors prior to a exec(2), he may explicitly use a file descriptor that has alreadybeen allocated to some port. In this case, the scsh kernel just shifts the port's

file descriptor to some new location with dup, freeing up its old descriptor. Thisprevents errors from happening in the following scenario. Suppose we have a
file open on port f. Now we want to run a program that reads input on file 0,writes output to file 1, errors to file 2, and logs execution information on file 3. We want to run this program with input from f. So we write:

(run (/usr/shivers/bin/prog)

(> 1 output.txt)
(> 2 error.log)
(> 3 trace.log)
(= 0 ,f))

Now, suppose by ill chance that, unbeknownst to us, when the operatingsystem opened

f's file, it allocated descriptor 3 for it. If we blindly redirect
trace.log into file descriptor 3, we'll clobber f! However, the port-shufflingmachinery saves us: when the

run form tries to dup trace.log's file descriptorto 3,
dup will notice that file descriptor 3 is already associated with an unre-vealed port (i.e.,

f). So, it will first move f to some other file descriptor. Thiskeeps
f alive and well so that it can subsequently be dup'd into descriptor 0for
prog's stdin.

The port-shifting machinery makes the following guarantee: a port is onlymoved when the underlying file descriptor is closed, either by a

close() or a
dup2() operation. Otherwise a port/file-descriptor association is stable.

Under normal circumstances, all this machinery just works behind thescenes to keep things straightened out. The only time the user has to think

about it is when he starts accessing file descriptors from ports, which he shouldalmost never have to do. If a user starts asking what file descriptors have been
allocated to what ports, he has to take responsibility for managing this infor-mation.

@subsection Port-mapping machinery
The procedures provided in this section are almost never needed. You maysafely skim or completely skip this section on a first reading.

Here are the routines for manipulating ports in scsh. The important pointsto remember are:

* A file port is associated with an open file, not a particular file descriptor.

* The association between a file port and a particular file descriptor is neverchanged except when the file descriptor is explicitly closed. "Closing"

includes being used as the target of a dup2, so the set of procedures belowthat close their targets are

close, two-argument dup, and move->fdes. Ifthe target file descriptor of one of these routines has an allocated port,

the port will be shifted to another freshly-allocated file descriptor, andmarked as unrevealed, thus preserving the port but freeing its old file
descriptor.
These rules are what is necessary to "make things work out" with no surprisesin the general case.

(fdes->inport fd) -! port procedure
(fdes->outport fd) -! port procedure
(port->fdes port) -! fixnum procedure

These increment the port's revealed count.

(port-revealed port) -! integer or #f procedure

Return the port's revealed count if positive, otherwise #f.

(release-port-handle port) -! undefined procedure

Decrement the port's revealed count.

(call/fdes fd/port consumer) -! value(s) of consumer procedure

Calls consumer on a file descriptor; takes care of revealed bookkeeping.If fd/port is a file descriptor, this is just

(consumer fd/port). If fd/port is aport, calls consumer on its underlying file descriptor. While consumer is

running, the port's revealed count is incremented.
When call/fdes is called with port argument, you are not allowed tothrow into consumer with a stored continuation, as that would violate the

revealed-count bookkeeping.
(move->fdes fd/port target-fd) -! port or fdes procedure

Maps fd!fd and port!port.
If fd/port is a file-descriptor not equal to target-fd, dup it to target-fd andclose it. Returns target-fd.

If fd/port is a port, it is shifted to target-fd, by duping its underlying file-descriptor if necessary. Fd/port's original file descriptor is closed (if it was
different from target-fd). Returns the port. This operation resets fd/port'srevealed count to 1.

In all cases when fd/port is actually shifted, if there is a port already usingtarget-fd, it is first relocated to some other file descriptor.

@subsection Unix I/O

(dup fd/port [newfd]) -! fd/port procedure
(dup->inport fd/port [newfd]) -! port procedure
(dup->outport fd/port [newfd]) -! port procedure
(dup->fdes fd/port [newfd]) -! fd procedure

These procedures provide the functionality of C's dup() and dup2().The different routines return different types of values:

dup->inport,
dup->outport, and dup->fdes return input ports, output ports, and in-teger file descriptors, respectively.

dup's return value depends on on thetype of fd/port--it maps fd!fd and port!port.

These procedures use the Unix dup() syscall to replicate the file descrip-tor or file port fd/port. If a newfd file descriptor is given, it is used as the
target of the dup operation, i.e., the operation is a dup2(). In this case,procedures that return a port (such as

dup->inport) will return one withthe revealed count set to one. For example,

(dup (current-input-port)
5) produces a new port with underlying file descriptor 5, whose revealedcount is 1. If newfd is not specified, then the operating system chooses the

file descriptor, and any returned port is marked as unrevealed.
If the newfd target is given, and some port is already using that file de-scriptor, the port is first quietly shifted (with another

dup) to some otherfile descriptor (zeroing its revealed count).

Since Scheme doesn't provide read/write ports, dup->inport and
dup->outport can be useful for getting an output version of an inputport, or vice versa. For example, if

p is an input port open on a tty, and wewould like to do output to that tty, we can simply use

(dup->outport p)to produce an equivalent output port for the tty. Be sure to open the file

with the open/read+write flag for this.
(seek fd/port offset [whence]) -! integer procedure

Reposition the I/O cursor for a file descriptor or port. whence is oneof {

seek/set, seek/delta, seek/end}, and defaults to seek/set. If
seek/set, then offset is an absolute index into the file; if seek/delta,then offset is a relative offset from the current I/O cursor; if

seek/end,then offset is a relative offset from the end of file. The fd/port argument

may be a port or an integer file descriptor. Not all such values are seek-able; this is dependent on the OS implementation. The return value is the
resulting position of the I/O cursor in the I/O stream.

Oops: The current implementation doesn't handle offset argumentsthat are not immediate integers (i.e., representable in 30 bits).

Oops: The current implementation doesn't handle buffered ports.

(tell fd/port) -! integer procedure

Returns the position of the I/O cursor in the the I/O stream. Not all filedescriptors or ports support cursor-reporting; this is dependent on the

OS implementation.
(open-file fname flags [perms]) -! port procedure

Perms defaults to #o666. Flags is an integer bitmask, composed by or'ingtogether constants listed in table 3.1. You must use exactly

one of the open/read, open/write, or open/read+write flags. The re-turned port is an input port if the flags permit it, otherwise an output
port. R5RS/Scheme 48/scsh do not have input/output ports, so it's oneor the other. This should be fixed. (You can hack simultaneous I/O on
a file by opening it r/w, taking the result input port, and duping it to anoutput port with

dup->outport.)

(open-input-file fname [flags]) -! port procedure
(open-output-file fname [flags perms]) -! port procedure

These are equivalent to open-file, after first setting the read/write bitsof the flags argument to

open/read or open/write, respectively. Flagsdefaults to zero for
open-input-file, and

(bitwise-ior open/create open/truncate)
for open-output-file. These defaults make the procedures backwards-compatible with their unary R5RS definitions.

(open-fdes fname flags [perms]) -! integer procedure

Returns a file descriptor.

(fdes-flags fd/port) -! integer procedure
(set-fdes-flags fd/port integer) -! undefined procedure

These procedures allow reading and writing of an open file's flags. Theonly such flag defined by @acronym{POSIX} is fdflags/close-on-exec; your Uniximplementation may provide others.

These procedures should not be particularly useful to the programmer, asthe scsh runtime already provides automatic control of the close-on-exec
property. Unrevealed ports always have their file descriptors markedclose-on-exec, as they can be closed when the scsh process execs a new
program. Whenever the user reveals or unreveals a port's file descrip-tor, the runtime automatically sets or clears the flag for the programmer.

Allowed operations Status flagOpen+Get+Set These flags can be used
in open-file,
fdes-status, and
set-fdes-status calls.

open/append
open/non-blocking
open/async (Non-@acronym{POSIX})
open/fsync (Non-@acronym{POSIX})Open+Get These flags can be used

in open-file and
fdes-status calls, butare ignored by

set-fdes-status.

open/read
open/write
open/read+write
open/access-mask

Open These flags are onlyrelevant in

open-filecalls; they are ignored

by fdes-status and
set-fdes-status calls.

open/create
open/exclusive
open/no-control-tty
open/truncate

Table 3.1: Status flags for open-file, fdes-status and set-fdes-status.Only @acronym{POSIX} flags are guaranteed to be present; your operating system may de-fine others. The

open/access-mask value is not an actual flag, but a bit maskused to select the field for the

open/read, open/write and open/read+writebits.

Programmers that manipulate this flag should be aware of these extra,automatic operations.

(fdes-status fd/port) -! integer procedure
(set-fdes-status fd/port integer) -! undefined procedure

These procedures allow reading and writing of an open file's status flags(table 3.1).

Note that this file-descriptor state is shared between file descriptors cre-ated by

dup--if you create port b by applying dup to port a, and changeb's status flags, you will also have changed a's status flags.

(pipe) -! [rport wport] procedure

Returns two ports, the read and write end-points of a Unix pipe.

(read-string nbytes [fd/port]) -! string or #f procedure
(read-string! str [fd/port start end]) -! nread or #f procedure

These calls read exactly as much data as you requested, unless there isnot enough data (@acronym{eof}).

read-string! reads the data into string str atthe indices in the half-open interval [start, end); the default interval is thewhole string: start = 0 and end =
(string-length string). They willpersistently retry on partial reads and when interrupted until (1) error, (2) @acronym{eof}, or (3) the input request is completely satisfied. Partial reads canoccur when reading from an intermittent source, such as a pipe or tty.

read-string returns the string read; read-string! returns the numberof characters read. They both return false at @acronym{eof}. A request to read zero
bytes returns immediately, with no @acronym{eof} check.
The values of start and end must specify a well-defined interval in str, i.e.,0 <= start <= end <=

(string-length str).

Any partially-read data is included in the error exception packet. Errorreturns on non-blocking input are considered an error.

(read-string/partial nbytes [fd/port]) -! string or #f procedure
(read-string!/partial str [fd/port start end]) -! nread or #f procedure

These are atomic best-effort/forward-progress calls. Best effort: theymay read less than you request if there is a lesser amount of data immediately available (e.g., because you are reading from a pipe or a tty).Forward progress: if no data is immediately available (e.g., empty pipe),
they will block. Therefore, if you request an n > 0 byte read, while youmay not get everything you asked for, you will always get something
(barring @acronym{eof}).
There is one case in which the forward-progress guarantee is cancelled:when the programmer explicitly sets the port to non-blocking I/O. In this

case, if no data is immediately available, the procedure will not block, butwill immediately return a zero-byte read.

read-string/partial reads the data into a freshly allocated string,which it returns as its value.

read-string!/partial reads the data intostring str at the indices in the half-open interval [start

, end); the defaultinterval is the whole string: start = 0 and end =
(string-length string).The values of start and end must specify a well-defined interval in str, i.e.,

0 <= start <= end <= (string-length str). It returns the number of bytesread.

A request to read zero bytes returns immediatedly, with no @acronym{eof} check.
In sum, there are only three ways you can get a zero-byte read: (1) yourequest one, (2) you turn on non-blocking I/O, or (3) you try to read at

@acronym{eof}.
These are the routines to use for non-blocking input. They are also use-ful when you wish to efficiently process data in large blocks, and your

algorithm is insensitive to the block size of any particular read operation.

34

(select rvec wvec evec [timeout]) -! [rvec' wvec' evec'] procedure
(select! rvec wvec evec [timeout]) -! [nr nw ne] procedure

The select procedure allows a process to block and wait for events onmultiple I/O channels. The rvec and evec arguments are vectors of input

ports and integer file descriptors; wvec is a vector of output ports andinteger file descriptors. The procedure returns three vectors whose elements are subsets of the corresponding arguments. Every element ofrvec' is ready for input; every element of wvec' is ready for output; every
element of evec' has an exceptional condition pending.
The select call will block until at least one of the I/O channels passedto it is ready for operation. For an input port this means that it either

has data sitting its buffer or that the underlying file descriptor has datawaiting. For an output port this means that it either has space available
in the associated buffer or that the underlying file descriptor can acceptoutput. For file descriptors, no buffers are checked, even if they have
associated ports.
The timeout value can be used to force the call to time-out after a givennumber of seconds. It defaults to the special value

#f, meaning waitindefinitely. A zero value can be used to poll the I/O channels.

If an I/O channel appears more than once in a given vector--perhapsoccuring once as a Scheme port, and once as the port's underlying integer file descriptor--only one of these two references may appear in thereturned vector. Buffered I/O ports are handled specially--if an input
port's buffer is not empty, or an output port's buffer is not yet full, thenthese ports are immediately considered eligible for I/O without using
the actual, primitive select system call to check the underlying file de-scriptor. This works pretty well for buffered input ports, but is a little
problematic for buffered output ports.
The select! procedure is similar, but indicates the subset of active I/Ochannels by side-effecting the argument vectors. Non-active I/O channels in the argument vectors are overwritten with #f values. The callreturns the number of active elements remaining in each vector. As a
convenience, the vectors passed in to select! are allowed to contain #fvalues as well as integers and ports.

Remark: Select and select! do not call their @acronym{POSIX} counter-parts directly--there is a @acronym{POSIX}

select sitting at the very heart of theScheme 48/scsh I/O system, so all multiplexed I/O is really

select-based. Therefore, you cannot expect a performance increase from

writing a single-threaded program using select and select! insteadof writing a multi-threaded program where each thread handles one
I/O connection.

The moral of this story is that select and select! make sense in onlytwo situations: legacy code written for an older version of scsh, and
programs which make inherent use of select/select! which do notbenefit from multiple threads. Examples are network clients that send
requests to multiple alternate servers and discard all but one of them.
In any case, the select-ports and select-port-channels pro-cedures described below are usually a preferable alternative to

select/select!: they are much simpler to use, and also have aslightly more efficient implementation.

(select-ports timeout port . . . ) -! ready-ports procedure

The select-ports call will block until at least one of the ports passed to itis ready for operation or until the timeout has expired. For an input port

this means that it either has data sitting its buffer or that the underlyingfile descriptor has data waiting. For an output port this means that it
either has space available in the associated buffer or that the underlyingfile descriptor can accept output.

The timeout value can be used to force the call to time out after a givennumber of seconds. A value of

#f means to wait indefinitely. A zerovalue can be used to poll the ports.

Select-ports returns a list of the ports ready for operation. Note thatthis list may be empty if the timeout expired before any ports became
ready.
(select-port-channels timeout port . . . ) -! ready-ports procedure

Select-port-channels is like select-ports, except that it only looks atthe operating system objects the ports refer to, ignoring any buffering

performed by the ports.

Remark: Select-port-channels should be used with care: for ex-ample, if an input port has data in the buffer but no data available
on the underlying file descriptor, select-port-channels will block,even though a read operation on the port would be able to complete
without blocking.
Select-port-channels is intended for situations where the programis not checking for available data, but rather for waiting until a port

has established a connection--for example, to a network port.

(write-string string [fd/port start end]) -! undefined procedure

This procedure writes all the data requested. If the procedure cannotperform the write with a single kernel call (due to interrupts or partial

writes), it will perform multiple write operations until all the data is writ-ten or an error has occurred. A non-blocking I/O error is considered an error. (Error exception packets for this syscall include the amount of datapartially transferred before the error occurred.)
The data written are the characters of string in the half-open interval[start

, end). The default interval is the whole string: start = 0 andend =

(string-length string). The values of start and end must specifya well-defined interval in str, i.e., 0 <= start <= end <=

(string-length str).A zero-byte write returns immediately, with no error.

Output to buffered ports: write-string's efforts end as soon as all thedata has been placed in the output buffer. Errors and true output may
not happen until a later time, of course.

(write-string/partial string [fd/port start end]) -! nwritten procedure

This routine is the atomic best-effort/forward-progress analog to
write-string. It returns the number of bytes written, which may beless than you asked for. Partial writes can occur when (1) we write off

the physical end of the media, (2) the write is interrrupted, or (3) the filedescriptor is set for non-blocking I/O.

If the file descriptor is not set up for non-blocking I/O, then a successfulreturn from these procedures makes a forward progress guarantee--that
is, a partial write took place of at least one byte:

* If we are at the end of physical media, and no write takes place, anerror exception is raised. So a return implies we wrote something.

* If the call is interrupted after a partial transfer, it returns immedi-ately. But if the call is interrupted before any data transfer, then the

write is retried.
If we request a zero-byte write, then the call immediately returns 0. If thefile descriptor is set for non-blocking I/O, then the call may return 0 if it
was unable to immediately write anything (e.g., full pipe). Barring thesetwo cases, a write either returns nwritten

> 0, or raises an error exception.

Non-blocking I/O is only available on file descriptors and unbufferedports. Doing non-blocking I/O to a buffered port is not well-defined,

and is an error (the problem is the subsequent flush operation).

Oops: write-string/partial is currently not implemented. Con-sider using threads to achive the same functionality.

@subsection Buffered I/O
Scheme 48 ports use buffered I/O--data is transferred to or from the OS inblocks. Scsh provides control of this mechanism: the programmer may force
saved-up output data to be transferred to the OS when he chooses, and mayalso choose which I/O buffering policy to employ for a given port (or turn
buffering off completely).

It can be useful to turn I/O buffering off in some cases, for example whenan I/O stream is to be shared by multiple subprocesses. For this reason, scsh allocates an unbuffered port for file descriptor 0 at start-up time. Because shellsfrequently share stdin with subprocesses, if the shell does buffered reads, it
might "steal" input intended for a subprocess. For this reason, all shells, in-cluding sh, csh, and scsh, read stdin unbuffered. Applications that can tolerate
buffered input on stdin can reset (current-input-port) to block buffering forhigher performance.

{Note So support peek-char a Scheme implementation has to maintain abuffer for all input ports. In scsh, for "unbuffered" input ports the buffer size
is one. As you cannot request less then one character there is no unrequestedreading so this can still be called "unbuffered input".}

(set-port-buffering port policy [size]) -! undefined procedure

This procedure allows the programmer to assign a particular I/O buffer-ing policy to a port, and to choose the size of the associated buffer. It

may only be used on new ports, i.e., before I/O is performed on the port.There are three buffering policies that may be chosen:

bufpol/block General block buffering (general default)
bufpol/line Line buffering (tty default)
bufpol/none Direct I/O--no buffering2

The line buffering policy flushes output whenever a newline is output;whenever the buffer is full; or whenever an input is read from stdin. Line

buffering is the default for ports open on terminal devices.

Oops: The current implementation doesn't support bufpol/line.
The size argument requests an I/O buffer of size bytes. For output ports,size must be non-negative, for input ports size must be positve. If not

given, a reasonable default is used. For output ports, if given and zero,buffering is turned off (i.e., size = 0 for any policy is equivalent to
policy = bufpol/none). For input ports, setting the size to one corre-sponds to unbuffered input as defined above. If given, size must be zero
respectively one for bufpol/none.

(force-output [fd/port]) -! undefined procedure

This procedure does nothing when applied to an integer file descriptoror unbuffered port. It flushes buffered output when applied to a buffered
port, and raises a write-error exception on error. Returns no value.

(flush-all-ports) -! undefined procedure

This procedure flushes all open output ports with buffered data.

@subsection File locking
Scsh provides @acronym{POSIX} advisory file locking. Advisory locks are locks that can bechecked by user code, but do not affect other I/O operations. For example, if
a process has an exclusive lock on a region of a file, other processes will not beable to obtain locks on that region of the file, but they will still be able to read
and write the file with no hindrance. Using advisory locks requires cooperationamongst the agents accessing the shared resource.

Remark: Unfortunately, @acronym{POSIX} file locks are associated with actual files,not with associated open file descriptors. Once a process locks a file, using
some file descriptor fd, the next time any file descriptor referencing that fileis closed, all associated locks are released. This severely limits the utility of @acronym{POSIX} advisory file locks, and we'd recommend caution when using them.It is not without reason that the FreeBSD man pages refer to @acronym{POSIX} filelocking as "completely stupid."

Scsh moves Scheme ports from file descriptor to file descriptor with dup()and

close() as required by the runtime, so it is impossible to keep file locksopen across one of these shifts. Hence we can only offer P

OSIX advisoryfile locking directly on raw integer file descriptors; regrettably, there are no

facilities for locking Scheme ports.
Note that once a Scheme port is revealed in scsh, the runtime will not shiftthe port around with

dup() and close(). This means the file-locking pro-cedures can then be applied to the port's associated file descriptor.

@acronym{POSIX} allows the user to lock a region of a file with either an exclusive orshared lock. Locked regions are described by the lock-region record:

(define-record lock-region

exclusive?
start
len
whence
proc)

39

* The exclusive? field is true if the lock is exclusive; false if it is shared.

* The whence field is one of the values from the seek call: seek/set,

seek/delta, or seek/end, and determines the interpretation of the startfield:

- If seek/set, the start value is simply an absolute index into thefile.
- If seek/delta, the start value is an offset from the file descriptor'scurrent position in the file.
- If seek/end, the start value is an offset from the end of the file.
The region of the file being locked is given by the start and len fields;if

len is zero, it means "infinity," that is, the region extends from thestarting point through the end of the file, even as the file is extended by

subsequent write operations.

* The proc field gives the process object for the process holding the regionlock, when relevant (see

get-lock-region below).

(make-lock-region exclusive? start len [whence]) -! lock-region procedure

This procedure makes a lock-region record. The whence field defaults to
seek/set.

(lock-region fdes lock) -! undefined procedure
(lock-region/no-block fdes lock) -! boolean procedure

These procedures lock a region of the file referenced by file descriptorfdes. The

lock-region procedure blocks until the lock is granted; thenon-blocking variant returns a boolean indicating whether or not the lock

was granted. To take an exclusive (write) lock, you must have the filedescriptor open with write access; to take a shared (read) lock, you must
have the file descriptor open with read access.
(get-lock-region fdes lock) -! lock-region or #f procedure

Return the first lock region on fdes that would conflict with lock regionlock. If there is no such lock region, return false. This procedure fills out

the proc field of the returned lock region, and is the only procedure thathas anything to do with this field. (See section @ref{3.4.1} for a description of
process objects.) Note that if you apply this procedure to a file systemthat is shared across multiple operating systems (i.e., an NFS file system),
the proc field may be ambiguous. We note, again, that @acronym{POSIX} advisoryfile locking is not a terribly useful or well-designed facility.

(unlock-region fdes lock) -! undefined procedure

Release a lock from a file.

(with-region-lock* fdes lock thunk) -! value(s) of thunk procedure
(with-region-lock fdes lock body . . . ) -! value(s) of body syntax

This procedure obtains the requested lock, and then calls (thunk). Whenthunk returns, the lock is released. A non-local exit (e.g., throwing to a

saved continuation or raising an exception) also causes the lock to bereleased.

After a normal return from thunk, its return values are returned by
with-region-lock*. The with-region-lock special form is equivalentsyntactic sugar.

@section File system
Besides the following procedures, which allow access to the computer's filesystem, scsh also provides a set of procedures which manipulate file names.
These string-processing procedures are documented in section @ref{5.1}.
(create-directory fname [perms override?]) -! undefined procedure
(create-fifo fname [perms override?]) -! undefined procedure
(create-hard-link oldname newname [override?]) -! undefined procedure
(create-symlink old-name new-name [override?]) -! undefined procedure

These procedures create objects of various kinds in the file system.
The override? argument controls the action if there is already an object inthe file system with the new name:

#f signal an error (default)
'query prompt the user
other delete the old object (with delete-file or

delete-directory, as appropriate) beforecreating the new object.

Perms defaults to #o777 (but is masked by the current umask).

Remark: Currently, if you try to create a hard or symbolic link from afile to itself, you will error out with override? false, and simply delete
your file with override? true. Catching this will require some sort oftrue-name procedure, which I currently do not have.

(delete-directory fname) -! undefined procedure
(delete-file fname) -! undefined procedure
(delete-filesys-object fname) -! undefined procedure

These procedures delete objects from the file system. The deletefilesys-object procedure will delete an object of any type from the filesystem: files, (empty) directories, symlinks, fifos, etc..

If the object being deleted doesn't exist, delete-directory and
delete-file raise an error, while delete-filesys-object simply re-turns.

(read-symlink fname) -! string procedure

Return the filename referenced by symbolic link fname.

(rename-file old-fname new-fname [override?]) -! undefined procedure

If you override an existing object, then old-fname and new-fname musttype-match--either both directories, or both non-directories. This is required by the semantics of Unix rename().

Remark: There is an unfortunate atomicity problem with the
rename-file procedure: if you specify no-override, but create file
new-fname sometime between rename-file's existence check and theactual rename operation, your file will be clobbered with

old-fname.There is no way to fix this problem, given the semantics of Unix

rename(); at least it is highly unlikely to occur in practice.

(set-file-mode fname/fd/port mode) -! undefined procedure
(set-file-owner fname/fd/port uid) -! undefined procedure
(set-file-group fname/fd/port gid) -! undefined procedure

These procedures set the permission bits, owner id, and group id of afile, respectively. The file can be specified by giving the file name, or

either an integer file descriptor or a port open on the file. Setting file userownership usually requires root privileges.

(set-file-times fname [access-time mod-time]) -! undefined procedure

This procedure sets the access and modified times for the file fname to thesupplied values (see section @ref{3.10} for the scsh representation of time). If

neither time argument is supplied, they are both taken to be the currenttime. You must provide both times or neither. If the procedure completes
successfully, the file's time of last status-change (ctime) is set to the cur-rent time.

(sync-file fd/port) -! undefined procedure
(sync-file-system) -! undefined procedure

Calling sync-file causes Unix to update the disk data structures for agiven file. If fd/port is a port, any buffered data it may have is first flushed.

Calling sync-file-system synchronises the kernel's entire file systemwith the disk.

These procedures are not @acronym{POSIX}. Interestingly enough, sync-filesystem doesn't actually do what it is claimed to do. We just threw itin for humor value. See the

sync(2) man page for Unix enlightenment.

(truncate-file fname/fd/port len) -! undefined procedure

The specified file is truncated to len bytes in length.

(file-info fname/fd/port [chase?]) -! file-info-record procedure

The file-info procedure returns a record structure containing every-thing there is to know about a file. If the chase? flag is true (the default),

then the procedure chases symlinks and reports on the files to which theyrefer. If chase? is false, then the procedure checks the actual file itself, even
if it's a symlink. The chase? flag is ignored if the file argument is a file de-scriptor or port.

The value returned is a file-info record, defined to have the following struc-ture:

(define-record file-info

type ; {block-special, char-special, directory,

; fifo, regular, socket, symlink}
device ; Device file resides on.
inode ; File's inode.
mode ; File's mode bits: permissions, setuid, setgid
nlinks ; Number of hard links to this file.
uid ; Owner of file.
gid ; File's group id.
size ; Size of file, in bytes.
atime ; Time of last access.
mtime ; Time of last mod.
ctime) ; Time of last status change.

The uid field of a file-info record is accessed with the procedure

(file-info:uid x)

and similarly for the other fields. The type field is a symbol; allother fields are integers. A file-info record is discriminated with the
file-info? predicate.
The following procedures all return selected information about a file;they are built on top of

file-info, and are called with the same argu-ments that are passed to it.

Procedure returns
file-type type
file-inode inode
file-mode mode
file-nlinks nlinks
file-owner uid
file-group gid
file-size size
file-last-access atime
file-last-mod mtime
file-last-status-change ctime

Example:

;; All my files in /usr/tmp:
(filter (* (f) (= (file-owner f) (user-uid)))

(directory-files "/usr/tmp")))

Remark: file-info was named file-attributes in releases ofscsh prior to release 0.4. We changed the name to

file-info forconsistency with the other information-retrieval procedures in scsh:

user-info, group-info, host-info, network-info , service-info,and

protocol-info.

The file-attributes binding is still supported in the current releaseof scsh, but is deprecated, and may go away in a future release.

(file-directory? fname/fd/port [chase?]) -! boolean procedure
(file-fifo? fname/fd/port [chase?]) -! boolean procedure
(file-regular? fname/fd/port [chase?]) -! boolean procedure
(file-socket? fname/fd/port [chase?]) -! boolean procedure
(file-special? fname/fd/port [chase?]) -! boolean procedure
(file-symlink? fname/fd/port) -! boolean procedure

These procedures are file-type predicates that test the type of a given file.They are applied to the same arguments to which

file-info is applied;the sole exception is
file-symlink?, which does not take the optionalchase? second argument.

For example,

(file-directory? "/usr/dalbertz") =) #t

There are variants of these procedures which work directly on file-inforecords:

(file-info-directory? file-info) -! boolean procedure
(file-info-fifo? file-info) -! boolean procedure
(file-info-regular? file-info) -! boolean procedure
(file-info-socket? file-info) -! boolean procedure
(file-info-special? file-info) -! boolean procedure
(file-info-symlink? file-info) -! boolean procedure

The following set of procedures are a convenient means to work on thepermission bits of a file:

(file-not-readable? fname/fd/port) -! boolean procedure
(file-not-writable? fname/fd/port) -! boolean procedure
(file-not-executable? fname/fd/port) -! boolean procedure

Returns:

Value meaning

#f Access permitted
'search-denied Can't stat--a protected directoryis blocking access.

'permission Permission denied.
'no-directory Some directory doesn't exist.
'nonexistent File doesn't exist.
A file is considered writeable if either (1) it exists and is writeable or (2)it doesn't exist and the directory is writeable. Since symlink permission

bits are ignored by the filesystem, these calls do not take a chase? flag.
Note that these procedures use the process' effective user and group idsfor permission checking. @acronym{POSIX} defines an access() function that usesthe process' real uid and gids. This is handy for setuid programs that would like to find out if the actual user has specific rights; scsh ought toprovide this functionality (but doesn't at the current time).

There are several problems with these procedures. First, there's an atom-icity issue. In between checking permissions for a file and then trying an
operation on the file, another process could change the permissions, so areturn value from these functions guarantees nothing. Second, the code
special-cases permission checking when the uid is root--if the file exists, root is assumed to have the requested permission. However, not evenroot can write a file that is on a read-only file system, such as a CD ROM.
In this case, file-not-writable? will lie, saying that root has write ac-cess, when in fact the opening the file for write access will fail. Finally,
write permission confounds write access and create access. These shouldbe disentangled.

Some of these problems could be avoided if @acronym{POSIX} had a real-uid vari-ant of the

access() call we could use, but the atomicity issue is still aproblem. In the final analysis, the only way to find out if you have the

right to perform an operation on a file is to try and open it for the desiredoperation. These permission-checking functions are mostly intended for
script-writing, where loose guarantees are tolerated.
(file-readable? fname/fd/port) -! boolean procedure
(file-writable? fname/fd/port) -! boolean procedure
(file-executable? fname/fd/port) -! boolean procedure

These procedures are the logical negation of the preceding
file-not-...? procedures. Refer to them for a discussion of theirproblems and limitations.

(file-info-not-readable? file-info) -! boolean procedure
(file-info-not-writable? file-info) -! boolean procedure
(file-info-not-executable? file-info) -! boolean procedure

(file-info-readable? file-info) -! boolean procedure
(file-info-writable? file-info) -! boolean procedure
(file-info-executable? file-info) -! boolean procedure

There are variants which work directly on file-info records.

(file-not-exists? fname/fd/port [chase?]) -! object procedure

Returns:

#f Exists.

#t Doesn't exist.
'search-denied Some protected directory isblocking the search.

(file-exists? fname/fd/port [chase?]) -! boolean procedure

This is simply (not (file-not-exists? fname [chase?]))

(directory-files [dir dotfiles?]) -! string list procedure

Return the list of files in directory dir, which defaults to the current work-ing directory. The dotfiles? flag (default

#f) causes dot files to be includedin the list. Regardless of the value of dotfiles?, the two files

. and .. arenever returned.

The directory dir is not prepended to each file name in the result list. Thatis,

(directory-files "/etc")
returns

("chown" "exports" "fstab" ...)
not

("/etc/chown" "/etc/exports" "/etc/fstab" ...)
To use the files in returned list, the programmer can either manuallyprepend the directory:

(map (* (f) (string-append dir "/" f)) files)
or cd to the directory before using the file names:

(with-cwd dir

(for-each delete-file (directory-files)))

or use the glob procedure, defined below.
A directory list can be generated by (run/strings (ls)), but this is un-reliable, as filenames with whitespace in their names will be split into

separate entries. Using directory-files is reliable.
(open-directory-stream dir) -! directory-stream-record procedure
(read-directory-stream directory-stream-record) -! string or #f procedure
(close-directory-stream directory-stream-record) -! undefined procedure

These functions implement a direct interface to the opendir()/
readdir()/ closedir() family of functions for processing directory streams.
(open-directory-stream dir) creates a stream of files in the directory
dir. (read-directory-stream directory-stream) returns the next file inthe stream or

#fif no such file exists. Finally, (close-directory-stream
directory-stream) closes the stream.

(glob pat1 . . . ) -! string list procedure

Glob each pattern against the filesystem and return the sorted list. Du-plicates are not removed. Patterns matching nothing are not included

literally.3 C shell {a,b,c} patterns are expanded. Backslash quotes char-acters, turning off the special meaning of

{, }, *, [, ], and ?.

3 Why bother to mention such a silly possibility? Because that is what sh does.

Note that the rules of backslash for Scheme strings and glob patternswork together to require four backslashes in a row to specify a single
literal backslash. Fortunately, it is very rare that a backslash occurs in aUnix file name.

A glob subpattern will not match against dot files unless the first char-acter of the subpattern is a literal "

.". Further, a dot subpattern willnot match the files
. or .. unless it is a constant pattern, as in (glob
"../*/*.c"). So a directory's dot files can be reliably generated with thesimple glob pattern

".*".

Some examples:

(glob "*.c" "*.h")

;; All the C and #include files in my directory.

(glob "*.c" "*/*.c")

;; All the C files in this directory and
;; its immediate subdirectories.

(glob "lexer/*.c" "parser/*.c")
(glob "{lexer,parser}/*.c")

;; All the C files in the lexer and parser dirs.

(glob "\\{lexer,parser\\}/*.c")

;; All the C files in the strange
;; directory "{lexer,parser}".

(glob "*\\*")

;; All the files ending in "*", e.g.
;; ("foo*" "bar*")

(glob "*lexer*")

("mylexer.c" "lexer1.notes")
;; All files containing the string "lexer".

(glob "lexer")

;; Either ("lexer") or ().

If the first character of the pattern (after expanding braces) is a slash, thesearch begins at root; otherwise, the search begins in the current working
directory.
If the last character of the pattern (after expanding braces) is a slash, thenthe result matches must be directories, e.g.,

(glob "/usr/man/man?/") =)

("/usr/man/man1/" "/usr/man/man2/" ...)

Globbing can sometimes be useful when we need a list of a directory'sfiles where each element in the list includes the pathname for the file.
Compare:

(directory-files "../include") =)

("cig.h" "decls.h" ...)

(glob "../include/*") =)

("../include/cig.h" "../include/decls.h" ...)

(glob-quote str) -! string procedure

Returns a constant glob pattern that exactly matches str. All wild-cardcharacters in str are quoted with a backslash.

(glob-quote "Any *.c files?")=)

"Any \*.c files\?"

(file-match root dot-files? pat1 pat2 . . . patn) -! string list procedure{

Note This procedure is deprecated, and will probably either go awayor be substantially altered in a future release. New code should not call

this procedure. The problem is that it relies upon Posix-notation regu-lar expressions; the rest of scsh has been converted over to the new SRE
notation.}
file-match provides a more powerful file-matching service, at the ex-pense of a less convenient notation. It is intermediate in power between

most shell matching machinery and recursive find(1).
Each pattern is a regexp. The procedure searches from root, matching thefirst-level files against pattern pat

1, the second-level files against pat2, andso forth. The list of files matching the whole path pattern is returned, in

sorted order. The matcher uses Spencer's regular expression package.
The files . and .. are never matched. Other dot files are only matched ifthe dot-files? argument is

#t.

A given pati pattern is matched as a regexp, so it is not forced to matchthe entire file name. E.g., pattern

"t" matches any file containing a "t" inits name, while pattern
"^t$" matches only a file whose entire name is"
t".

The pati patterns can be more general than stated above.

* A single pattern can specify multiple levels of the path by em-bedding

/ characters within the pattern. For example, the pattern
"a/b/c" gives a match equivalent to the list of patterns "a" "b"
"c".

* A pati pattern can be a procedure, which is used as a match predi-cate. It will be repeatedly called with a candidate file-name to test.

The file-name will be the entire path accumulated. If the procedureraises an error condition,

file-match will catch the error and treatit as a failed match. This keeps

file-match from being blown out ofthe water by applying tests to dangling symlinks and other similar

situations.

Some examples:

(file-match "/usr/lib" #f "m$" "^tab") =)

("/usr/lib/term/tab300" "/usr/lib/term/tab300-12" ...)

(file-match "." #f "^lex|parse|codegen$" "\\.c$") =)

("lex/lex.c" "lex/lexinit.c" "lex/test.c"

"parse/actions.c" "parse/error.c" parse/test.c"
"codegen/io.c" "codegen/walk.c")

(file-match "." #f "^lex|parse|codegen$/\\.c$")

;; The same.

(file-match "." #f file-directory?)

;; Return all subdirs of the current directory.

(file-match "/" #f file-directory?) =)

("/bin" "/dev" "/etc" "/tmp" "/usr")
;; All subdirs of root.

(file-match "." #f "\\.c")

;; All the C files in my directory.

(define (ext extension)

(* (fn) (string-suffix? fn extension)))

(define (true . x) #t)

(file-match "." #f "./\\.c")
(file-match "." #f "" "\\.c")
(file-match "." #f true "\\.c")
(file-match "." #f true (ext "c"))

;; All the C files of all my immediate subdirs.

(file-match "." #f "lexer") =)

("mylexer.c" "lexer.notes")
;; Compare with (glob "lexer"), above.

Note that when root is the current working directory ("."), when it isconverted to directory form, it becomes

"", and doesn't show up in theresult file-names.

It is regrettable that the regexp wild card char, ".", is such an importantfile name literal, as dot-file prefix and extension delimiter.

(create-temp-file [prefix]) -! string procedure

Create-temp-file creates a new temporary file and return its name. Theoptional argument specifies the filename prefix to use, and defaults to

the value of "$TMPDIR/pid" if $TMPDIR is set and to "/var/tmp/pid" oth-erwise, where pid is the current process' id. The procedure generates a
sequence of filenames that have prefix as a common prefix, looking fora filename that doesn't already exist in the file system. When it finds
one, it creates it, with permission #o600 and returns the filename. (Thefile permission can be changed to a more permissive permission with
set-file-mode after being created).
This file is guaranteed to be brand new. No other process will have itopen. This procedure does not simply return a filename that is very likely

to be unused. It returns a filename that definitely did not exist at themoment

create-temp-file created it.

It is not necessary for the process' pid to be a part of the filename for theuniqueness guarantees to hold. The pid component of the default prefix

simply serves to scatter the name searches into sparse regions, so thatcollisions are less likely to occur. This speeds things up, but does not
affect correctness.
Security note: doing I/O to files created this way in /var/tmp/ is notnecessarily secure. General users have write access to

/var/tmp/, so evenif an attacker cannot access the new temp file, he can delete it and replace it with one of his own. A subsequent open of this filename will thengive you his file, to which he has access rights. There are several ways to defeat this attack,

1. Use temp-file-iterate, below, to return the file descriptor allo-cated when the file is opened. This will work if the file only needs to be opened once.
2. If the file needs to be opened twice or more, create it in a protected directory, e.g., $HOME.

3. Ensure that /var/tmp has its sticky bit set. This requires system ad-ministrator privileges.

The actual default prefix used is controlled by the dynamic variable
\*temp-file-template\*, and can be overridden for increased security.See

temp-file-iterate.

(temp-file-iterate maker [template]) -! object+ procedure
*temp-file-template* string

This procedure can be used to perform certain atomic transactions on thefile system involving filenames. Some examples:

* Linking a file to a fresh backup temp name.*

Creating and opening an unused, secure temp file.*
Creating an unused temporary directory.

This procedure uses template to generate a series of trial file names.Template is a

format control string, and defaults to

"$TMPDIR/pid.~a"
if $TMPDIR is set and

"/var/tmp/pid.~a"
otherwise where pid is the current process' process id. File names aregenerated by calling

format to instantiate the template's ~a field with avarying string.

Maker is a procedure which is serially called on each file name gener-ated. It must return at least one value; it may return multiple values. If
the first return value is #f or if maker raises the errno/exist errno ex-ception,

temp-file-iterate will loop, generating a new file name andcalling maker again. If the first return value is true, the loop is terminated,

returning whatever value(s) maker returned.
After a number of unsuccessful trials, temp-file-iterate may give upand signal an error.

Thus, if we ignore its optional prefix argument, create-temp-file couldbe defined as:

(define (create-temp-file)

(let ((flags (bitwise-ior open/create open/exclusive)))

(temp-file-iterate

(* (f)

(close (open-output-file f flags #o600))
f))))

To rename a file to a temporary name:

(temp-file-iterate (* (backup)

(create-hard-link old-file backup)
backup)
".#temp.~a") ; Keep link in cwd.
(delete-file old-file)

Recall that scsh reports syscall failure by raising an error exception, notby returning an error code. This is critical to to this example--the programmer can assume that if the temp-file-iterate call returns, it re-turns successully. So the following

delete-file call can be reliably in-voked, safe in the knowledge that the backup link has definitely been

established.
To create a unique temporary directory:

(temp-file-iterate (* (dir) (create-directory dir) dir)

"/var/tmp/tempdir.~a")

Similar operations can be used to generate unique symlinks and fifos, orto return values other than the new filename (e.g., an open file descriptor

or port).
The default template is in fact taken from the value of the dynamic vari-able

*temp-file-template*, which itself defaults to "$TMPDIR/pid.~a"if
$TMPDIR is set and "/usr/tmp/pid.~a" otherwise, where pid is the scshprocess' pid. For increased security, a user may wish to change the template to use a directory not allowing world write access (e.g., his homedirectory).

(temp-file-channel) -! [inp outp] procedure

This procedure can be used to provide an interprocess communicationschannel with arbitrary-sized buffering. It returns two values, an input

port and an output port, both open on a new temp file. The temp file itselfis deleted from the Unix file tree before

temp-file-channel returns, sothe file is essentially unnamed, and its disk storage is reclaimed as soon

as the two ports are closed.
Temp-file-channel is analogous to port-pipe with two exceptions:

* If the writer process gets ahead of the reader process, it will not hangwaiting for some small pipe buffer to drain. It will simply buffer the

data on disk. This is good.*
If the reader process gets ahead of the writer process, it will also nothang waiting for data from the writer process. It will simply see and

report an end of file. This is bad.
In order to ensure that an end-of-file returned to the reader is legit-imate, the reader and writer must serialise their I/O. The simplest

way to do this is for the reader to delay doing input until the writerhas completely finished doing output, or exited.

@section Processes
(exec prog arg1 . . . argn) -! no return value procedure
(exec-path prog arg1 . . . argn) -! no return value procedure
(exec/env prog env arg1 . . . argn) -! no return value procedure
(exec-path/env prog env arg1 . . . argn) -! no return value procedure

The .../env variants take an environment specified as a string!stringalist. An environment of

#t is taken to mean the current process' envi-ronment (i.e., the value of the external char

**environ).

[Rationale: #f is a more convenient marker for the current environmentthan

#t, but would cause an ambiguity on Schemes that identify #f and
().]

The path-searching variants search the directories in the list exec-pathlist for the program. A path-search is not performed if the programname contains a slash character--it is used directly. So a program with

a name like "bin/prog" always executes the program bin/prog in thecurrent working directory. See

$path and exec-path-list, below.

Note that there is no analog to the C function execv(). To get the effectjust do

(apply exec prog arglist)
All of these procedures flush buffered output and close unrevealed portsbefore executing the new binary. To avoid flushing buffered output, see

%exec below.
Note that the C exec() procedure allows the zeroth element of the argu-ment vector to be different from the file being executed, e.g.

char *argv[] = {"-", "-f", 0};
exec("/bin/csh", argv, envp);

The scsh exec, exec-path, exec/env, and exec-path/env procedures donot give this functionality--element 0 of the arg vector is always identical
to the prog argument. In the rare case the user wishes to differentiatethese two items, he can use the low-level

%exec and exec-path-searchprocedures. These procedures never return under any circumstances. As

with any other system call, if there is an error, they raise an exception.
(%exec prog arglist env) -! undefined procedure
(exec-path-search fname pathlist) -! string or #f procedure

The %exec procedure is the low-level interface to the system call. Thearglist parameter is a list of arguments; env is either a string!string alist or #t. The new program's argv[0] will be taken from (car arglist),not from prog. An environment of

#t means the current process' environ-ment.
%exec does not flush buffered output (see flush-all-ports).

All exec procedures, including %exec, coerce the prog and arg valuesto strings using the usual conversion rules: numbers are converted to

decimal numerals, and symbols converted to their print-names.
exec-path-search searches the directories of pathlist looking for an oc-currence of file

fname. If no executable file is found, it returns #f. If
fname contains a slash character, the path search is short-circuited, butthe procedure still checks to ensure that the file exists and is executable--

if not, it still returns #f. Users of this procedure should be aware thatit invites a potential race condition: between checking the file with
exec-path-search and executing it with %exec, the file's status mightchange. The only atomic way to do the search is to loop over the candidate file names, exec'ing each one and looping when the exec operationfails.

See $path and exec-path-list, below.
(exit [status]) -! no return value procedure
(%exit [status]) -! no return value procedure

These procedures terminate the current process with a given exit status.The default exit status is 0. The low-level

%exit procedure immediatelyterminates the process without flushing buffered output.

(call-terminally thunk) -! no return value procedure

call-terminally calls its thunk. When the thunk returns, the processexits. Although

call-terminally could be implemented as

(* (thunk) (thunk) (exit 0))
an implementation can take advantage of the fact that this procedurenever returns. For example, the runtime can start with a fresh stack and also start with a fresh dynamic environment, where shadowed bindingsare discarded. This can allow the old stack and dynamic environment
to be collected (assuming this data is not reachable through some livecontinuation).

(suspend) -! undefined procedure

Suspend the current process with a SIGSTOP signal.

(fork [thunk or #f] [continue-threads?]) -! proc or #f procedure
(%fork [thunk or #f] [continue-threads?]) -! proc or #f procedure

fork with no arguments or #f instead of a thunk is like C fork(). Inthe parent process, it returns the child's process object (see below for more

information on process objects). In the child process, it returns #f.
fork with an argument only returns in the parent process, returning thechild's process object. The child process calls thunk and then exits.

fork flushes buffered output before forking, and sets the child processto non-interactive.

%fork does not perform this bookkeeping; it simplyforks.

The optional boolean argument continue-threads? specifies whether thecurrently active threads continue to run in the child or not. The default is
#f.
(fork/pipe [thunk] [continue-threads?]) -! proc or #f procedure
(%fork/pipe [thunk] [continue-threads?]) -! proc or #f procedure

Like fork and %fork, but the parent and child communicate via a pipeconnecting the parent's stdin to the child's stdout. These procedures sideeffect the parent by changing his stdin.
In effect, fork/pipe splices a process into the data stream immediatelyupstream of the current process. This is the basic function for creating pipelines. Long pipelines are built by performing a sequence of
fork/pipe calls. For example, to create a background two-process pipe a
| b, we write:

(fork (* () (fork/pipe a) (b)))
which returns the process object for b's process.
To create a background three-process pipe a | b | c, we write:

(fork (* () (fork/pipe a)

(fork/pipe b)
(c)))

which returns the process object for c's process.
Note that these procedures affect file descriptors, not ports. That is, thepipe is allocated connecting the child's file descriptor 1 to the parent's file

descriptor 0. Any previous Scheme port built over these affected file descriptorsis shifted to a new, unused file descriptor with

dup before allocating the I/O pipe.This means, for example, that the ports bound to

(current-input-port)and
(current-output-port) in either process are not affected--they stillrefer to the same I/O sources and sinks as before. Remember the simple

scsh rule: Scheme ports are bound to I/O sources and sinks, not particularfile descriptors.

If the child process wishes to rebind the current output port to the pipeon file descriptor 1, it can do this using

with-current-output-portor a related form. Similarly, if the parent wishes to change the current input port to the pipe on file descriptor 0, it can do this using
set-current-input-port! or a related form. Here is an example show-ing how to set up the I/O ports on both sides of the pipe:

(fork/pipe (* ()

(with-current-output-port (fdes->outport 1)

(display "Hello, world.\n"))))

(set-current-input-port! (fdes->inport 0))
(read-line) ; Read the string output by the child.

None of this is necessary when the I/O is performed by an exec'd pro-gram in the child or parent process, only when the pipe will be referenced

by Scheme code through one of the default current I/O ports.
(fork/pipe+ conns [thunk] [continue-threads?]) -! proc or #f procedure
(%fork/pipe+ conns [thunk] [continue-threads?]) -! proc or #f procedure

Like fork/pipe, but the pipe connections between the child and parentare specified by the connection list conns. See the

(|+ conns pf1 ... pfn)
process form for a description of connection lists.

@subsection Process objects and process reaping
Scsh uses process objects to represent Unix processes. They are created by the
fork procedure, and have the following exposed structure:

(define-record proc pid)

The only exposed slot in a proc record is the process' pid, the integer id as-signed by Unix to the process. The only exported primitive procedures for manipulating process objects are proc? and proc:pid. Process objects are createdwith the fork procedure.

(pid->proc pid [probe?]) -! proc procedure

This procedure maps integer Unix process ids to scsh process objects. Itis intended for use in interactive and debugging code, and is deprecated

for use in production code. If there is no process object in the systemindexed by the given pid,

pid->proc's action is determined by the probe?parameter (default
#f):

probe? Return
#f signal error condition.
'create Create new proc object.True value

#f

Sometime after a child process terminates, scsh will perform a wait systemcall on the child in background, caching the process' exit status in the child's
proc object. This is called "reaping" the process. Once the child has beenwaited, the Unix kernel can free the storage allocated for the dead process'
exit information, so process reaping prevents the process table from becomingcluttered with un-waited dead child processes (a.k.a. "zombies"). This can be
especially severe if the scsh process never waits on child processes at all; if theprocess table overflows with forgotten zombies, the OS may be unable to fork
further processes.

Reaping a child process moves its exit status information from the kernelinto the scsh process, where it is cached inside the child's process object. If

the scsh user drops all pointers to the process object, it will simply be garbagecollected. On the other hand, if the scsh program retains a pointer to the process object, it can use scsh's wait system call to synchronise with the child andretrieve its exit status multiple times (this is not possible with simple Unix integer pids in C--the programmer can only wait on a pid once).

Thus, process objects allow scsh programmer to do two things not allowedin other programming environments:

* Subprocesses that are never waited on are still removed from the pro-cess table, and their associated exit status data is eventually automatically garbage collected.

* Subprocesses can be waited on multiple times.

However, note that once a child has exited, if the scsh programmer dropsall pointers to the child's proc object, the child's exit status will be reaped and

58

thrown away. This is the intended behaviour, and it means that integer pids arenot enough to cause a process's exit status to be retained by the scsh runtime.
(This is because it is clearly impossible to GC data referenced by integers.)

As a convenience for interactive use and debugging, all procedures thattake process objects will also accept integer Unix pids as arguments, coercing

them to the corresponding process objects. Since integer process ids are notreliable ways to keep a child's exit status from being reaped and garbage collected, programmers are encouraged to use process objects in production code.
(autoreap-policy [policy]) -! old-policy procedure

The scsh programmer can choose different policies for automatic processreaping. The policy is determined by applying this procedure to one of

the values 'early, 'late, or #f (i.e., no autoreap).
early The child is reaped from the Unix kernel's process table into scshas soon as it dies. This is done by having a signal handler for the

SIGCHLD signal reap the process.
late The child is not autoreaped until it dies and the scsh program dropsall pointers to its process object. That is, the process table is cleaned

out during garbage collection.
#f If autoreaping is turned off, process reaping is completely under con-trol of the programmer, who can force outstanding zombies to be

reaped by manually calling the reap-zombies procedure (see be-low).

Note that under any of the autoreap policies, a particular process p canbe manually reaped into scsh by simply calling

(wait p). All zombiescan be manually reaped with
reap-zombies.

The autoreap-policy procedure returns the policy's previous value.Calling

autoreap-policy with no arguments returns the current policywithout no change.

(reap-zombies) -! boolean procedure

This procedure reaps all outstanding exited child processes into scsh. Itreturns true if there are no more child processes to wait on, and false if

there are outstanding processes still running or suspended.

Issues with process reaping
Reaping a process does not reveal its process group at the time of death; thisinformation is lost when the process reaped. This means that a dead, reaped

59

process is not eligible as a return value for a future wait-process-group call.This is not likely to be a problem for most code, as programs almost never wait
on exited processes by process group. Process group waiting is usually appliedto stopped processes, which are never reaped. So it is unlikely that this will be
a problem for most programs.

Automatic process reaping is a useful programming convenience. How-ever, if a program is careful to wait for all children, and does not wish automatic reaping to happen, the programmer can simply turn process autoreapingoff.

Programs that do not wish to use automatic process reaping should beaware that some scsh routines create subprocesses but do not return the child's
pid: run/port*, and its related procedures and special forms (run/strings, etal.). Automatic process reaping will clean the child processes created by these
procedures out of the kernel's process table. If a program doesn't use processreaping, it should either avoid these forms, or use

wait-any to wait for thechildren to exit.

@subsection Process waiting
(wait proc/pid [flags]) -! status procedure

This procedure waits until a child process exits, and returns its exit code.The proc/pid argument is either a process object (section @ref{3.4.1}) or an integer process id. Wait returns the child's exit status code (or suspensioncode, if the

wait/stopped-children option is used, see below). Statusvalues can be queried with the procedures in section @ref{3.4.3}.

The flags argument is an integer whose bits specify additional options. Itis composed by or'ing together the following flags:

Flag Meaning
wait/poll Return #f immediately if child still active.
wait/stopped-children Wait for suspend as well as exit.

(wait-any [flags]) -! [proc status] procedure

The optional flags argument is as for wait. This procedure waits for anychild process to exit (or stop, if the

wait/stopped-children flag is used)It returns the process' process object and status code. If there are no children left for which to wait, the two values [#f #t] are returned. If the
wait/poll flag is used, and none of the children are immediately eligblefor waiting, then the values

[#f #f] are returned:

[#f #f] Poll, none ready[

#f #t] No children

60

Wait-any will not return a process that has been previouslywaited by any other process-wait procedure (

wait, wait-any, and
wait-process-group). It will return reaped processes that haven't yetbeen waited.

The use of wait-any is deprecated.

(wait-process-group proc/pid [flags]) -! [proc status] procedure

This procedure waits for any child whose process group is proc/pid (eithera process object or a pid). The flags argument is as for

wait.

Note that if the programmer wishes to wait for exited processes by pro-cess group, the program should take care not to use process reaping

(section @ref{3.4.1}), as this loses process group information. However, mostprocess-group waiting is for stopped processes (to implement job control), so this is rarely an issue, as stopped processes are not subject toreaping.

@subsection Analysing process status codes
When a child process dies (or is suspended), its parent can call the wait pro-cedure to recover the exit (or suspension) status of the child. The exit status is
a small integer that encodes information describing how the child terminated.The bit-level format of the exit status is not defined by P

OSIX; you must usethe following three functions to decode one. However, if a child terminates

normally with exit code 0, @acronym{POSIX} does require wait to return an exit status thatis exactly zero. So

(zero? status) is a correct way to test for non-error, normaltermination, e.g.,

(if (zero? (run (rcp scsh.tar.gz lambda.csd.hku.hk:)))

(delete-file "scsh.tar.gz"))

(status:exit-val status) -! integer or #f procedure
(status:stop-sig status) -! integer or #f procedure
(status:term-sig status) -! integer or #f procedure

For a given status value produced by calling wait, exactly one of theseroutines will return a true value.

If the child process exited normally, status:exit-val returns the exitcode for the child process (i.e., the value the child passed to

exit or re-turned from
main). Otherwise, this function returns false.

61

If the child process was suspended by a signal, status:stop-sig returnsthe signal that suspended the child. Otherwise, this function returns
false.
If the child process terminated abnormally, status:term-sig returns thesignal that terminated the child. Otherwise, this function returns false.

@section Process state
(umask) -! fixnum procedure
(set-umask perms) -! undefined procedure
(with-umask* perms thunk) -! value(s) of thunk procedure
(with-umask perms . body) -! value(s) of body syntax

The process' current umask is retrieved with umask, and set with
(set-umask perms). Calling with-umask* changes the umask to permsfor the duration of the call to thunk. If the program throws out of thunk

by invoking a continuation, the umask is reset to its external value. Ifthe program throws back into thunk by calling a stored continuation, the
umask is restored to the perms value. The special form with-umask isequivalent in effect to the procedure

with-umask*, but does not requirethe programmer to explicitly wrap a
(* () ...) around the body of thecode to be executed.

(chdir [fname]) -! undefined procedure
(cwd) -! string procedure
(with-cwd* fname thunk) -! value(s) of thunk procedure
(with-cwd fname . body) -! value(s) of body syntax

These forms manipulate the current working directory. The cwd can bechanged with

chdir (although in most cases, with-cwd is preferrable). If
chdir is called with no arguments, it changes the cwd to the user's homedirectory. The

with-cwd* procedure calls thunk with the cwd temporar-ily set to fname; when thunk returns, or is exited in a non-local fashion

(e.g., by raising an exception or by invoking a continuation), the cwd isreturned to its original value. The special form

with-cwd is simply syn-tactic sugar for
with-cwd*.

(pid) -! fixnum procedure
(parent-pid) -! fixnum procedure
(process-group) -! fixnum procedure
(set-process-group [proc/pid] pgrp) -! undefined procedure

(pid) and (parent-pid) retrieve the process id for the current processand its parent.

(process-group) returns the process group of the current

62

process. A process' process-group can be set with set-process-group;the value proc/pid specifies the affected process. It may be either a process
object or an integer process id, and defaults to the current process.
(set-priority which who priority) -! undefined procedure
(priority which who) -! fixnum procedure
(nice [proc/pid delta]) -! undefined procedure

These procedures set and access the priority of processes. I can't remem-ber how

set-priority and priority work, so no documentation, andbesides, they aren't implemented yet, anyway.

(user-login-name) -! string procedure
(user-uid) -! fixnum procedure
(user-gid) -! fixnum procedure
(user-supplementary-gids) -! fixnum list procedure
(set-uid uid) -! undefined procedure
(set-gid gid) -! undefined procedure

These routines get and set the effective and real user and group ids. The
set-uid and set-gid routines correspond to the @acronym{POSIX} setuid() and
setgid() procedures.

(user-effective-uid) -! fixnum procedure
(set-user-effective-uid fixnum) -! undefined procedure
(with-user-effective-uid* fixnum thunk) -! value(s) of thunk procedure
(with-user-effective-uid fixnum . body) -! value(s) of body syntax
(user-effective-gid) -! fixnum procedure
(set-user-effective-gid fixnum) -! undefined procedure
(with-user-effective-gid* fixnum thunk) -! value(s) of thunk procedure
(with-user-effective-gid fixnum . body) -! value(s) of body syntax

These forms manipulate the effective user/group IDs. Possible valuesfor setting this resource are either the real user/group ID or the saved

set-user/group-ID. The with-... forms perform the ususal tempraryassignment during the execution of the second argument. The effective
user and group IDs are thread-local.
(process-times) -! [fixnum fixnum fixnum fixnum] procedure

Returns four values:user CPU time in clock-ticks

system CPU time in clock-ticksuser CPU time of all descendant processes
system CPU time of all descendant processesNote that CPU time clock resolution is not the same as the real-time clock
resolution provided by time+ticks. That's Unix.

63

(cpu-ticks/sec) -! integer procedure

Returns the resolution of the CPU timer in clock ticks per second. Thiscan be used to convert the times reported by

process-times to seconds.

@section User and group database access
These procedures are used to access the user and group databases (e.g., theones traditionally stored in

/etc/passwd and /etc/group.)

(user-info uid/name) -! record procedure

Return a user-info record giving the recorded information for a partic-ular user:

(define-record user-info

name uid gid home-dir shell)

The uid/name argument is either an integer uid or a string user-name.

(->uid uid/name) -! fixnum procedure
(->username uid/name) -! string procedure

These two procedures coerce integer uid's and user names to a particularform.

(group-info gid/name) -! record procedure

Return a group-info record giving the recorded information for a partic-ular group:

(define-record group-info

name gid members)

The gid/name argument is either an integer gid or a string group-name.

@section Accessing command-line arguments
command-line-arguments string list
(command-line) -! string list procedure

The list of strings command-line-arguments contains the argumentspassed to the scsh process on the command line. Calling

(command-line)returns the complete
argv string list, including the program. So if we runa scsh program

/usr/shivers/bin/myls -CF src

64

then command-line-arguments is

("-CF" "src")
and (command-line) returns

("/usr/shivers/bin/myls" "-CF" "src")
command-line returns a fresh list each time it is called. In this way,the programmer can get a fresh copy of the original argument list if

command-line-arguments has been modified or is lexically shadowed.
(arg arglist n [default]) -! string procedure
(arg* arglist n [default-thunk]) -! string procedure
(argv n [default]) -! string procedure

These procedures are useful for accessing arguments from argument lists.
arg returns the nth element of arglist. The index is 1-based. If n is toolarge, default is returned; if no default, then an error is signaled.

arg* is similar, except that the default-thunk is called to generate the de-fault value.
(argv n) is simply (arg (command-line) (+ n 1)). The +1 offset en-sures that the two forms

(arg command-line-arguments n)
(argv n)

return the same argument (assuming the user has not rebound or modi-fied

command-line-arguments).

Example:

(if (null? command-line-arguments)

(& (xterm -n ,host -title ,host

-name ,(string-append "xterm_" host)))
(let* ((progname (file-name-nondirectory (argv 1)))

(title (string-append host ":" progname)))
(& (xterm -n ,title

-title ,title
-e ,@command-line-arguments))))

A subtlety: when the scsh interpreter is used to execute a scsh program,the program name reported in the head of the

(command-line) list is thescsh program, not the interpreter. For example, if we have a shell script

in file fullecho:

#!/usr/local/bin/scsh -s
!#
(for-each (* (arg) (display arg) (display " "))

(command-line))

65

and we run the program

fullecho hello world
the program will print out

fullecho hello world
not

/usr/local/bin/scsh -s fullecho hello world

This argument line processing ensures that if a scsh program is sub-sequently compiled into a standalone executable or byte-compiled to a
heap-image executable by the Scheme 48 virtual machine, its semanticswill be unchanged--the arglist processing is invariant. In effect, the

/usr/local/bin/scsh -s
is not part of the program; it's a specification for the machine to executethe program on, so it is not properly part of the program's argument list.

@section System parameters
(system-name) -! string procedure

Returns the name of the host on which we are executing. This may be alocal name, such as "solar," as opposed to a fully-qualified domain name

such as "solar.csie.ntu.edu.tw."
(uname) -! uname-record procedure

Returns a uname-record of the following structure:

(define-record uname

os-name
node-name
release
version
machine)

Each of the fields contains a string.
Be aware that @acronym{POSIX} limits the length of all entries to 32 characters, andthat the node name does not necessarily correspond to the fully-qualified

domain name.

66

@section Signal system
Signal numbers are bound to the variables signal/hup, signal/int, . . . . Seetables 3.9 and 3.3 for the full list.

(signal-process proc sig) -! undefined procedure
(signal-process-group prgrp sig) -! undefined procedure

These two procedures send signals to a specific process, and all the pro-cesses in a specific process group, respectively. The proc and prgrp arguments are either processes or integer process ids.
(itimer secs) -! undefined procedure

Schedules a timer interrupt in secs seconds.{
Note As the thread system needs the timer interrupt for its own purpose,
itimer works by spawning a thread which calls the interrupt handler for
interrupt/alrm after the specified time.}

(process-sleep secs) -! undefined procedure
(process-sleep-until time) -! undefined procedure

The sleep procedure causes the process to sleep for secs seconds. The
sleep-until procedure causes the process to sleep until time (see section @ref{3.10}).

{Note The use of these procedures is deprecated as they suspend all run-ning threads, including the ones Scsh uses for administrtive purposes.
Consider using the sleep procedure from the thread package.}

Interrupt handlers
Scsh interrupt handlers are complicated by the fact that scsh is implemented ontop of the Scheme 48 virtual machine, which has its own interrupt system, independent of the Unix signal system. This means that Unix signals are deliveredin two stages: first, Unix delivers the signal to the Scheme 48 virtual machine,
then the Scheme 48 virtual machine delivers the signal to the executing Schemeprogram as a Scheme 48 interrupt. This ensures that signal delivery happens
between two VM instructions, keeping individual instructions atomic.

The Scheme 48 machine has its own set of interrupts, which includes theasynchronous Unix signals (table 3.9).

(signal->interrupt integer) -! integer procedure

The programmer maps from Unix signals to Scheme 48 interrupts withthe

signal->interrupt procedure. If the signal does not have a definedScheme 48 interrupt, an error is signaled.

67

Interrupt Unix signal OS Variant
interrupt/alrma signal/alrm @acronym{POSIX}
interrupt/intb signal/int @acronym{POSIX}
interrupt/memory-shortage N/A
interrupt/chld signal/chld @acronym{POSIX}
interrupt/cont signal/cont @acronym{POSIX}
interrupt/hup signal/hup @acronym{POSIX}
interrupt/quit signal/quit @acronym{POSIX}
interrupt/term signal/term @acronym{POSIX}
interrupt/tstp signal/tstp @acronym{POSIX}
interrupt/usr1 signal/usr1 @acronym{POSIX}
interrupt/usr2 signal/usr2 @acronym{POSIX}

interrupt/info signal/info BSD only
interrupt/io signal/io BSD + SVR4
interrupt/poll signal/poll SVR4 only
interrupt/prof signal/prof BSD + SVR4
interrupt/pwr signal/pwr SVR4 only
interrupt/urg signal/urg BSD + SVR4
interrupt/vtalrm signal/vtalrm BSD + SVR4
interrupt/winch signal/winch BSD + SVR4
interrupt/xcpu signal/xcpu BSD + SVR4
interrupt/xfsz signal/xfsz BSD + SVR4

Table 3.2: Scheme 48 virtual-machine interrupts and related Unix signals. Onlythe P

OSIX signals are guaranteed to be defined; however, your implementationand OS may define other signals and interrupts not listed here.

aAlso bound to Scheme 48 interrupt interrupt/alarm.
bAlso bound to Scheme 48 interrupt interrupt/keyboard.

68

Unix signal Type OS Variant
signal/stop Uncatchable @acronym{POSIX}
signal/kill Uncatchable @acronym{POSIX}

signal/abrt Synchronous @acronym{POSIX}
signal/fpe Synchronous @acronym{POSIX}
signal/ill Synchronous @acronym{POSIX}
signal/pipe Synchronous @acronym{POSIX}
signal/segv Synchronous @acronym{POSIX}
signal/ttin Synchronous @acronym{POSIX}
signal/ttou Synchronous @acronym{POSIX}

signal/bus Synchronous BSD + SVR4
signal/emt Synchronous BSD + SVR4
signal/iot Synchronous BSD + SVR4
signal/sys Synchronous BSD + SVR4
signal/trap Synchronous BSD + SVR4

Table 3.3: Uncatchable and synchronous Unix signals. While these signals maybe sent with

signal-process or signal-process-group, there are no corre-sponding scsh interrupt handlers. Only the P

OSIX signals are guaranteed to bedefined; however, your implementation and OS may define other signals not

listed here.

69

(interrupt-set integer1 . . . integern) -! integer procedure

This procedure builds interrupt sets from its interrupt arguments. A setis represented as an integer using a two's-complement representation of

the bit set.

(enabled-interrupts) -! interrupt-set procedure
(set-enabled-interrupts interrupt-set) -! interrupt-set procedure

Get and set the value of the enabled-interrupt set. Only interrupts in thisset have their handlers called when delivered. When a disabled interrupt

is delivered to the Scheme 48 machine, it is held pending until it becomesenabled, at which time its handler is invoked.

Interrupt sets are represented as integer bit sets (constructed with the
interrupt-set function). The set-enabled-interrupts procedure re-turns the previous value of the enabled-interrupt set.

(with-enabled-interrupts interrupt-set . body) -! value(s) of body syntax
(with-enabled-interrupts* interrupt-set thunk) -! value(s) of thunk procedure

Run code with a given set of interrupts enabled. Note that "enabling"an interrupt means enabling delivery from the Scheme 48 vm to the scsh

program. Using the Scheme 48 interrupt system is fairly lightweight,and does not involve actually making a system call. Note that enabling
an interrupt means that the assigned interrupt handler is allowed to runwhen the interrupt is delivered. Interrupts not enabled are held pending
when delivered.
Interrupt sets are represented as integer bit sets (constructed with the
interrupt-set function).

(set-interrupt-handler interrupt handler) -! old-handler procedure

Assigns a handler for a given interrupt, and returns the interrupt's oldhandler. The handler argument is

#f (ignore), #t (default), or a proceduretaking an integer argument; the return value follows the same conventions. Note that the interrupt argument is an interrupt value, not a signalvalue. An interrupt is delivered to the Scheme 48 machine by (1) blocking all interrupts, and (2) applying the handler procedure to the set ofinterrupts that were enabled prior to the interrupt delivery. If the procedure returns normally (i.e., it doesn't throw to a continuation), the setof enabled interrupts will be returned to its previous value. (To restore
the enabled-interrupt set before throwing out of an interrupt handler, see
set-enabled-interrupts)

70

{Note If you set a handler for the interrupt/chld interrupt, you maybreak scsh's autoreaping process machinery. See the discussion of autoreaping in section @ref{3.4.1}.}
{Note We recommend you avoid using interrupt handlers unless you ab-solutely have to; Section @ref{9.4} describes a better interface to handling signals.}

(interrupt-handler interrupt) -! handler procedure

Return the handler for a given interrupt. Note that the argument is aninterrupt value, not a signal value. A handler is either

#f (ignore), #t(default), or a procedure taking an integer argument.

Note that scsh does not support interrupt handlers for "synchronous" Unixsignals, such as

signal/ill or signal/pipe (see table 3.3). Synchronous oc-currences of these signals are better handled by raising a Scheme exception.

There are, however, some rare situtations where it is necessary to ignore theoccurrence of a synchronous signal. For this case, the following procedures
exist:
(ignore-signal integer) -! undefined procedure
(handle-signal-default integer) -! undefined procedure

The procedure ignore-signal tells the process to ignore the given signal.The procedure

handle-signal-default resets the signal handler to thedefault handler.

These procedures manipulate the raw signal handler of the scsh processand therfore undermine the signal handling facility of the VM. They are
intended to be used for igoring synchronous signals if system calls can-not succeed otherwise. Do not use these procedures for asynchronous
signals!

@section Time

Scsh's time system is fairly sophisticated, particularly with respect to its carefultreatment of time zones. However, casual users shouldn't be intimidated; all of
the complexity is optional, and defaulting all the optional arguments reducesthe system to a simple interface.

71

@subsection Terminology

"UTC" and "UCT" stand for "universal coordinated time," which is the officialname for what is colloquially referred to as "Greenwich Mean Time."

@acronym{POSIX} allows a single time zone to specify two different offsets from UTC:one standard one, and one for "summer time." Summer time is frequently
some sort of daylight savings time.

The scsh time package consistently uses this terminology: we never say"gmt" or "dst;" we always say "utc" and "summer time."

@subsection Basic data types

We have two types: time and date.

A time specifies an instant in the history of the universe. It is location andtime-zone independent.4 A time is a real value giving the number of elapsed

seconds since the Unix "epoch" (Midnight, January 1, 1970 UTC). Time valuesprovide arbitrary time resolution, limited only by the number system of the
underlying Scheme system.

A date is a name for an instant in time that is specified relative to somelocation/time-zone in the world, e.g.:

Friday October 31, 1994 3:47:21 pm EST.Dates provide one-second resolution, and are expressed with the following
record type:

(define-record date ; A Posix tm struct

seconds ; Seconds after the minute [0-59]
minute ; Minutes after the hour [0-59]
hour ; Hours since midnight [0-23]
month-day ; Day of the month [1-31]
month ; Months since January [0-11]
year ; Years since 1900
tz-name ; Time-zone name: #f or a string.
tz-secs ; Time-zone offset: #f or an integer.
summer? ; Summer (Daylight Savings) time in effect?
week-day ; Days since Sunday [0-6]
year-day) ; Days since Jan. 1 [0-365]

If the tz-secs field is given, it specifies the time-zone's offset from UTC inseconds. If it is specified, the

tz-name and summer? fields are ignored whenusing the date structure to determine a specific instant in time.

4Physics pedants please note: The scsh authors live in a Newtonian universe. We disclaim
responsibility for calculations performed in non-@acronym{ANSI} standard light-cones.

72

If the tz-name field is given, it is a time-zone string such as "EST" or
"HKT" understood by the OS. Since @acronym{POSIX} time-zone strings can specify dualstandard/summer time-zones (e.g., "EST5EDT" specifies U.S. Eastern Standard/Eastern Daylight Time), the value of the summer? field is used to resolvethe amiguous boundary cases. For example, on the morning of the Fall daylight savings change-over, 1:00am-2:00am happens twice. Hence the date 1:30am on this morning can specify two different seconds; the

summer? flag sayswhich one.

A date with tz-name = tz-secs = #f is a date that is specified in terms ofthe system's current time zone.
There is redundancy in the date data structure. For example, the year-dayfield is redundant with the

month-day and month fields. Either of these impliesthe values of the
week-day field. The summer? and tz-name fields are redun-dant with the
tz-secs field in terms of specifying an instant in time. Thisredundancy is provided because consumers of dates may want it broken out

in different ways. The scsh procedures that produce date records fill them outcompletely. However, when date records produced by the programmer are
passed to scsh procedures, the redundancy is resolved by ignoring some of thesecondary fields. This is described for each procedure below.

(make-date s min h mday mon y [tzn tzs summ? wday yday]) -! date procedure

When making a date record, the last five elements of the record are op-tional, and default to

#f, #f, #f, 0, and 0 respectively. This is useful whencreating a
date record to pass as an argument to time. Other procedures,however, may refuse to work with these incomplete

date records.

@subsection Time zones

Several time procedures take time zones as arguments. When optional, thetime zone defaults to local time zone. Otherwise the time zone can be one of:

#f Local timeInteger Seconds of offset from UTC. For example, New York City is -18000 (-5 hours), San Francisco is-28800 (-8 hours).

String A @acronym{POSIX} time zone string understood by the OS(i.e.., the sort of time zone assigned to the $TZ environment variable).

An integer time zone gives the number of seconds you must add to UTC to gettime in that zone. It is not "seconds west" of UTC--that flips the sign.

To get UTC time, use a time zone of either 0 or "UCT0".

73

@subsection Procedures

(time+ticks) -! [secs ticks] procedure
(ticks/sec) -! real procedure

The current time, with sub-second resolution. Sub-second resolution is not provided by @acronym{POSIX}, but is available on many systems. The time isreturned as elapsed seconds since the Unix epoch, plus a number of subsecond "ticks." The length of a tick may vary from implementation toimplementation; it can be determined from

(ticks/sec).

The system clock is not required to report time at the full resolution givenby

(ticks/sec). For example, on BSD, time is reported at 1us resolution,so

(ticks/sec) is 1,000,000. That doesn't mean the system clock hasmicro-second resolution.

If the OS does not support sub-second resolution, the ticks value is always0, and

(ticks/sec) returns 1.

Remark: I chose to represent system clock resolution as ticks/secinstead of sec/tick to increase the odds that the value could be represented as an exact integer, increasing efficiency and making it easierfor Scheme implementations that don't have sophisticated numeric
support to deal with the quantity.
You can convert seconds and ticks to seconds with the expression

(+ secs (/ ticks (ticks/sec)))

Given that, why not have the fine-grain time procedure just return anon-integer real for time? Following Common Lisp, I chose to allow

the system clock to report sub-second time in its own units to lowerthe overhead of determining the time. This would be important for a
system that wanted to precisely time the duration of some event. Timestamps could be collected with little overhead, deferring the overhead
of precisely calculating with them until after collection.
This is all a bit academic for the Scheme 48 implementation, where wedetermine time with a heavyweight system call, but it's nice to plan

for the future.

(date) -! date-record procedure
(date [time tz]) -! date-record procedure

Simple (date) returns the current date, in the local time zone.
With the optional arguments, date converts the time to the date as spec-ified by the time zone tz. Time defaults to the current time; tz defaults to

local time, and is as described in the time-zone section.
If the tz argument is an integer, the date's tz-name field is a @acronym{POSIX} timezone of the form "

UTC+hh :mm :ss "; the trailing :mm :ss portion is deletedif it is zeroes.

74

Oops: The Posix facility for converting dates to times, mktime(), hasa broken design: it indicates an error by returning -1, which is also a
legal return value (for date 23:59:59 UCT, 12/31/1969). Scsh resolvesthe ambiguity in a paranoid fashion: it always reports an error if the
underlying Unix facility returns -1. We feel your pain.

(time) -! integer procedure
(time [date]) -! integer procedure

Simple (time) returns the current time.
With the optional date argument, time converts a date to a time. Datedefaults to the current date.

Note that the input date record is overconstrained. time ignores date's
week-day and year-day fields. If the date's tz-secs field is set, the
tz-name and summer? fields are ignored.

If the tz-secs field is #f, then the time-zone is taken from the tz-namefield. A false

tz-name means the system's current time zone. When cal-culating with time-zones, the date's

summer? field is used to resolve am-biguities:

#f Resolve an ambiguous time in favor of non-summer time.true Resolve an ambiguous time in favor of summer time.
This is useful in boundary cases during the change-over. For example, inthe Fall, when US daylight savings time changes over at 2:00 am, 1:30 am
happens twice--it names two instants in time, an hour apart.
Outside of these boundary cases, the summer? flag is ignored. For ex-ample, if the standard/summer change-overs happen in the Fall and the

Spring, then the value of summer? is ignored for a January or July date. AJanuary date would be resolved with standard time, and a July date with
summer time, regardless of the summer? value.
The summer? flag is also ignored if the time zone doesn't have a summertime--for example, simple UTC.

(date->string date) -! string procedure
(format-date fmt date) -! string procedure

Date->string formats the date as a 24-character string of the form:Sun Sep 16 01:03:52 1973

Format-date formats the date according to the format string fmt. Theformat string is copied verbatim, except that tilde characters indicate conversion specifiers that are replaced by fields from the date record. Figure3.1 gives the full set of conversion specifiers supported by

format-date.

(fill-in-date! date) -! date procedure

75

~~ Converted to the ~ character.
~a abbreviated weekday name
~A full weekday name
~b abbreviated month name
~B full month name
~c time and date using the time and date representation for the locale(

~X ~x)

~d day of the month as a decimal number (01-31)
~H hour based on a 24-hour clock as a decimal number (00-23)
~I hour based on a 12-hour clock as a decimal number (01-12)
~j day of the year as a decimal number (001-366)
~m month as a decimal number (01-12)
~M minute as a decimal number (00-59)
~p AM/PM designation associated with a 12-hour clock
~S second as a decimal number (00-61)
~U week number of the year; Sunday is first day of week (00-53)
~w weekday as a decimal number (0-6), where Sunday is 0
~W week number of the year; Monday is first day of week (00-53)
~x date using the date representation for the locale
~X time using the time representation for the locale
~y year without century (00-99)
~Y year with century (e.g.1990)
~Z time zone name or abbreviation, or no characters if no time zone isdeterminable

Figure 3.1: format-date conversion specifiers

76

This procedure fills in missing, redundant slots in a date record. In de-creasing order of priority:

* year, month, month-day ) year-dayIf the

year, month, and month-day fields are all defined (are all inte-gers), the

year-day field is set to the corresponding value.*

year, year-day ) month, month-dayIf the

month and month-day fields aren't set, but the year and
year-day fields are set, then month and month-day are calculated.*

year, month, month-day, year-day ) week-dayIf either of the above rules is able to determine what day it is, the

week-day field is then set.*
tz-secs ) tz-nameIf

tz-secs is defined, but tz-name is not, it is assigned a time-zonename of the form "

UTC+hh :mm :ss "; the trailing :mm :ss portion isdeleted if it is zeroes.

* tz-name, date, summer? ) tz-secs, summer?If the date information is provided up to second resolution,

tz-nameis also provided, and
tz-secs is not set, then tz-secs and summer?are set to their correct values. Summer-time ambiguities are resolved using the original value of summer?. If the time zone doesn'thave a summer time variant, then

summer? is set to #f.*

local time, date, summer? ) tz-name, tz-secs, summer?If the date information is provided up to second resolution, but no

time zone information is provided (both tz-name and tz-secs aren'tset), then we proceed as in the above case, except the system's current time zone is used.
These rules allow one particular ambiguity to escape: if both tz-nameand

tz-secs are set, they are not brought into agreement. It isn't clearhow to do this, nor is it clear which one should take precedence.

Oops: fill-in-date! isn't implemented yet.

@section Environment variables

(setenv var val) -! undefined procedure
(getenv var) -! string procedure

These functions get and set the process environment, stored in the exter-nal C variable

char **environ. An environment variable var is a string.If an environment variable is set to a string val, then the process' global

77

environment structure is altered with an entry of the form "var=val". Ifval is

#f, then any entry for var is deleted.

(env->alist) -! string!string alist procedure

The env->alist procedure converts the entire environment into an alist,e.g.,

(("TERM" . "vt100")

("SHELL" . "/usr/local/bin/scsh")
("PATH" . "/sbin:/usr/sbin:/bin:/usr/bin")
("EDITOR" . "emacs")
...)

(alist->env alist) -! undefined procedure

Alist must be an alist whose keys are all strings, and whose values areall either strings or string lists. String lists are converted to colon lists

(see below). The alist is installed as the current Unix environment (i.e.,converted to a null-terminated C vector of

"var=val" strings which is as-signed to the global
char **environ).

;;; Note $PATH entry is converted
;;; to /sbin:/usr/sbin:/bin:/usr/bin.
(alist->env '(("TERM" . "vt100")

("PATH" "/sbin" "/usr/sbin" "/bin")
("SHELL" . "/usr/local/bin/scsh")))

Note that env->alist and alist->env are not exact inverses--
alist->env will convert a list value into a single colon-separated string,but

env->alist will not parse colon-separated values into lists. (See the
$PATH element in the examples given for each procedure.)

The following three functions help the programmer manipulate alist tablesin some generally useful ways. They are all defined using

equal? for key com-parison.

(alist-delete key alist) -! alist procedure

Delete any entry labelled by value key.

(alist-update key val alist) -! alist procedure

Delete key from alist, then cons on a (key . val) entry.

78

(alist-compress alist) -! alist procedure

Compresses alist by removing shadowed entries. Example:

;;; Shadowed (1 . c) entry removed.
(alist-compress '( (1 . a) (2 . b) (1 . c) (3 . d) ))=)

((1 . a) (2 . b) (3 . d))

(with-env* env-alist-delta thunk) -! value(s) of thunk procedure
(with-total-env* env-alist thunk) -! value(s) of thunk procedure

These procedures call thunk in the context of an altered environment.They return whatever values thunk returns. Non-local returns restore the

environment to its outer value; throwing back into the thunk by invokinga stored continuation restores the environment back to its inner value.

The env-alist-delta argument specifies a modification to the current environ-ment--thunk's environment is the original environment overridden with
the bindings specified by the alist delta.
The env-alist argument specifies a complete environment that is installedfor thunk.

(with-env env-alist-delta . body) -! value(s) of body syntax
(with-total-env env-alist . body) -! value(s) of body syntax

These special forms provide syntactic sugar for with-env* and withtotal-env*. The env alists are not evaluated positions, but are implicitlybackquoted. In this way, they tend to resemble binding lists for

let and
let* forms.

Example: These four pieces of code all run the mailer with special $TERMand

$EDITOR values.

(with-env (("TERM" . "xterm") ("EDITOR" . ,my-editor))

(run (mail shivers@lcs.mit.edu)))

(with-env* `(("TERM" . "xterm") ("EDITOR" . ,my-editor))

(* () (run (mail shivers@csd.hku.hk))))

(run (begin (setenv "TERM" "xterm") ; Env mutation happens

(setenv "EDITOR" my-editor) ; in the subshell.
(exec-epf (mail shivers@research.att.com))))

79

;; In this example, we compute an alternate environment ENV2
;; as an alist, and install it with an explicit call to the
;; EXEC-PATH/ENV procedure.
(let* ((env (env->alist)) ; Get the current environment,

(env1 (alist-update env "TERM" "xterm")) ; and compute
(env2 (alist-update env1 "EDITOR" my-editor))) ; the new env.
(run (begin (exec-path/env "mail" env2 "shivers@cs.cmu.edu"))))

@subsection Path lists and colon lists

When environment variables such as $PATH need to encode a list of strings(such as a list of directories to be searched), the common Unix convention is
to separate the list elements with colon delimiters.5 To convert between thecolon-separated string encoding and the list-of-strings representation, see the
infix-splitter function (section @ref{8.1.2}) and the string library's string-joinfunction. For example,

(define split (infix-splitter (rx ":")))
(split "/sbin:/bin::/usr/bin") )

'("/sbin" "/bin" "" "/usr/bin")
(string-join ":" '("/sbin" "/bin" "" "/usr/bin")) )

"/sbin:/bin::/usr/bin"

The following two functions are useful for manipulating these ordered lists,once they have been parsed from their colon-separated form.

(add-before elt before list) -! list procedure
(add-after elt after list) -! list procedure

These functions are for modifying search-path lists, where element orderis significant.

add-before adds elt to the list immediately before the first occurrence ofbefore in the list. If before is not in the list, elt is added to the end of the list.
add-after is similar: elt is added after the last occurrence of after. If afteris not found, elt is added to the beginning of the list.
Neither function destructively alters the original path-list. The result mayshare structure with the original list. Both functions use

equal? for com-paring elements.

5. . . and hope the individual list elements don't contain colons themselves.

80

@subsection $USER, $HOME, and $PATH

Like sh and unlike csh, scsh has no interactive dependencies on environmentvariables. It does, however, initialise certain internal values at startup time
from the initial process environment, in particular $HOME and $PATH. Scshnever uses

$USER at all. It computes (user-login-name) from the system call
(user-uid).

home-directory string
exec-path-list string list thread-fluid

Scsh accesses $HOME at start-up time, and stores the value in the globalvariable

home-directory. It uses this value for ~ lookups and for return-ing to home on

(chdir).

Scsh accesses $PATH at start-up time, colon-splits the path list, and storesthe value in the thread fluid

exec-path-list. This list is used for
exec-path and exec-path/env searches.

To access, rebind or side-effect thread-fluid cells, you must open the
thread-fluids package.

@section Terminal device control

Scsh provides a complete set of routines for manipulating terminal devices--putting them in "raw" mode, changing and querying their special characters,
modifying their I/O speeds, and so forth. The scsh interface is designed bothfor generality and portability across different Unix platforms, so you don't
have to rewrite your program each time you move to a new system. We'vealso made an effort to use reasonable, Scheme-like names for the multitudinous named constants involved, so when you are reading code, you'll haveless likelihood of getting lost in a bewildering maze of obfuscatory constants
named ICRNL, INPCK, IUCLC, and ONOCR.

This section can only lay out the basic functionality of the terminal deviceinterface. For further details, see the termios(3) man page on your system, or

consult one of the standard Unix texts.

@subsection Portability across OS variants

Terminal-control software is inescapably complex, ugly, and low-level. Unixvariants each provide their own way of controlling terminal devices, making
it difficult to provide interfaces that are portable across different Unix systems.Scsh's terminal support is based primarily upon the @acronym{POSIX} termios interface.Programs that can be written using only the @acronym{POSIX} interface are likely to bewidely portable.

81

The bulk of the documentation that follows consists of several pages worthof tables defining different named constants that enable and disable different
features of the terminal driver. Some of these flags are @acronym{POSIX}; others are takenfrom the two common branches of Unix development, SVR4 and 4.3+ Berkeley.
Scsh guarantees that the non-@acronym{POSIX} constants will be bound identifiers.

* If your OS supports a particular non-@acronym{POSIX} flag, its named constant willbe bound to the flag's value.

* If your OS doesn't support the flag, its named constant will be present,but bound to

#f.

This means that if you want to use SVR4 or Berkeley features in a program,your program can portably test the values of the flags before using them--the
flags can reliably be referenced without producing OS-dependent "unboundvariable" errors.

Finally, note that although @acronym{POSIX}, SVR4, and Berkeley cover the lion's shareof the terminal-driver functionality, each operating system inevitably has nonstandard extensions. While a particular scsh implementation may providethese extensions, they are not portable, and so are not documented here.

@subsection Miscellaneous procedures

(tty? fd/port) -! boolean procedure

Return true if the argument is a tty.

(tty-file-name fd/port) -! string procedure

The argument fd/port must be a file descriptor or port open on a tty. Re-turn the file-name of the tty.

@subsection The tty-info record type

The primary data-structure that describes a terminal's mode is a tty-inforecord, defined as follows:

82

(define-record tty-info

control-chars ; String: Magic input chars
input-flags ; Int: Input processing
output-flags ; Int: Output processing
control-flags ; Int: Serial-line control
local-flags ; Int: Line-editting UI
input-speed ; Int: Code for input speed
output-speed ; Int: Code for output speed
min ; Int: Raw-mode input policy
time) ; Int: Raw-mode input policy

The control-characters string
The control-chars field is a character string; its characters may be indexed byinteger values taken from table 3.4.

As discussed above, only the @acronym{POSIX} entries in table 3.4 are guaranteed tobe legal, integer indices. A program can reliably test the OS to see if the non@acronym{POSIX} characters are supported by checking the index constants. If the control-character function is supported by the terminal driver, then the corresponding
index will be bound to an integer; if it is not supported, the index will be boundto

#f.

To disable a given control-character function, set its correspondingentry in the

tty-info:control-chars string to the special character
disable-tty-char (and then use the (set-tty-info fd/port info) procedureto update the terminal's state).

The flag fields
The tty-info record's input-flags, output-flags, control-flags, and
local-flags fields are all bit sets represented as two's-complement integers.Their values are composed by or'ing together values taken from the named

constants listed in tables 3.5 through 3.9.

As discussed above, only the @acronym{POSIX} entries listed in these tables are guar-anteed to be legal, integer flag values. A program can reliably test the OS to see

if the non-@acronym{POSIX} flags are supported by checking the named constants. If thefeature is supported by the terminal driver, then the corresponding flag will be
bound to an integer; if it is not supported, the flag will be bound to #f.

83

The speed fields
The input-speed and output-speed fields determine the I/O rate of the ter-minal's line. The value of these fields is an integer giving the speed in bits-persecond. The following speeds are supported by @acronym{POSIX}:

0 134 600 480050 150 1200 9600

75 200 1800 19200110 300 2400 38400

Your OS may accept others; it may also allow the special symbols 'exta and
'extb.

The min and time fields
The integer min and time fields determine input blocking behaviour duringnon-canonical (raw) input; otherwise, they are ignored. See the termios(3) man
page for further details.

Be warned that @acronym{POSIX} allows the base system call's representation of the
tty-info record to share storage for the min field and the ttychar/eof elementof the control-characters string, and for the

time field and the ttychar/eolelement of the control-characters string. Many implementations in fact do this.

To stay out of trouble, set the min and time fields only if you are putting theterminal into raw mode; set the @acronym{eof} and eol control-characters only if you are
putting the terminal into canonical mode. It's ugly, but it's Unix.

@subsection Using tty-info records

(make-tty-info if of cf lf ispeed ospeed min time) -! tty-info-record procedure
(copy-tty-info tty-info-record) -! tty-info-record procedure

These procedures make it possible to create new tty-info records. Thetypical method for creating a new record is to copy one retrieved by a call

to the tty-info procedure, then modify the copy as desired. Note thatthe

make-tty-info procedure does not take a parameter to define thenew record's control characters.6 Instead, it simply returns a

tty-inforecord whose control-character string has all elements initialised to A

SCIInul. You may then install the special characters by assigning to the

string. Similarly, the control-character string in the record produced by
copy-tty-info does not share structure with the string in the record be-ing copied, so you may mutate it freely.

6 Why? Because the length of the string varies from Unix to Unix. For example, the word-erase
control character (typically control-w) is provided by most Unixes, but not part of the @acronym{POSIX} spec.

84

(tty-info [fd/port/fname]) -! tty-info-record procedure

The fd/port/fname parameter is an integer file descriptor or Scheme I/Oport opened on a terminal device, or a file-name for a terminal device;

it defaults to the current input port. This procedure returns a tty-inforecord describing the terminal's current mode.

(set-tty-info/now fd/port/fname info) -! no-value procedure
(set-tty-info/drain fd/port/fname info) -! no-value procedure
(set-tty-info/flush fd/port/fname info) -! no-value procedure

The fd/port/fname parameter is an integer file descriptor or Scheme I/Oport opened on a terminal device, or a file-name for a terminal device.

The procedure chosen determines when and how the terminal's mode isaltered:

Procedure Meaning
set-tty-info/now Make change immediately.
set-tty-info/drain Drain output, then change.
set-tty-info/flush Drain output, flush input, then change.

Oops: If I had defined these with the parameters in the reverse order,I could have made fd/port/fname optional. Too late now.

@subsection Other terminal-device procedures

(send-tty-break [fd/port/fname duration]) -! no-value procedure

The fd/port/fname parameter is an integer file descriptor or Scheme I/Oport opened on a terminal device, or a file-name for a terminal device;

it defaults to the current output port. Send a break signal to the desig-nated terminal. A break signal is a sequence of continuous zeros on the
terminal's transmission line.
The duration argument determines the length of the break signal. A zerovalue (the default) causes a break of between 0.25 and 0.5 seconds to be

sent; other values determine a period in a manner that will depend uponlocal community standards.

(drain-tty [fd/port/fname]) -! no-value procedure

The fd/port/fname parameter is an integer file descriptor or Scheme I/Oport opened on a terminal device, or a file-name for a terminal device; it

defaults to the current output port.
This procedure waits until all the output written to the terminal devicehas been transmitted to the device. If fd/port/fname is an output port with

buffered I/O enabled, then the port's buffered characters are flushed be-fore waiting for the device to drain.

85

(flush-tty/input [fd/port/fname]) -! no-value procedure
(flush-tty/output [fd/port/fname]) -! no-value procedure
(flush-tty/both [fd/port/fname]) -! no-value procedure

The fd/port/fname parameter is an integer file descriptor or SchemeI/O port opened on a terminal device, or a file-name for a terminal device; it defaults to the current input port (flush-tty/input and
flush-tty/both), or output port (flush-tty/output).

These procedures discard the unread input chars or unwritten outputchars in the tty's kernel buffers.

(start-tty-output [fd/port/fname]) -! no-value procedure
(stop-tty-output [fd/port/fname]) -! no-value procedure
(start-tty-input [fd/port/fname]) -! no-value procedure
(stop-tty-input [fd/port/fname]) -! no-value procedure

These procedures can be used to control a terminal's input and outputflow. The fd/port/fname parameter is an integer file descriptor or Scheme

I/O port opened on a terminal device, or a file-name for a terminal de-vice; it defaults to the current input or output port.

The stop-tty-output and start-tty-output procedures suspend andresume output from a terminal device. The

stop-tty-input and
start-tty-input procedures transmit the special STOP and STARTcharacters to the terminal with the intention of stopping and starting terminal input flow.

@subsection Control terminals, sessions, and terminal process groups

(open-control-tty tty-name [flags]) -! port procedure

This procedure opens terminal device tty-name as the process' control ter-minal (see the

termios man page for more information on control termi-nals). The tty-name argument is a file-name such as

/dev/ttya. The flagsargument is a value suitable as the second argument to the

open-filecall; it defaults to
open/read+write, causing the terminal to be openedfor both input and output.

The port returned is an input port if the flags permit it, otherwise an out-put port. R5RS/Scheme 48/scsh do not have input/output ports, so it's
one or the other. However, you can get both read and write ports openon a terminal by opening it read/write, taking the result input port, and
duping it to an output port with dup->outport.
This procedure guarantees to make the opened terminal the process' con-trol terminal only if the process does not have an assigned control terminal at the time of the call. If the scsh process already has a controlterminal, the results are undefined.

86

To arrange for the process to have no control terminal prior to calling thisprocedure, use the

become-session-leader procedure.

(become-session-leader) -! integer procedure

This is the C setsid() call. @acronym{POSIX} job-control has a three-level hierarchy:session/process-group/process. Every session has an associated control

terminal. This procedure places the current process into a brand newsession, and disassociates the process from any previous control terminal. You may subsequently use open-control-tty to open a new controlterminal.

It is an error to call this procedure if the current process is already aprocess-group leader. One way to guarantee this is not the case is only to
call this procedure after forking.
(tty-process-group fd/port/fname) -! integer procedure
(set-tty-process-group fd/port/fname pgrp) -! undefined procedure

This pair of procedures gets and sets the process group of a given termi-nal.

(control-tty-file-name) -! string procedure

Return the file-name of the process' control tty. On every version of Unixof which we are aware, this is just the string

"/dev/tty". However, thisprocedure uses the official Posix interface, so it is more portable than simply using a constant string.

@subsection Pseudo-terminals

Scsh implements an interface to Berkeley-style pseudo-terminals.
(fork-pty-session thunk) -! [process pty-in pty-out tty-name] procedure

This procedure gives a convenient high-level interface to pseudo-terminals. It first allocates a pty/tty pair of devices, and then forks a

child to execute procedure thunk. In the child process

* Stdio and the current I/O ports are bound to the terminal device.*

The child is placed in its own, new session (see become-sessionleader).*

The terminal device becomes the new session's controlling terminal(see

open-control-tty).*

The (error-output-port) is unbuffered.

87

The fork-pty-session procedure returns four values: the child's processobject, two ports open on the controlling pty device, and the name of the
child's corresponding terminal device.
(open-pty) -! pty-inport tty-name procedure

This procedure finds a free pty/tty pair, and opens the pty device withread/write access. It returns a port on the pty, and the name of the corresponding terminal device.
The port returned is an input port--Scheme doesn't allow input/outputports. However, you can easily use

(dup->outport pty-inport) to pro-duce a matching output port. You may wish to turn off I/O buffering for

this output port.
(pty-name->tty-name pty-name) -! tty-name procedure
(tty-name->pty-name tty-name) -! pty-name procedure

These two procedures map between corresponding terminal and pty con-troller names. For example,

(pty-name->tty-name "/dev/ptyq3") =) "/dev/ttyq3"
(tty-name->pty-name "/dev/ttyrc") =) "/dev/ptyrc"

Remark: This is rather Berkeley-specific. SVR4 ptys are rare enoughthat I've no real idea if it generalises across the Unix gap. Experts are
invited to advise. Users feel free to not worry--the predominance ofcurrent popular Unix systems use Berkeley ptys.

(make-pty-generator) -! procedure procedure

This procedure returns a generator of candidate pty names. Each time thereturned procedure is called, it produces a new candidate. Software that

wishes to search through the set of available ptys can use a pty generatorto iterate over them. After producing all the possible ptys, a generator
returns #f every time it is called. Example:

(define pg (make-pty-generator))
(pg) =) "/dev/ptyp0"
(pg) =) "/dev/ptyp1"

...

(pg) =) "/dev/ptyqe"
(pg) =) "/dev/ptyqf" (Last one)
(pg) =) #f
(pg) =) #f

...

88

Scsh C Typical char

@acronym{POSIX}
ttychar/delete-char ERASE del
ttychar/delete-line KILL ^U
ttychar/eof EOF ^D
ttychar/eol EOL
ttychar/interrupt INTR ^C
ttychar/quit QUIT ^\
ttychar/suspend SUSP ^Z
ttychar/start START ^Q
ttychar/stop STOP ^S

SVR4 and 4.3+BSD
ttychar/delayed-suspend DSUSP ^Y
ttychar/delete-word WERASE ^W
ttychar/discard DISCARD ^O
ttychar/eol2 EOL2
ttychar/literal-next LNEXT ^V
ttychar/reprint REPRINT ^R

4.3+BSD
ttychar/status STATUS ^T

Table 3.4: Indices into the tty-info record's control-chars string, and the char-acter traditionally found at each index. Only the indices for the P

OSIX entriesare guaranteed to be non#f.

89

Scsh C Meaning

@acronym{POSIX}
ttyin/check-parity INPCK Check parity.
ttyin/ignore-bad-parity-chars IGNPAR Ignore chars with parity errors.
ttyin/mark-parity-errors PARMRK Insert chars to mark parity errors.
ttyin/ignore-break IGNBRK Ignore breaks.
ttyin/interrupt-on-break BRKINT Signal on breaks.
ttyin/7bits ISTRIP Strip char to seven bits.
ttyin/cr->nl ICRNL Map carriage-return to newline.
ttyin/ignore-cr IGNCR Ignore carriage-returns.
ttyin/nl->cr INLCR Map newline to carriage-return.
ttyin/input-flow-ctl IXOFF Enable input flow control.
ttyin/output-flow-ctl IXON Enable output flow control.

SVR4 and 4.3+BSD
ttyin/xon-any IXANY Any char restarts after stop.
ttyin/beep-on-overflow IMAXBEL Ring bell when queue full.

SVR4
ttyin/lowercase IUCLC Map upper case to lower case.

Table 3.5: Input-flags. These are the named flags for the tty-info record'sinput-flags field. These flags generally control the processing of input chars.
Only the @acronym{POSIX} entries are guaranteed to be non-#f.

Scsh C Meaning

@acronym{POSIX}
ttyout/enable OPOST Enable output processing.

SVR4 and 4.3+BSD
ttyout/nl->crnl ONLCR Map nl to cr-nl.

4.3+BSD
ttyout/discard-eot ONOEOT Discard EOT chars.
ttyout/expand-tabs OXTABS7 Expand tabs.

SVR4
ttyout/cr->nl OCRNL Map cr to nl.
ttyout/nl-does-cr ONLRET Nl performs cr as well.
ttyout/no-col0-cr ONOCR No cr output in column 0.
ttyout/delay-w/fill-char OFILL Send fill char to delay.
ttyout/fill-w/del OFDEL Fill char is ASCII DEL.
ttyout/uppercase OLCUC Map lower to upper case.

Table 3.6: Output-flags. These are the named flags for the tty-info record'soutput-flags field. These flags generally control the processing of output chars.
Only the @acronym{POSIX} entries are guaranteed to be non-#f.

90

Value CommentBackspace delay
ttyout/bs-delay Bit-field mask

ttyout/bs-delay0
ttyout/bs-delay1Carriage-return delay
ttyout/cr-delay Bit-field mask

ttyout/cr-delay0
ttyout/cr-delay1
ttyout/cr-delay2
ttyout/cr-delay3Form-feed delay
ttyout/ff-delay Bit-field mask

ttyout/ff-delay0
ttyout/ff-delay1Horizontal-tab delay
ttyout/tab-delay Bit-field mask

ttyout/tab-delay0
ttyout/tab-delay1
ttyout/tab-delay2
ttyout/tab-delayx Expand tabsNewline delay
ttyout/nl-delay Bit-field mask

ttyout/nl-delay0
ttyout/nl-delay1Vertical tab delay
ttyout/vtab-delay Bit-field mask

ttyout/vtab-delay0
ttyout/vtab-delay1All
ttyout/all-delay Total bit-field mask

Table 3.7: Delay constants. These are the named flags for the tty-info record'soutput-flags field. These flags control the output delays associated with printing special characters. They are non-@acronym{POSIX}, and have non-#f values only on SVR4systems.

91

Scsh C Meaning

@acronym{POSIX}
ttyc/char-size CSIZE Character size mask
ttyc/char-size5 CS5 5 bits
ttyc/char-size6 CS6 6 bits
ttyc/char-size7 CS7 7 bits
ttyc/char-size8 CS8 8 bits
ttyc/enable-parity PARENB Generate and detect parity.
ttyc/odd-parity PARODD Odd parity.
ttyc/enable-read CREAD Enable reception of chars.
ttyc/hup-on-close HUPCL Hang up on last close.
ttyc/no-modem-sync LOCAL Ignore modem lines.
ttyc/2-stop-bits CSTOPB Send two stop bits.

4.3+BSD
ttyc/ignore-flags CIGNORE Ignore control flags.
ttyc/CTS-output-flow-ctl CCTS_OFLOW CTS flow control of output
ttyc/RTS-input-flow-ctl CRTS_IFLOW RTS flow control of input
ttyc/carrier-flow-ctl MDMBUF

Table 3.8: Control-flags. These are the named flags for the tty-info record'scontrol-flags field. These flags generally control the details of the terminal's
serial line. Only the @acronym{POSIX} entries are guaranteed to be non-#f.

92

Scsh C Meaning

@acronym{POSIX}
ttyl/canonical ICANON Canonical input processing.
ttyl/echo ECHO Enable echoing.
ttyl/echo-delete-line ECHOK Echo newline after line kill.
ttyl/echo-nl ECHONL Echo newline even if echo is off.
ttyl/visual-delete ECHOE Visually erase chars.
ttyl/enable-signals ISIG Enable ^C, ^Z signalling.
ttyl/extended IEXTEN Enable extensions.
ttyl/no-flush-on-interrupt NOFLSH Don't flush after interrupt.
ttyl/ttou-signal ITOSTOP SIGTTOU on background output.

SVR4 and 4.3+BSD
ttyl/echo-ctl ECHOCTL Echo control chars as "^X".
ttyl/flush-output FLUSHO Output is being flushed.
ttyl/hardcopy-delete ECHOPRT Visual erase for hardcopy.
ttyl/reprint-unread-chars PENDIN Retype pending input.
ttyl/visual-delete-line ECHOKE Visually erase a line-kill.

4.3+BSD
ttyl/alt-delete-word ALTWERASE Alternate word erase algorithm
ttyl/no-kernel-status NOKERNINFO No kernel status on ^T.

SVR4
ttyl/case-map XCASE Canonical case presentation

Table 3.9: Local-flags. These are the named flags for the tty-info record'slocal-flags field. These flags generally control the details of the line-editting
user interface. Only the @acronym{POSIX} entries are guaranteed to be non-#f.

@node Networking
@c    Node name, Next, Previous, Up
@chapter Networking

The Scheme Shell provides a BSD-style sockets interface. There is not an of-ficial standard for a network interface for scsh to adopt (this is the subject of
the forthcoming Posix.8 standard). However, Berkeley sockets are a de factostandard, being found on most Unix workstations and PC operating systems.

It is fairly straightforward to add higher-level network protocols such assmtp, telnet, or http on top of the the basic socket-level support scsh provides.
The Scheme Underground has also released a network library with many ofthese protocols as a companion to the current release of scsh. See this code for
examples showing the use of the sockets interface.

@section High-level interface

For convenience, and to avoid some of the messy details of the socket interface,we provide a high level socket interface. These routines attempt to make it easy
to write simple clients and servers without having to think of many of the de-tails of initiating socket connections. We welcome suggested improvements to
this interface, including better names, which right now are solely descriptionsof the procedure's action. This might be fine for people who already understand sockets, but does not help the new networking programmer.
(socket-connect protocol-family socket-type . args) -! socket procedure

socket-connect is intended for creating client applications.protocol-family is specified as either the

protocol-family/internetor
protocol-family/unix. socket-type is specified as either
socket-type/stream or socket-type/datagram. See socket for amore complete description of these terms.

94

The variable args list is meant to specify protocol family specific informa-tion. For Internet sockets, this consists of two arguments: a host name
and a port number. For Unix sockets, this consists of a pathname.
socket-connect returns a socket which can be used for input and out-put from a remote server. See

socket for a description of the socket record.

(bind-listen-accept-loop protocol-family proc arg) -! does-not-return procedure

bind-listen-accept-loop is intended for creating server applications.protocol-family is specified as either the

protocol-family/internet or
protocol-family/unix. proc is a procedure of two arguments: a socketand a socket-address. arg specifies a port number for Internet sockets or a

pathname for Unix sockets. See socket for a more complete descriptionof these terms.

proc is called with a socket and a socket address each time there is a con-nection from a client application. The socket allows communications
with the client. The socket address specifies the address of the remoteclient.

This procedure does not return, but loops indefinitely accepting connec-tions from client programs.

(bind-prepare-listen-accept-loop protocol-family prepare proc arg) -! does-not-return procedure

Same as bind-listen-accept-loop but runs the thunk prepare after bind-ing the address and before entering the loop. The typical task of the

prepare procedure is to change the user id from the superuser to someunprivileged id once the address has been bound.

@section Sockets

(create-socket protocol-family type [protocol]) -! socket procedure
(create-socket-pair type) -! [socket1 socket2] procedure
(close-socket socket) -! undefined procedure

A socket is one end of a network connection. Three specific propertiesof sockets are specified at creation time: the protocol-family, type, and

protocol.
The protocol-family specifies the protocol family to be used with thesocket. This also determines the address family of socket addresses,

which are described in more detail below. Scsh currently supports theUnix internal protocols and the Internet protocols using the following
constants:

95

protocol-family/unspecified
protocol-family/unix
protocol-family/internet

The type specifies the style of communication. Examples that your oper-ating system probably provides are stream and datagram sockets. Others
maybe available depending on your system. Typical values are:

socket-type/stream
socket-type/datagram
socket-type/raw

The protocol specifies a particular protocol to use within a protocol familyand type. Usually only one choice exists, but it's probably safest to set this
explicitly. See the protocol database routines for information on lookingup protocol constants.

New sockets are typically created with create-socket. However,
create-socket-pair can also be used to create a pair of connected sock-ets in the

protocol-family/unix protocol-family. The value of a re-turned socket is a socket record, defined to have the following structure:

(define-record socket

family ; protocol family
inport ; input-port
outport) ; output-port

The family specifies the protocol family of the socket. The inport and
outport fields are ports that can be used for input and output, respec-tively. For a stream socket, they are only usable after a connection has

been established via connect-socket or accept-connection. For a data-gram socket, outport can be immediately using

send-message, and inportcan be used after
bind has created a local address.

close-socket provides a convenient way to close a socket's port. It ispreferred to explicitly closing the inport and outport because using

closeon sockets is not currently portable across operating systems.

(port->socket port protocol-family) -! socket procedure

This procedure turns port into a socket object. The port's underly-ing file descriptor must be a socket with protocol family protocol-family.

port->socket applies dup->inport and dup->outport to port to createthe ports of the socket object.

port->socket comes in handy for writing servers which run as childrenof

inetd: after receiving a connection inetd creates a socket and passesit as standard input to its child.

96

@section Socket addresses

The format of a socket-address depends on the address family of the socket.Address-family-specific routines are provided to convert protocol-specific addresses to socket addresses. The value returned by these routines is a socket-address record, defined to have the following visible structure:

(define-record socket-address

family) ; address family

The family is one of the following constants:

address-family/unspecified
address-family/unix
address-family/internet

(unix-address->socket-address pathname) -! socket-address procedure

unix-address->socket-address returns a socket-address based on thestring pathname. There is a system dependent limit on the length of

pathname.
(internet-address->socket-address host-address service-port) -! socket-address procedure

internet-address->socket-address returns a socket-address based onan integer host-address and an integer service-port. Besides being a 32-bit

host address, an Internet host address can also be one of the followingconstants:

internet-address/any
internet-address/loopback
internet-address/broadcast

The use of internet-address/any is described below in bind-socket.
internet-address/loopback is an address that always specifies the localmachine.

internet-address/broadcast is used for network broadcastcommunications.

For information on obtaining a host's address, see the host-info func-tion.

(socket-address->unix-address socket-address) -! pathname procedure
(socket-address->internet-address socket-address) -! [host-address service-port] procedure

The routines socket-address->internet-address and
socket-address->unix-address return the address-family-specificaddresses. Be aware that most implementations don't correctly return anything more than an empty string for addresses in the Unixaddress-family.

97

@section Socket primitives

The procedures in this section are presented in the order in which a typicalprogram will use them. Consult a text on network systems programming for
more information on sockets.1 The last two tutorials are freely available as partof BSD. In the absence of these, your Unix manual pages for socket might be a
good starting point for information.
(connect-socket socket socket-address) -! undefined procedure

connect-socket sets up a connection from a socket to a remotesocket-address. A connection has different meanings depending on the

socket type. A stream socket must be connected before use. A datagramsocket can be connected multiple times, but need not be connected at all
if the remote address is specified with each send-message, described be-low. Also, datagram sockets may be disassociated from a remote address
by connecting to a null remote address.
(connect-socket-no-wait socket socket-address) -! boolean procedure
(connect-socket-successful? socket) -! boolean procedure

Just like connect-socket, connect-socket-no-wait sets up a connec-tion from a socket to a remote socket-address. Unlike

connect-socket,
connect-socket-no-wait does not block if it cannot establish the con-nection immediately. Instead it will return

#f at once. In this case a sub-sequent
select on the output port of the socket will report the outputport as ready as soon as the operation system has established the connection or as soon as setting up the connection led to an error. Afterwards,the procedure

connect-socket-successful? can be used to test whetherthe connection has been established successfully or not.

(bind-socket socket socket-address) -! undefined procedure

bind-socket assigns a certain local socket-address to a socket. Binding asocket reserves the local address. To receive connections after binding

the socket, use listen-socket for stream sockets and receive-messagefor datagram sockets.

Binding an Internet socket with a host address of internet-address/anyindicates that the caller does not care to specify from which local network
1 Some recommended ones are:

* "Unix Network Programming" by W. Richard Stevens*

"An Introductory 4.3BSD Interprocess Communication Tutorial." (reprinted in UNIX Pro-grammer's Supplementary Documents Volume 1, PS1:7)

* "An Advanced 4.3BSD Interprocess Communication Tutorial." (reprinted in UNIX Pro-grammer's Supplementary Documents Volume 1, PS1:8)

98

interface connections are received. Binding an Internet socket with a ser-vice port number of zero indicates that the caller has no preference as to
the port number assigned.
Binding a socket in the Unix address family creates a socket special filein the file system that must be deleted before the address can be reused.

See delete-file.
(listen-socket socket backlog) -! undefined procedure

listen-socket allows a stream socket to start receiving connections, al-lowing a queue of up to backlog connection requests. Queued connections

may be accepted by accept-connection.
(accept-connection socket) -! [new-socket socket-address] procedure

accept-connection receives a connection on a socket, returning a newsocket that can be used for this connection and the remote socket address

associated with the connection.
(socket-local-address socket) -! socket-address procedure
(socket-remote-address socket) -! socket-address procedure

Sockets can be associated with a local address or a remote addressor both.

socket-local-address returns the local socket-address recordassociated with socket.

socket-remote-address returns the remotesocket-address record associated with socket.

(shutdown-socket socket how-to) -! undefined procedure

shutdown-socket shuts down part of a full-duplex socket. The methodof shutting done is specified by the how-to argument, one of:

shutdown/receives
shutdown/sends
shutdown/sends+receives

@section Performing input and output on sockets

(receive-message socket length [flags]) -! [string-or-#f socket-address] procedure
(receive-message! socket string [start] [end] [flags]) -! [count-or-#f socket-address] procedure
(receive-message/partial socket length [flags]) -! [string-or-#f socket-address] procedure
(receive-message!/partial socket string [start] [end] [flags]) -! [count-or-#f socket-address] procedure

(send-message socket string [start] [end] [flags] [socket-address]) -! undefined procedure
(send-message/partial socket string [start] [end] [flags] [socket-address]) -! count procedure

For most uses, standard input and output routines such as read-stringand

write-string should suffice. However, in some cases an extended

99

interface is required. The receive-message and send-message calls par-allel the

read-string and write-string calls with a similar namingscheme.

One additional feature of these routines is that receive-message re-turns the remote socket-address and send-message takes an optional remote
socket-address. This allows a program to know the source of inputfrom a datagram socket and to use a datagram socket for output without
first connecting it.
All of these procedures take an optional flags field. This argument is aninteger bit-mask, composed by or'ing together the following constants:

message/out-of-band
message/peek
message/dont-route

See read-string and write-string for a more detailed description ofthe arguments and return values.

@section Socket options

(socket-option socket level option) -! value procedure
(set-socket-option socket level option value) -! undefined procedure

socket-option and set-socket-option allow the inspection and mod-ification, respectively, of several options available on sockets. The level

argument specifies what protocol level is to be examined or affected. Alevel of

level/socket specifies the highest possible level that is avail-able on all socket types. A specific protocol number can also be used as

provided by protocol-info, described below.
There are several different classes of socket options. The first class con-sists of boolean options which can be either true or false. Examples of

this option type are:

socket/debug
socket/accept-connect
socket/reuse-address
socket/keep-alive
socket/dont-route
socket/broadcast
socket/use-loop-back
socket/oob-inline
socket/use-privileged
socket/cant-signal
tcp/no-delay

100

Value options are another category of socket options. Options of this typeare an integer value. Examples of this option type are:

socket/send-buffer
socket/receive-buffer
socket/send-low-water
socket/receive-low-water
socket/error
socket/type
ip/time-to-live
tcp/max-segment

A third option type specifies how long for data to linger after a socket hasbeen closed. There is only one option of this type:

socket/linger. It isset with either
#fto disable it or an integer number of seconds to lingerand returns a value of the same type upon inspection.

The fourth and final option type of this time is a timeout option.There are two examples of this option type:

socket/send-timeout and
socket/receive-timeout. These are set with a real number of microsec-onds resolution and returns a value of the same type upon inspection.

@section Database-information entries

(host-info name-or-socket-address) -! host-info procedure
(network-info name-or-socket-address) -! network-info or #f procedure
(service-info name-or-number [protocol-name]) -! service-info or #f procedure
(protocol-info name-or-number) -! protocol-info or #f procedure

host-info allows a program to look up a host entry based on either itsstring name or socket-address. The value returned by this routine is a hostinfo record, defined to have the following structure:

(define-record host-info

name ; Host name
aliases ; Alternative names
addresses) ; Host addresses

host-info could fail and raise an error for one of the following reasons:

herror/host-not-found
herror/try-again
herror/no-recovery
herror/no-data
herror/no-address

101

network-info allows a program to look up a network entry based oneither its string name or socket-address. The value returned by this routine
is a network-info record, defined to have the following structure:

(define-record network-info

name ; Network name
aliases ; Alternative names
net) ; Network number

service-info allows a program to look up a service entry based on ei-ther its string name or integer port. The value returned by this routine is
a service-info record, defined to have the following structure:

(define-record service-info

name ; Service name
aliases ; Alternative names
port ; Port number
protocol) ; Protocol name

protocol-info allows a program to look up a protocol entry based on ei-ther its string name or integer number. The value returned by this routine
is a protocol-info record, defined to have the following structure:

(define-record protocol-info

name ; Protocol name
aliases ; Alternative names
number) ; Protocol number)

network-info, service-info and protocol-info return #fif the speci-fied entity was not found.

102

@node Strings and characters
@c    Node name, Next, Previous, Up
@chapter Strings and characters

Strings are the basic communication medium for Unix processes, so a Unix pro-gramming environment must have reasonable facilities for manipulating them.
Scsh provides a powerful set of procedures for processing strings and charac-ters. Besides the the facilities described in this chapter, scsh also provides

* Regular expressions (chapter 6)A complete regular-expression system.

* Field parsing, delimited record I/O and the awk loop (chapter 8)These procedures let you read in chunks of text delimited by selected

characters, and parse each record into fields based on regular expressions(for example, splitting a string at every occurrence of colon or whitespace). The awk form allows you to loop over streams of these recordsin a convenient way.

* The SRFI-13 string librariesThis pair of libraries contains procedures that create, fold, iterate

over, search, compare, assemble, cut, hash, case-map, and other-wise manipulate strings. They are provided by the

string-lib and
string-lib-internals packages, and are also available in the default
scsh package.

More documentation on these procedures can be found at URLs

http://srfi.schemers.org/srfi-13/srfi-13.html
http://srfi.schemers.org/srfi-13/srfi-13.txt

* The SRFI-14 character-set libraryThis library provides a set-of-characters abstraction, which is frequently

useful when searching, parsing, filtering or otherwise operating on

103

strings and character data. The SRFI is provided by the char-set-libpackage; it's bindings are also available in the default

scsh package.

More documentation on this library can be found at URLs

http://srfi.schemers.org/srfi-14/srfi-14.html
http://srfi.schemers.org/srfi-14/srfi-14.txt

@section Manipulating file names

These procedures do not access the file-system at all; they merely operate onfile-name strings. Much of this structure is patterned after the gnu emacs design. Perhaps a more sophisticated system would be better, something likethe pathname abstractions of COMMON LISP or MIT Scheme. However, beingUnix-specific, we can be a little less general.

@subsection Terminology

These procedures carefully adhere to the @acronym{POSIX} standard for file-name reso-lution, which occasionally entails some slightly odd things. This section will
describe these rules, and give some basic terminology.

A file-name is either the file-system root ("/"), or a series of slash-terminateddirectory components, followed by a a file component. Root is the only filename that may end in slash. Some examples:

File name Dir components File component
src/des/main.c ("src" "des") "main.c"
/src/des/main.c ("" "src" "des") "main.c"
main.c () "main.c"

Note that the relative filename src/des/main.c and the absolute filename
/src/des/main.c are distinguished by the presence of the root component ""in the absolute path.

Multiple embedded slashes within a path have the same meaning as a sin-gle slash. More than two leading slashes at the beginning of a path have the
same meaning as a single leading slash--they indicate that the file-name is anabsolute one, with the path leading from root. However, P

OSIX permits the OSto give special meaning to two leading slashes. For this reason, the routines in

this section do not simplify two leading slashes to a single slash.

A file-name in directory form is either a file-name terminated by a slash, e.g.,"
/src/des/", or the empty string, "". The empty string corresponds to the cur-rent working directory, whose file-name is dot ("

."). Working backwards fromthe append-a-slash rule, we extend the syntax of P

OSIX file-names to define the

104

empty string to be a file-name form of the root directory "/". (However, "/" isalso acceptable as a file-name form for root.) So the empty string has two interpretations: as a file-name form, it is the file-system root; as a directory form,it is the current working directory. Slash is also an ambiguous form:

/ is botha directory-form and a file-name form.

The directory form of a file-name is very rarely used. Almost allof the procedures in scsh name directories by giving their file-name
form (without the trailing slash), not their directory form. So, you say"

/usr/include", and ".", not "/usr/include/" and "". The sole exceptionsare

file-name-as-directory and directory-as-file-name, whose jobs areto convert back-and-forth between these forms, and

file-name-directory,whose job it is to split out the directory portion of a file-name. However, most

procedures that expect a directory argument will coerce a file-name in direc-tory form to file-name form if it does not have a trailing slash. Bear in mind
that the ambiguous case, empty string, will be interpreted in file-name form,i.e., as root.

@subsection Procedures

(file-name-directory? fname) -! boolean procedure
(file-name-non-directory? fname) -! boolean procedure

These predicates return true if the string is in directory form, or file-nameform (see the above discussion of these two forms). Note that they both

return true on the ambiguous case of empty string, which is both a direc-tory (current working directory), and a file name (the file-system root).

File name ...-directory? ...-non-directory?
"src/des" #f #t
"src/des/" #t #f
"/" #t #f
"." #f #t
"" #t #t

(file-name-as-directory fname) -! string procedure

Convert a file-name to directory form. Basically, add a trailing slash ifneeded:

(file-name-as-directory "src/des") =) "src/des/"
(file-name-as-directory "src/des/") =) "src/des/"

., /, and "" are special:
(file-name-as-directory ".") =) ""
(file-name-as-directory "/") =) "/"
(file-name-as-directory "") =) "/"

105

(directory-as-file-name fname) -! string procedure

Convert a directory to a simple file-name. Basically, kill a trailing slash ifone is present:

(directory-as-file-name "foo/bar/") =) "foo/bar"
/ and "" are special:
(directory-as-file-name "/") =) "/"
(directory-as-file-name "") =) "." (i.e., the cwd)

(file-name-absolute? fname) -! boolean procedure

Does fname begin with a root or ~ component? (Recognising ~ as a home-directory specification is an extension of P

OSIX rules.)

(file-name-absolute? "/usr/shivers") =) #t
(file-name-absolute? "src/des") =) #f
(file-name-absolute? "~/src/des") =) #t

Non-obvious case:
(file-name-absolute? "") =) #t (i.e., root)

(file-name-directory fname) -! string or false procedure

Return the directory component of fname in directory form. If the file-name is already in directory form, return it as-is.

(file-name-directory "/usr/bdc") =) "/usr/"
(file-name-directory "/usr/bdc/") =) "/usr/bdc/"
(file-name-directory "bdc/.login") =) "bdc/"
(file-name-directory "main.c") =) ""

Root has no directory component:
(file-name-directory "/") =) ""
(file-name-directory "") =) ""

(file-name-nondirectory fname) -! string procedure

Return non-directory component of fname.

106

(file-name-nondirectory "/usr/ian") =) "ian"
(file-name-nondirectory "/usr/ian/") =) ""
(file-name-nondirectory "ian/.login") =) ".login"
(file-name-nondirectory "main.c") =) "main.c"
(file-name-nondirectory "") =) ""
(file-name-nondirectory "/") =) "/"

(split-file-name fname) -! string list procedure

Split a file-name into its components.

(split-file-name "src/des/main.c")=)

("src" "des" "main.c")

(split-file-name "/src/des/main.c")=)

("" "src" "des" "main.c")

(split-file-name "main.c")=)

("main.c")

(split-file-name "/")=)

("")

(path-list->file-name path-list [dir]) -! string procedure

Inverse of split-file-name.

(path-list->file-name '("src" "des" "main.c"))=)

"src/des/main.c"
(path-list->file-name '("" "src" "des" "main.c"))=)

"/src/des/main.c"

Optional dir arg anchors relative path-lists:
(path-list->file-name '("src" "des" "main.c")

"/usr/shivers")=)
"/usr/shivers/src/des/main.c"

The optional dir argument is usefully (cwd).

(file-name-extension fname) -! string procedure

Return the file-name's extension.

(file-name-extension "main.c") =) ".c"
(file-name-extension "main.c.old") =) ".old"
(file-name-extension "/usr/shivers") =) ""

107

Weird cases:
(file-name-extension "foo.") =) "."
(file-name-extension "foo..") =) "."

Dot files are not extensions:
(file-name-extension "/usr/shivers/.login") =) ""

(file-name-sans-extension fname) -! string procedure

Return everything but the extension.

(file-name-sans-extension "main.c") =) "main"
(file-name-sans-extension "main.c.old") =) "main.c""
(file-name-sans-extension "/usr/shivers")=)

"/usr/shivers"

Weird cases:
(file-name-sans-extension "foo.") =) "foo"
(file-name-sans-extension "foo..") =) "foo."

Dot files are not extensions:
(file-name-sans-extension "/usr/shivers/.login")=)

"/usr/shivers/.login

Note that appending the results of file-name-extension and filename-sans-extension in all cases produces the original file-name.

(parse-file-name fname) -! [dir name extension] procedure

Let f be (file-name-nondirectory fname). This function returns thethree values:

* (file-name-directory fname)*

(file-name-sans-extension f))*
(file-name-extension f)

The inverse of parse-file-name, in all cases, is string-append. Theboundary case of

/ was chosen to preserve this inverse.

(replace-extension fname ext) -! string procedure

This procedure replaces fname's extension with ext. It is exactly equiva-lent to

(string-append (file-name-sans-extension fname) ext)

108

(simplify-file-name fname) -! string procedure

Removes leading and internal occurrences of dot. A trailing dot is leftalone, as the parent could be a symlink. Removes internal and trailing

double-slashes. A leading double-slash is left alone, in accordance withP

OSIX. However, triple and more leading slashes are reduced to a singleslash, in accordance with P

OSIX. Double-dots (parent directory) are leftalone, in case they come after symlinks or appear in a

/../machine/..."super-root" form (which P
OSIX permits).

(resolve-file-name fname [dir]) -! string procedure*

Do ~ expansion.*
If dir is given, convert a relative file-name to an absolute file-name,relative to directory dir.

(expand-file-name fname [dir]) -! string procedure

Resolve and simplify the file-name.

(absolute-file-name fname [dir]) -! string procedure

Convert file-name fname into an absolute file name, relative to directorydir, which defaults to the current working directory. The file name is

simplified before being returned.
This procedure does not treat a leading tilde character specially.

(home-dir [user]) -! string procedure

home-dir returns user's home directory. User defaults to the current user.

(home-dir) =) "/user1/lecturer/shivers"
(home-dir "ctkwan") =) "/user0/research/ctkwan"

(home-file [user] fname) -! string procedure

Returns file-name fname relative to user's home directory; user defaults tothe current user.

(home-file "man") =) "/usr/shivers/man"
(home-file "fcmlau" "man") =) "/usr/fcmlau/man"

The general substitute-env-vars string procedure, defined in the previ-ous section, is also frequently useful for expanding file-names.

109

@section Other string manipulation facilities

(substitute-env-vars fname) -! string procedure

Replace occurrences of environment variables with their values. An en-vironment variable is denoted by a dollar sign followed by alphanumeric

chars and underscores, or is surrounded by braces.

(substitute-env-vars "$USER/.login")=)

"shivers/.login"
(substitute-env-vars "${USER}_log") =) "shivers_log"

@section ASCII encoding

(char->ascii character) -! integer procedure
(ascii->char integer) -! character procedure

These are identical to char->integer and integer->char except thatthey use the A

SCII encoding.

@section Character predicates

(char-letter? character) -! boolean procedure
(char-lower-case? character) -! boolean procedure
(char-upper-case? character) -! boolean procedure
(char-title-case? character) -! boolean procedure
(char-digit? character) -! boolean procedure
(char-letter+digit? character) -! boolean procedure
(char-graphic? character) -! boolean procedure
(char-printing? character) -! boolean procedure
(char-whitespace? character) -! boolean procedure
(char-blank? character) -! boolean procedure
(char-iso-control? character) -! boolean procedure
(char-punctuation? character) -! boolean procedure
(char-hex-digit? character) -! boolean procedure
(char-ascii? character) -! boolean procedure

Each of these predicates tests for membership in one of the standard char-acter sets provided by the SRFI-14 character-set library. Additionally, the

following redundant bindings are provided for R5RS compatibility:

110

R5RS name scsh definition
char-alphabetic? char-letter+digit?
char-numeric? char-digit?
char-alphanumeric? char-letter+digit?

@section Deprecated character-set procedures

The SRFI-13 character-set library grew out of an earlier library developed forscsh. However, the SRFI standardisation process introduced incompatibilities
with the original scsh bindings. The current version of scsh provides the library
obsolete-char-set-lib, which contains the old bindings found in previousreleases of scsh. The following table lists the members of this library, along

with the equivalent SRFI-13 binding. This obsolete library is deprecated andnot open by default in the standard

scsh environment; new code should usethe SRFI-13 bindings.

Old obsolete-char-set-lib SRFI-13 char-set-lib
char-set-members char-set->list
chars->char-set list->char-set
ascii-range->char-set ucs-range->char-set (not exact)
predicate->char-set char-set-filter (not exact)
char-set-every? char-set-every
char-set-any? char-set-any

char-set-invert char-set-complement
char-set-invert! char-set-complement!

char-set:alphabetic char-set:letter
char-set:numeric char-set:digit
char-set:alphanumeric char-set:letter+digit
char-set:control char-set:iso-control

Note also that the ->char-set procedure no longer handles a predicate argument.

@node Pattern-matching strings with regular expressions
@c    Node name, Next, Previous, Up
@chapter Pattern-matching strings with regular expressions

Scsh provides a rich facility for matching regular-expression patterns in strings.The system is composed of several pieces:

* An s-expression notation for writing down general regular expressions.In most systems, regexp patterns are encoded as string literals, such as

"g(oo|ee)se". In scsh, they are written using s-expressions, such as (:
"g" (| "oo" "ee") "se"), and are called sre's. The sre notation has sev-eral advantages over the traditional string-based notation. It's more expressive, can be commented, and can be indented to expose the structureof the form.

* An abstract data type (ADT) representation for regexp values. Traditionalregular-expression systems compute regular expressions from run-time

values using strings. This can be awkward. Scsh, instead, provides aseparate data type for regexps, with a set of basic constructor and accessor functions; regular expressions can be dynamically computed andmanipulated using these functions.

* Some tools that work on the regexp ADT: case-sensitve to case-insensitiveregexp transform, a regexp simplifier, and so forth.

* Parsers and unparsers that can convert between external representationsand the regexp ADT. The supported external representations are

- Posix strings
- S-expression notation (that is, sre's)

112

Being able to convert regexps to Posix strings allows implementations toimplement regexp matching using standard Posix C-based engines.

* Macro support for the s-expression notation. The rx macro provides anew special form that allows you to embed regexps in the s-expression

notation within a Scheme program. Evaluating the macro form producesa regexp ADT value which can be used by Scheme pattern-matching procedures and other regexp consumers.

* Pattern-matching and searching procedures. Spencer's Posix regexp en-gine is linked in to the runtime; the regexp code uses this engine to provide text matching.

The regexp language supported is a complete superset of Posix functional-ity, providing:

* sequencing and choice (|)

* repetition (*, +, ?, {m,n})

* character classes (e.g., [aeiou]) and wildcard (.)

* beginning/end of string anchors (^, $)

* case-sensitivity control

* submatch-marking

@section Summary SRE syntax
The following figures give a summary of the SRE syntax; the next section is afriendlier tutorial introduction.

113

string Literal match--interpreted relative to the currentcase-sensitivity lexical context (default is casesensitive)
(string1 string2 ...) Set of chars, e.g., ("abc" "XYZ"). Interpretedrelative to the current case-sensitivity lexical

context.
(* sre ...) 0 or more matches
(+ sre ...) 1 or more matches
(? sre ...) 0 or 1 matches
(= n sre ...) n matches
(>= n sre ...) n or more matches
(** n m sre ...) n to m matchesN and m are Scheme expressions producing non-negative integers.

M may also be #f, meaning "infinity."
(| sre ...) Choice (or is R5RS symbol;
(or sre ...) | is not specified by R5RS.)

(: sre ...) Sequence (seq is legal
(seq sre ...) Common Lisp symbol)

(submatch sre ...) Numbered submatch
(dsm pre post sre ...) Deleted submatchesPre and post are numerals.

(uncase sre ...) Case-folded match
(w/case sre ...) Introduce a lexical case-sensitivity
(w/nocase sre ...) context.

,@exp Dynamically computed regexp
,exp Same as ,@exp, but no submatch infoExp must produce a character, string, char-set, or regexp.

bos eos Beginning/end of string
bol eol Beginning/end of line

Figure 6.1: SRE syntax summary (part 1)

114

(posix-string string) Escape for Posix string notation
char Singleton char setclass-name alphanumeric, whitespace, etc.

These two forms are interpreted subject to the lexical case-sensitivitycontext.

(~ cset-sre ...) Complement-of-union ([^...])
(- cset-sre ...) Difference
(& cset-sre ...) Intersection

(/ range-spec ...) Character range--interpreted subject to the lexi-cal case-sensitivy context

Figure 6.2: SRE syntax summary (part 2)

class-name ::= any

| nonl
| lower-case | lower
| upper-case | upper
| alphabetic | alpha
| numeric | digit | num
| alphanumeric | alnum
| punctuation | punct
| graphic | graph
| whitespace | space | white
| printing | print
| control | cntrl
| hex-digit | xdigit | hex
| ascii

range-spec ::= string | charThe chars are taken in pairs to form inclusive ranges.

Figure 6.3: SRE character-class names and range specs.

115

<cset-sre> ::= (~ <cset-sre> ...) Set complement-of-union

| (- <cset-sre> ...) Set difference
| (& <cset-sre> ...) Intersection
| (| <cset-sre> ...) Set union
| (/ <range-spec> ...) Range

| (<string>) Constant set
| <char> Singleton constant set
| <string> For 1-char string "c"

| <class-name> Constant set
| ,<exp> <exp> evals to a char-set,
| ,@<exp> char, single-char string,

or re-char-set regexp.

| (uncase <cset-sre>) Case-folding
| (w/case <cset-sre>)
| (w/nocase <cset-sre>)

Figure 6.4: applied to SRE's that specify character sets. These are the "type-checking" rules for character-set SRE's.

116

@section Examples

(- alpha ("aeiouAEIOU")) ; Various forms of
(- alpha ("aeiou") ("AEIOU")) ; non-vowel letter
(w/nocase (- alpha ("aeiou")))
(- (/"azAZ") ("aeiouAEIOU"))
(w/nocase (- (/"az") ("aeiou")))

;;; Upper-case letter, lower-case vowel, or digit
(| upper ("aeiou") digit)
(| (/"AZ09") ("aeiou"))

;;; Not an SRE, but Scheme code containing some embedded SREs.
(let* ((ws (rx (+ whitespace))) ; Seq of whitespace

(date (rx (: (| "Jan" "Feb" "Mar" ...) ; A month/day date.

,ws
(| ("123456789") ; 1-9

(: ("12") digit) ; 10-29
"30" "31"))))) ; 30-31

;; Now we can use DATE several times:
(rx ... ,date ... (* ... ,date ...)

... .... ,date))

;;; More Scheme code
(define (csl re) ; A comma-separated list of RE's is

(rx (| "" ; either zero of them (empty string), or

(: ,re ; one RE, followed by

(* ", " ,re))))) ; Zero or more comma-space-RE matches.

(csl (rx (| "John" "Paul" "George" "Ringo")))

@section A short tutorial

S-expression regexps are called "SRE"s. Keep in mind that they are not Schemeexpressions; they are another, separate notation that is expressed using the underlying framework of s-expression list structure: lists, symbols, etc. SRE'scan be embedded inside of Scheme expressions using special forms that extend
Scheme's syntax (such as the rx macro); there are places in the SRE grammarwhere one may place a Scheme expression. In these ways, SRE's and Scheme
expressions can be intertwined. But this isn't fundamental; SRE's may be usedin a completely Scheme-independent context. By simply restricting the nota117

tion to eliminate two special Scheme-embedding forms, they can be a com-pletely independent notation.
Constant strings The simplest SRE is a string, denoting a constant regexp.For example, the SRE

"Spot"
matches only the string <<capital-S, little-p, little-o, little-t>>. There is no in-terpretation of the characters in the string at all--the SRE

".*["
matches the string <<period, asterisk, open-bracket>>.

Simple character sets To specify a set of characters, write a list whose singleelement is a string containing the set's elements. So the SRE

("aeiou")
only matches a vowel. One way to think of this, notationally, is that the setbrackets are

(" and ").

Wild card Another simple SRE is the symbol any, which matches any singlecharacter--including newline, but excluding ASCII NUL.

Sequences We can form sequences of SRE's with the SRE (: sre ...). So theSRE

(: "x" any "z")
matches any three-character string starting with "x" and ending with "z". Aswe'll see shortly, many SRE forms have bodies that are implicit sequences of
other SRE's, analogous to the manner in which the body of a Scheme lambdaor

let expression is an implicit begin sequence. The regexp (seq sre ...) iscompletely equivalent to

(: sre ...); it's included in order to have a syntaxthat doesn't require
: to be a legal symbol 1

1That is, for use within s-expression syntax frameworks that, unlike R5RS, don't allow for : as
a legal symbol. A Common Lisp embedding of SREs, for example, would need to use seq insteadof

:.

118

Choices The SRE (| sre ...) is a regexp that matches anything any of thesre regexps match. So the regular expression

(| "sasha" "Pete")
matches either the string "sasha" or the string "Pete". The regexp

(| ("aeiou") ("0123456789"))
is the same as

("aeiou0123456789")
The regexp (or sre ...) is completely equivalent to (| sre ...); it's includedin order to have a syntax that doesn't require

| to be a legal symbol.

Repetition There are several SRE forms that match multiple occurences of aregular expression. For example, the SRE

(* sre ...) matches zero or moreoccurences of the sequence
(: sre ...). Here is the complete list of SRE repe-tition forms:

SRE means at least no more than
(* sre ...) zero-or-more 0 infinity
(+ sre ...) one-or-more 1 infinity
(? sre ...) zero-or-one 0 1
(= from sre ...) exactly-n from from
(>= from sre ...) n-or-more from infinity
(** from to sre ...) n-to-m from to

A from field is a Scheme expression that produces an integer. A to field is aScheme expression that produces either an integer, or false, meaning infinity.

While it is illegal for the from or to fields to be negative, it is allowed forfrom to be greater than to in a

** form--this simply produces a regexp that willnever match anything.

As an example, we can describe the names of car/cdr access functions("car", "cdr", "cadr", "cdar", "caar" , "cddr", "caaadr", etc.) with either of
the SREs

(: "c" (+ (| "a" "d")) "r")
(: "c" (+ ("ad")) "r")

We can limit the a/d chains to 4 characters or less with the SRE

(: "c" (** 1 4 ("ad")) "r")

119

Some boundary cases:

(** 5 2 "foo") ; Will never match
(** 0 0 "foo") ; Matches the empty string

Character classes There is a special set of SRE's that form "characterclasses"--basically, a regexp that matches one character from some specified
set of characters. There are operators to take the intersection, union, comple-ment, and difference of character classes to produce a new character class. (Except for union, these capabilities are not provided for general regexps as theyare computationally intractable in the general case.)

A single character is the simplest character class: #\x is a character classthat matches only the character "x". A string that has only one letter is also a
character class: "x" is the same SRE as #\x.

The character-set notation (string) we've seen is a primitive character class,as is the wildcard

any. When arguments to the choice operator, |, are all char-acter classes, then the choice form is itself a character-class. So these SREs are

all character-classes:

("aeiou")
(| #\a #\e #\i #\o #\u)
(| ("aeiou") ("1234567890"))

However, these SRE's are not character-classes:

"aeiou"
(| "foo" #\x)

The (~ cset-sre ...) char class matches one character not in the specifiedclasses:

(~ ("0248") ("1359"))
matches any character that is not a digit.

More compactly, we can use the / operator to specify character sets by giv-ing the endpoints of contiguous ranges, where the endpoints are specified by a

sequence of strings and characters. For example, any of these char classes

(/ #\A #\Z #\a #\z #\0 #\9)
(/ "AZ" #\a #\z "09")
(/ "AZ" #\a "z09")
(/"AZaz09")

120

matches a letter or a digit. The range endpoints are taken in pairs to forminclusive ranges of characters. Note that the exact set of characters included
in a range is dependent on the underlying implementation's character type, soranges may not be portable across different implementations.

There is a wide selection of predefined, named character classes that maybe used. One such SRE is the wildcard

any. nonl is a character class matchinganything but newline; it is equivalent to

(~ #\newline)
and is useful as a wildcard in line-oriented matching.

There are also predefined named char classes for the standard Posix andGnu character classes:

scsh name Posix/ctype Alternate name Comment
lower-case lower
upper-case upper
alphabetic alpha
numeric digit num
alphanumeric alnum alphanum
punctuation punct
graphic graph
blank (Gnu extension)
whitespace space white "space" is deprecated.
printing print
control cntrl
hex-digit xdigit hex
ascii (Gnu extension)

See the scsh character-set documentation or the Posix isalpha(3) man page forthe exact definitions of these sets.

You can use either the long scsh name or the shorter Posix and alternatenames to refer to these char classes. The standard Posix name "

space" is pro-vided, but deprecated, since it is ambiguous. It means "whitespace," the set

of whitespace characters, not the singleton set of the #\space character. If youwant a short name for the set of whitespace characters, use the char-class name
"white" instead.

Char classes may be intersected with the operator (& cset-sre ...), and set-difference can be performed with

(- cset-sre ...). These operators are partic-ularly useful when you want to specify a set by negation with respect to a limited

universe. For example, the set of all non-vowel letters is

(- alpha ("aeiou") ("AEIOU"))
whereas writing a simple complement

121

(~ ("aeiouAEIOU"))
gives a char class that will match any non-vowel--including punctuation, dig-its, white space, control characters, and A

SCII nul.

We can compute a char class by writing the SRE

,cset-exp
where cset-exp is a Scheme expression producing a value that can be coercedto a character set: a character set, character, one-character string, or char-class
regexp value. This regexp matches one character from the set.

The char-class SRE ,@cset-exp is entirely equivalent to ,cset-exp whencset-exp produces a character set (but see below for the more general non-charclass context, where there is a distinction between ,exp and ,@exp.

As an example of character-class SREs, an SRE that matches a lower-casevowel, upper-case letter, or digit is

(| ("aeiou") (/"AZ09"))
or, equivalently

(| ("aeiou") upper-case numeric)
Boundary cases: the empty-complement char class

(~)
matches any character; it is equivalent to any. The empty-union char class

(|)
never matches at all. This is rarely useful for human-written regexps, but maybe of occasional utility in machine-generated regexps, perhaps produced by
macros.

The rules for determining if an SRE is a simple, char-class SRE or a morecomplex SRE form a little "type system" for SRE's. See the summary section

preceding this one for a complete listing of these rules.{

Note There is no way to include the ASCII NUL character in a characterset or search for it in any other way using regular expression. This is because

the @acronym{POSIX} regexp facility is based on the C language which uses ASCII NULto terminate strings.}

122

Case sensitivity There are three forms that control case sensitivity:

(uncase sre ...)
(w/case sre ...)
(w/nocase sre ...)

uncase is a regexp operator producing a regexp that matches any case per-mutation of any string that matches

(: sre ...). For example, the regexp

(uncase "foo")
matches the strings "foo", "foO", "fOo", "fOO", "Foo", . . .

Expressions in SRE notation are interpreted in a lexical case-sensitivy con-text. The forms

w/case and w/nocase are the scoping operators for this con-text, which controls how constant strings and char-class forms are interpreted

in their bodies. So, for example, the regexp

(w/nocase "abc"

(* "FOO" (w/case "Bar"))
("aeiou"))

defines a case-insensitive match for all of its elements except for the sub-element "Bar", which must match exactly capital-B, little-a, little-r. The default,
the outermost, top-level context is case sensitive.

The lexical case-sensitivity context affects the interpretation of

* constant strings, such as "foo",

* chars, such as #\x,

* char sets, such as ("abc"), and

* ranges, such as (/"az") that appear within that context. It does not affectdynamically computed regexps--ones that are introduced by ,exp and

,@exp forms. It does not affect named char-classes--presumably, if youwrote

lower, you didn't mean alpha.

uncase is not the same as w/nocase. To point up one distinction, considerthe two regexps

(uncase (~ "a"))
(w/nocase (~ "a"))

123

The regexp (~ "a") matches any character except "a," which means it doesmatch "A." Now,

(uncase re) matches any case-permutation of a string that rematches.
(~ "a") matches "A," so (uncase (~ "a")) matches "A" and "a"--and, for that matter, every other character. So

(uncase (~ "a")) is equivalentto
any.

In contrast, (w/nocase (~ "a")) establishes a case-insensitive lexical con-text in which the

"a" is interpreted, making the SRE equivalent to (~ ("aA")).

Dynamic regexps SRE notation allows you to compute parts of a regular ex-pressions at run time. The SRE

,exp
is a regexp whose body exp is a Scheme expression producing a string, charac-ter, char-set, or regexp as its value. Strings and characters are converted into

constant regexps; char-sets are converted into char-class regexps; and regexpvalues are substituted in place. So we can write regexps like this

(: "feeding the "

,(if (> n 1) "geese" "goose"))

This is how you can drop computed strings, such as someone's name, or thedecimal numeral for a computed number, into a complex regexp.

If we have a large, complex regular expression that is used multiple times insome other, containing regular expression, we can name it, using the binding
forms of the embedding language (e.g., Scheme), and refer to it by name in thecontaining expression. For example, consider the Scheme expression

(let* ((ws (rx (+ whitespace))) ; Seq of whitespace

;; Something like "Mar 14"
(date (rx (: (| "Jan" "Feb" "Mar" ...)

,ws
(| ("123456789") ; 1-9

(: ("12") digit) ; 10-29
"30" ; 30
"31"))))) ; 31
;; Now we can use DATE several times:
(rx ... ,date ... (* ... ,date ...)

... ,date ...))

where the (rx sre ...) macro is the Scheme special form that produces aScheme regexp value given a body in SRE notation.

As we saw in the char-class section, if a dynamic regexp is used in a char-class context (e.g., as an argument to a

~ operation), the expression must be

124

coercable not merely to a general regexp, but to a character sre--so it must beeither a singleton string, a character, a scsh char set, or a char-class regexp.

We can also define and use functions on regexps in the host language.For example, consider the following Scheme expressions, containing embedded SRE's (inside the rx macro expressions) which in term contain embeddedScheme expressions computing dynamic regexps:

(define (csl re)

;; A comma-separated list of RE's is either
(rx (| "" ; zero of them (empty string),

(: ,re ; or RE followed by

(* ", " ,re))))); zero or more comma-space-RE matches.

(rx ... ,date ...

,(csl (rx (| "John" "Paul" "George" "Ringo")))
...
,(csl date)
...)

We leave the extension of csl to allow for an optional "and" between the lasttwo matches as an exercise for the interested reader (e.g., to match "John, Paul,
George and Ringo").

Note, in passing, one of the nice features of SRE notation: they can be com-mented, and indented in a fashion to show the lexical extent of the subexpressions.

When we embed a computed regexp inside another regular expression withthe ,exp form, we must specify how to account for the submatches that may be

in the computed part. For example, suppose we have the regexp

(rx (submatch (* "foo"))

(submatch (? "bar"))
,(f x)
(submatch "baz"))

It's clear that the submatch for the (* "foo") part of the regexp is submatch#1, and the

(? "bar") part is submatch #2. But what number submatch isthe
"baz" submatch? It's not clear. Suppose the Scheme expression (f x)produces a regular expression that itself has 3 subforms. Are these counted

(making the "baz" submatch #6), or not counted (making the "bar" submatch#3)?

SRE notation provides for both possibilities. The SRE

,exp

125

does not contribute its submatches to its containing regexp; it has zero sub-matches. So one can reliably assign submatch indices to forms appearing after
a ,exp form in a regexp.

On the other hand, the SRE

,@exp
"splices" its resulting regexp into place, exposing its submatches to the con-taining regexp. This is useful if the computed regexp is defined to produce a
certain number of submatches--if that is part of exp's "contract."

String and line units The regexps bos and eos match the empty string at thebeginning and end of the string, respectively.

The regexps bol and eol match the empty string at the beginning and endof a line, respectively. A line begins at the beginning of the string, and just after
every newline character. A line ends at the end of the string, and just beforeevery newline character. The char class

nonl matches any character exceptnewline, and is useful in conjunction with line-based pattern matching.

{Note bol and eol are not supported by scsh's current regexp search en-gine, which is Spencer's Posix matcher. This is the only element of the notation
that is not supported by the current scsh reference implementation.}

Posix string notation The SRE (posix-string string), where string is astring literal (not a general Scheme expression), allows one to use Posix string
notation for a regexp. It's intended as backwards compatibility and is depre-cated. For example,

(posix-string "[aeiou]+|x*|y{3,5}") matches a stringof vowels, a possibly empty string of x's, or three to five y's.

Note that parentheses are used ambiguously in Posix notation--both forgrouping and submatch marking. The

(posix-string string) form makes theconservative assumption: all parentheses introduce submatches.

Deleted submatches Deleted submatches, or "DSM's," are a subtle featurethat are never required in expressions written by humans. They can be introduced by the simplifier when reducing regular expressions to simpler equiva-lents, and are included in the syntax to give it expressibility spanning the full
regexp ADT. They may appear when unparsing simplified regular expressionsthat have been run through the simplifier; otherwise you are not likely to see
them. Feel free to skip this section.

The regexp simplifier can sometimes eliminate entire sub-expressions froma regexp. For example, the regexp

126

(: "foo" (** 0 0 "apple") "bar")
can be simplified to

"foobar"
since (** 0 0 "apple") will always match the empty string. The regexp

(| "foo"

(: "Richard" (|) "Nixon")
"bar")

can be simplified to

(| "foo" "bar")
The empty choice (|) can't match anything, so the whole

(: "Richard" (|) "Nixon")
sequence can't match, and we can remove it from the choice.

However, if deleting part of a regular expression removes a submatch form,any following submatch forms will have their numbering changed, which

would be an error. For example, if we simplify

(: (** 0 0 (submatch "apple"))

(submatch "bar"))

to

(submatch "bar")
then the "bar" submatch changes from submatch #2 to submatch #1--so thisis not a legal simplification.

When the simplifier deletes a sub-regexp that contains submatches, it in-troduces a special regexp form to account for the missing, deleted submatches,
thus keeping the submatch accounting correct.

(dsm pre post sre ...)
is a regexp that matches the sequence (: sre ...). pre and post are integerconstants. The DSM form introduces pre deleted submatches before the body,
and post deleted submatches after the body. If the body (: sre . . . ) itself hasbody-sm submatches, then the total number of submatches for the DSM form is

pre + body-sm + post.

127

These extra, deleted submatches are never assigned string indices in any matchvalues produced when matching the regexp against a string.

As examples,

(| (: (submatch "Richard") (|) "Nixon")

(submatch "bar"))

can be simplified to

(dsm 1 0 (submatch "bar"))
The regexp

(: (** 0 0 (submatch "apple"))

(submatch "bar"))

can be simplified to

(dsm 1 0 (submatch "bar"))

@subsection Embedding regexps within Scheme programs

SRE's can be placed in a Scheme program using the (rx sre ...) Schemeform, which evaluates to a Scheme regexp value.

Static and dynamic regexps
We separate SRE expressions into two classes: static and dynamic expressions.A static expression is one that has no run-time dependencies; it is a complete,
self-contained description of a regular set. A dynamic expression is one thatrequires run-time computation to determine the particular regular set being
described. There are two places where one can embed run-time computationsin an SRE:

* The from or to repetition counts of **, =, and >= forms;

* ,exp and ,@exp forms.

A static SRE is one that does not contain any ,exp or ,@exp forms, and whose
**, =, and >= forms all contain constant repetition counts.

Scsh's rx macro is able, at macro-expansion time, to completely parse, sim-plify and translate any static SRE into the equivalent Posix string which is used

to drive the underlying C-based matching engine; there is no run-time over-head. Dynamic SRE's are partially simplified and then expanded into Scheme
code that constructs the regexp at run-time.

128

@section Regexp functions

@subsection Obsolete, deprecated procedures

These two procedures are survivors from the previous, now-obsolete scsh reg-exp interface. Old code must open the

re-old-funs package to access them.They should not be used in new code.

(string-match posix-re-string string [start]) -! match or false procedure
(make-regexp posix-re-string) -! regexp procedure

These are old functions included for backwards compatibility with pre-vious releases. They are deprecated and will go away at some point in

the future.
Note that the new release has no "regexp compiling" procedure at all--regexp values are compiled for the matching engine on-demand, and the

necessary data structures are cached inside the ADT values.

@subsection Standard procedures and syntax

(rx sre . . . ) -! regexp Syntax

This allows you to describe a regexp value with SRE notation.

(regexp? x) -! boolean procedure

Returns true if the value is a regular expression.

(regexp-search re string [start flags]) -! match-data or false procedure
(regexp-search? re string [start flags]) -! boolean procedure

Search string starting at position start, looking for a match for regexp re.If a match is found, return a match structure describing the match, otherwise #f. Start defaults to 0.
Flags is the bitwise-or of regexp/bos-not-bol and regexp/eos-not-eol.
regexp/bos-not-bol means the beginning of the string isn't a line-begin.
regexp/eos-not-eol is analogous. {Note They're currently ignored be-cause begining/end-of-line anchors aren't supported by the current implementation.}
Use regexp-search? when you don't need submatch information, as ithas the potential to be significantly faster on submatch-containing regexps.
There is no longer a separate regexp "compilation" function; regexp val-ues are compiled for the C engine on demand, and the resulting C structures are cached in the regexp structure after the first use.

129

(match:start m [i]) -! integer or false procedure
(match:end m [i]) -! integer or false procedure
(match:substring m [i]) -! string or false procedure

match:start returns the start position of the submatch denoted bymatch-number. The whole regexp is 0; positive integers index submatches

in the regexp, counting left-to-right. Match-number defaults to 0.
If the regular expression matches as a whole, but a particular sub-expression does not match, then

match:start returns #f.

match:end is analogous to match:start, returning the end position ofthe indexed submatch.

match:substring returns the substring matched regexp's submatch. Ifthere was no match for the indexed submatch, it returns false.

(regexp-substitute port-or-false match . items) -! object procedure

This procedure can be used to perform string substitutions based onregular-expression matches. The results of the substitution can be either

output to a port or returned as a string.
The match argument is a regular-expression match structure that controlsthe substitution. If port is an output port, the items are written out to the

port:

* If an item is a string, it is copied directly to the port.*

If an item is an integer, the corresponding submatch from match iswritten to the port.

* If an item is 'pre, the prefix of the matched string (the text precedingthe match) is written to the port.

* If an item is 'post, the suffix of the matched string is written.
If port is #f, nothing is written, and a string is constructed and returnedinstead.

(regexp-substitute/global port-or-false re str . items) -! object procedure

This procedure is similar to regexp-substitute, but can be used to per-form repeated match/substitute operations over a string. It has the following differences with regexp-substitute:

* It takes a regular expression and string to be matched as parameters,instead of a completed match structure.

* If the regular expression doesn't match the string, this procedure isthe identity transform--it returns or outputs the string.

130

* If an item is 'post, the procedure recurses on the suffix string (thetext from string following the match). Including a

'post in the listof items is how one gets multiple match/substitution operations.

* If an item is a procedure, it is applied to the match structure for agiven match. The procedure returns a string to be used in the result.

The regexp parameter can be either a compiled regular expression or astring specifying a regular expression.
Some examples:
;;; Replace occurrences of "Cotton" with "Jin".
(regexp-substitute/global #f (rx "Cotton") s

'pre "Jin" 'post)

;;; mm/dd/yy -> dd/mm/yy date conversion.
(regexp-substitute/global #f (rx (submatch (+ digit)) "/" ; 1 = M

(submatch (+ digit)) "/" ; 2 = D
(submatch (+ digit))) ; 3 = Y
s ; Source string
'pre 2 "/" 1 "/" 3 'post)

;;; "9/29/61" -> "Sep 29, 1961" date conversion.
(regexp-substitute/global #f (rx (submatch (+ digit)) "/" ; 1 = M

(submatch (+ digit)) "/" ; 2 = D
(submatch (+ digit))) ; 3 = Y
s ; Source string
'pre
;; Sleazy converter -- ignores "year 2000" issue,
;; and blows up if month is out of range.
(lambda (m)

(let ((mon (vector-ref '#("Jan" "Feb" "Mar" "Apr" "May" "Jun"

"Jul" "Aug" "Sep" "Oct" "Nov" "Dec")
(- (string->number (match:substring m 1)) 1)))
(day (match:substring m 2))
(year (match:substring m 3)))
(string-append mon " " day ", 19" year)))
'post)

;;; Remove potentially offensive substrings from string S.
(define (kill-matches re s)

(regexp-substitute/global #f re s 'pre 'post))

(kill-matches (rx (| "Windows" "tcl" "Intel")) s) ; Protect the children.

(regexp-fold re kons knil s [finish start]) -! object procedure

131

The following definition is a bit unwieldy, but the intuition is sim-ple: this procedure uses the regexp re to divide up string s into nonmatching/matching chunks, and then "folds" the procedure kons acrossthis sequence of chunks. It is useful when you wish to operate on a
string in sub-units defined by some regular expression, as are the related
regexp-fold-right and regexp-for-each procedures.

Search from start (defaulting to 0) for a match to re; call this match m. Leti be the index of the end of the match (that is,

(match:end m 0)). Loopas follows:

(regexp-fold re kons (kons start m knil) s finish i)If there is no match, return instead
(finish start knil)Finish defaults to

(lambda (i knil) knil).

In other words, we divide up s into a sequence of non-matching/matching chunks:

NM1 M1 NM1 M2 . . . NMk-1 Mk-1 NMk
where NM1 is the initial part of s that isn't matched by the regexp re,M

1 is the first match, NM2 is the following part of s that isn't matched,M
2 is the second match, and so forth--NMk is the final non-matchingchunk of s. We apply kons from left to right to build up a result, passing it one non-matching/matching chunk each time: on an application
(kons i m knil), the non-matching chunk goes from i to (match:beginm

0), and the following matching chunk goes from (match:begin m 0)to
(match:end m 0). The last non-matching chunk NMk is processed byk. So the computation we perform is

(final Q (kons jk Mk ... (kons J1 M1 knil) ...))
where Ji is the index of the start of NMi, Mi is a match value describingM

i, and Q is the index of the beginning of NMk.
Hint: The let-match macro is frequently useful for operating on thematch value M passed to the kons function.

(regexp-fold-right re kons knil s [finish start]) -! object procedure

The right-to-left variant of regexp-fold.
This procedure repeatedly matches regexp re across string s. This dividess up into a sequence of matching/non-matching chunks:

NM1 M1 NM1 M2 . . . NMk-1 Mk-1 NMk
where NM1 is the initial part of s that isn't matched by the regexp re, M1is the first match, NM

2 is the following part of s that isn't matched, M2

132

is the second match, and so forth--NMk is the final non-matching chunkof s. We apply kons from right to left to build up a result, passing it one
non-matching/matching chunk each time:

(final Q (kons M1 j1 ... (kons Mk Jk knil) ...))
where MTCHi is a match value describing Mi, Ji is the index of the endof NMi (or, equivalently, the beginning of Mi+1), and Q is the index of

the beginning of M1. In other words, KONS is passed a match, an indexdescribing the following non-matching text, and the value produced by
folding the following text. The FINAL function "polishes off" the fold op-eration by handling the initial chunk of non-matching text (NM0, above).
FINISH defaults to (lambda (i knil) knil)
Example: To pick out all the matches to re in s, say

(regexp-fold-right re

(* (m i lis)

(cons (match:substring m 0) lis))

'() s)

Hint: The let-match macro is frequently useful for operating on thematch value m passed to the

kons function.

(regexp-for-each re proc s [start]) -! undefined procedure

Repeatedly match regexp re against string s. Apply proc to each matchthat is produced. Matches do not overlap.

Hint: The let-match macro is frequently useful for operating on thematch value m passed to varproc.

(let-match match-exp mvars body . . . ) -! object Syntax
(if-match match-exp mvars on-match no-match) -! object Syntax

Mvars is a list of vars that is bound to the match and submatches of thestring;

#F is allowed as a don't-care element. For example,

(let-match (regexp-search date s) (whole-date month day year)

... body ...)

matches the regexp against string s, then evaluates the body of the
let-match in a scope where whole-date is bound to the matched string,and

month, day and year are bound to the first, second and third sub-matches.

if-match is similar, but if the match expression is false, then the no-matchexpression is evaluated; this would be an error in

let-match.

(match-cond clause . . . ) -! object Syntax

133

This macro allows one to conditionally attempt a sequence of patternmatches, interspersed with other, general conditional tests. There are
four kinds of match-cond clause, one introducing a pattern match, andthe other three simply being regular

cond-style clauses, marked by the
test and else keywords:

(match-cond (match-exp match-vars body ...) ; As in if-match

(test exp body ...) ; As in cond
(test exp => proc) ; As in cond
(else body ...)) ; As in cond

(flush-submatches re) -! re procedure
(uncase re) -! re procedure
(simplify-regexp re) -! re procedure
(uncase-char-set cset) -! re procedure
(uncase-string str) -! re procedure

These functions map regexps and char sets to other regexps.
flush-submatches returns a regexp which matches exactly what its ar-gument matches, but contains no submatches.

uncase returns a regexp that matches any case-permutation of its argu-ment regexp.
simplify-regexp applies the simplifier to its argument. This is done au-tomatically when compiling regular expressions, so this is only useful for
programmers that are directly examining the ADT value with lower-levelaccessors.

uncase-char-set maps a char set to a regular expression thatmatches any character from that set, regardless of case. Similarly,
uncase-string returns a regexp that matches any case-permutation ofthe string. For example,

(uncase-string "Knight") returns the samevalue that
(rx ("kK") ("nN") ("iI") ("gG") ("hH") ("tT")) or (rx
(w/nocase "Knight")).

(sre->regexp sre) -! re procedure
(regexp->sre re) -! sre procedure

These are the SRE parser and unparser. That is, sre->regexp maps anSRE to a regexp value, and

regexp->sre does the inverse. The latterfunction can be useful for printing out regexps in a readable format.

134

(sre->regexp '(: "Olin " (? "G. ") "Shivers")) =) regexp
(define re (re-seq (re-string "Pete ")

(re-repeat 1 #f (re-string "Sz"))
(re-string "ilagyi")))
(regexp->sre (re-repeat 0 1 re))=)

'(? "Pete" (+ "Sz") "ilagyi")

(posix-string->regexp string) -! re procedure
(regexp->posix-string re) -! [string syntax-level paren-count submatches-vector] procedure

These two functions are the Posix notation parser and unparser. That is,
posix-string->regexp maps a Posix-notation regular expression, suchas

"g(ee|oo)se", to a regexp value, and regexp->posix-string does theinverse.

You can use these tools to map between scsh regexps and Posix regexpstrings, which can be useful if you want to do conversion between SRE's
and Posix form. For example, you can write a particularly complex reg-exp in SRE form, or compute it using the ADT constructors, then convert
to Posix form, print it out, cut and paste it into a C or emacs lisp program.Or you can import an old regexp from some other program, parse it into
an ADT value, render it to an SRE, print it out, then cut and paste it intoa scsh program.

Note:

* The string parser doesn't handle the exotica of character class namessuch as

[[:alnum:]]; the current implementation was written in inthree hours.

@section The regexp ADT

The following functions may be used to construct and examine scsh's regexpabstract data type. They are in the following Scheme 48 packages: re-adt-lib
re-lib scsh

Each basic class of regexp has a predicate, a basic constructor, a "smart"consructor that performs limited "peephole" optimisation on its arguments,

and a set of accessors. The ...:tsm accessor returns the total number of sub-matches contained in the regular expression.

(re-seq? x) -! boolean Type predicate
(make-re-seq re-list) -! re Basic constructor
(re-seq re-list) -! re Smart constructor
(re-seq:elts re) -! re-list Accessor

135

(re-seq:tsm re) -! integer Accessor
(re-choice? x) -! boolean Type predicate
(make-re-choice re-list) -! re Basic constructor
(re-choice re-list) -! re Smart constructor
(re-choice:elts re) -! re-list Accessor
(re-choice:tsm re) -! integer Accessor

(re-repeat? x) -! boolean Type predicate
(make-re-repeat from to body) -! re Accessor
(re-repeat:from re) -! integer Accessor
(re-repeat:to re) -! integer Accessor
(re-repeat:tsm re) -! integer Accessor

(re-submatch? x) -! boolean Type predicate
(make-re-submatch body [pre-dsm post-dsm]) -! re Accessor
(re-submatch:pre-dsm re) -! integer Accessor
(re-submatch:post-dsm re) -! integer Accessor
(re-submatch:tsm re) -! integer Accessor

(re-string? x) -! boolean Type predicate
(make-re-string chars) -! re Basic constructor
(re-string chars) -! re Basic constructor
(re-string:chars re) -! string Accessor

(re-char-set? x) -! boolean Type predicate
(make-re-char-set cset) -! re Basic constructor
(re-char-set cset) -! re Basic constructor
(re-char-set:cset re) -! char-set Accessor

(re-dsm? x) -! boolean Type predicate
(make-re-dsm body pre-dsm post-dsm) -! re Basic constructor
(re-dsm body pre-dsm post-dsm) -! re Smart constructor
(re-dsm:body re) -! re Accessor
(re-dsm:pre-dsm re) -! integer Accessor
(re-dsm:post-dsm re) -! integer Accessor
(re-dsm:tsm re) -! integer Accessor

re-bos regexp
re-eos regexp
re-bol regexp
re-eol regexp

These variables are bound to the primitive anchor regexps.

(re-bos? object) -! boolean procedure
(re-eos? object) -! boolean procedure
(re-bol? object) -! boolean procedure
(re-eol? object) -! boolean procedure

136

These predicates recognise the associated primitive anchor regexp.
re-trivial regexp
(re-trivial? re) -! boolean procedure

The variable re-trivial is bound to a regular expression that matchesthe empty string (corresponding to the SRE

"" or (:)); it is recognisedby the associated predicate. Note that the predicate is only guaranteed to

recognise this particular trivial regexp; other trivial regexps built usingother constructors may or may not produce a true value.

re-empty regexp
(re-empty? re) -! boolean procedure

The variable re-empty is bound to a regular expression that nevermatches (corresponding to the SRE

(|)); it is recognised by the associ-ated predicate. Note that the predicate is only guaranteed to recognise

this particular empty regexp; other empty regexps built using other con-structors may or may not produce a true value.

re-any regexp
(re-any? re) -! boolean procedure

The variable re-any is bound to a regular expression that matches anycharacter (corresponding to the SRE

any); it is recognised by the associ-ated predicate. Note that the predicate is only guaranteed to recognise

this particular any-character regexp value; other any-character regexpsbuilt using other constructors may or may not produce a true value.

re-nonl regexp

The variable re-nonl is bound to a regular expression that matches anynon-newline character (corresponding to the SRE

(~ #\newline)).

(regexp? object) -! boolean procedure

Is the object a regexp?

(re-tsm re) -! integer procedure

Return the total number of submatches contained in the regexp.

(clean-up-cres) -! undefined procedure

The current scsh implementation should call this function periodically torelease C-heap storage associated with compiled regexps. Hopefully, this

procedure will be removed at a later date.

137

@section Syntax-hacking tools

The Scheme 48 package sre-syntax-tools exports several tools for macrowriters that want to use SREs in their macros. In the functions defined below,
compare and rename parameters are as passed to Clinger-Rees explicit-renaminglow-level macros.

(if-sre-form form conseq-form alt-form) -! form Syntax

If form is a legal SRE, this is equivalent to the expression conseq-form, oth-erwise it expands to alt-form.

This is useful for high-level macro authors who want to write a macrowhere one field in the macro can be an SRE or possibly something else.
E.g., we might have a conditional form wherein if the test part of one armis an SRE, it expands to a regexp match on some implied value, otherwise
the form is evaluated as a boolean Scheme expression. For example, aconditional macro might expand into code containing the following form,
which in turn would have one of two possible expansions:

(if-sre-form test-exp ; If TEST-EXP is SRE,

(regexp-search? (rx test-exp) line) ; match it w/the line,
test-exp) ; otw it's a text exp.

(sre-form? form rename compare) -! boolean procedure

This procedure is for low-level macros doing things equivalent to
if-sre-form. It returns true if the form is a legal SRE.

Note that neither sre-form nor if-sre-form does a deep recursion overthe form in the case where the form is a list. They simply check the car of

the form for one of the legal SRE keywords.
(parse-sre sre-form compare rename) -! re procedure
(parse-sres sre-forms compare rename) -! re procedure

Parse sre-form into an ADT. Note that if the SRE is dynamic--contains
,exp or ,@exp forms, or has repeat operators whose from/to counts arenot constants--then the returned ADT will have Scheme expressions in the

corresponding slots of the regexp records instead of the correspondinginteger, char-set, or regexp. In other words, we use the ADT as its own
AST. It's called a "hack."
parse-sres parses a list of SRE forms that comprise an implicit sequence.

(regexp->scheme re rename) -! Scheme-expression procedure

Returns a Scheme expression that will construct the regexp re using ADTconstructors such as

make-re-sequence, make-re-repeat, and so forth.

If the regexp is static, it will be simplified and pre-translated to a Posixstring as well, which will be part of the constructed regexp value.

138

(static-regexp? re) -! boolean procedure

Is the regexp a static one?

@node Reading delimited strings
@c    Node name, Next, Previous, Up
@chapter Reading delimited strings

Scsh provides a set of procedures that read delimited strings from input ports.There are procedures to read a single line of text (terminated by a newline character), a single paragraph (terminated by a blank line), and general delimitedstrings (terminated by a character belonging to an arbitrary character set).

These procedures can be applied to any Scheme input port. However, thescsh virtual machine has native-code support for performing delimited reads
on Unix ports, and these input operations should be particularly fast--muchfaster than doing the equivalent character-at-a-time operation from Scheme
code.

All of the delimited input operations described below take a handle-delimparameter, which determines what the procedure does with the terminating

delimiter character. There are four possible choices for a handle-delim param-eter:

handle-delim Meaning
'trim Ignore delimiter character.
'peek Leave delimiter character in input stream.
'concat Append delimiter character to returned value.
'split Return delimiter as second value.

The first case, 'trim, is the standard default for all the routines described inthis section. The last three cases allow the programmer to distinguish between

strings that are terminated by a delimiter character, and strings that are termi-nated by an end-of-file.

(read-line [port handle-newline]) -! string or eof-object procedure

Reads and returns one line of text; on @acronym{eof}, returns the @acronym{eof} object. A line isterminated by newline or @acronym{eof}.

140

handle-newline determines what read-line does with the newline or @acronym{eof} that terminates the line; it takes the general set of values described for
the general handle-delim case above, and defaults to 'trim (discard thenewline). Using this argument allows one to tell whether or not the last
line of input in a file is newline terminated.

(read-paragraph [port handle-delim]) -! string or @acronym{eof} procedure

This procedure skips blank lines, then reads text from a port until a blankline or @acronym{eof} is found. A "blank line" is a (possibly empty) line composed

only of white space. The handle-delim parameter determines how the ter-minating blank line is handled. It is described above, and defaults to
'trim. The 'peek option is not available.
The following procedures read in strings from ports delimited by charactersbelonging to a specific set. See section @ref{5.5} for information on character set

manipulation.
(read-delimited char-set [port handle-delim]) -! string or @acronym{eof} procedure

Read until we encounter one of the chars in char-set or @acronym{eof}. Thehandle-delim parameter determines how the terminating character is handled. It is described above, and defaults to 'trim.
The char-set argument may be a charset, a string, or a character; it is co-erced to a charset.

(read-delimited! char-set buf [port handle-delim start end]) -! nchars or @acronym{eof} or #f procedure

A side-effecting variant of read-delimited.
The data is written into the string buf at the indices in the half-open in-terval [start

, end); the default interval is the whole string: start = 0 andend =
(string-length buf). The values of start and end must specify awell-defined interval in str, i.e., 0 <= start <= end <=

(string-length buf).

It returns nbytes, the number of bytes read. If the buffer filled up withouta delimiter character being found,

#f is returned. If the port is at @acronym{eof}when the read starts, the @acronym{eof} object is returned.

If an integer is returned (i.e., the read is successfully terminated by read-ing a delimiter character), then the handle-delim parameter determines
how the terminating character is handled. It is described above, and de-faults to

'trim.

(%read-delimited! char-set buf gobble? [port start end]) -! [char-or-@acronym{eof}-or-#f integer] procedure

This low-level delimited reader uses an alternate interface. It returns twovalues: terminator and num-read.

141

terminator A value describing why the read was terminated:

Character or @acronym{eof}-object ) Read terminated by this value.
#f ) Filled buffer without finding a delimiter.

num-read Number of characters read into buf.

If the read is successfully terminated by reading a delimiter character,then the gobble? parameter determines what to do with the terminating

character. If true, the character is removed from the input stream; if false,the character is left in the input stream where a subsequent read operation will retrieve it. In either case, the character is also the first valuereturned by the procedure call.

(skip-char-set skip-chars [port]) -! integer procedure

Skip characters occurring in the set skip-chars; return the number of char-acters skipped. The skip-chars argument may be a charset, a string, or a

character; it is coerced to a charset.

@node Awk, record I/O, and field parsing
@c    Node name, Next, Previous, Up
@chapter Awk, record I/O, and field parsing

Unix programs frequently process streams of records, where each record isdelimited by a newline, and records are broken into fields with other delimiters (for example, the colon character in /etc/passwd). Scsh has proceduresthat allow the programmer to easily do this kind of processing. Scsh's field
parsers can also be used to parse other kinds of delimited strings, such ascolon-separated

$PATH lists. These routines can be used with scsh's awk loopconstruct to conveniently perform pattern-directed computation over streams

of records.

@section Record I/O and field parsing

The procedures in this section are used to read records from I/O streams andparse them into fields. A record is defined as text terminated by some delimiter
(usually a newline). A record can be split into fields by using regular expres-sions in one of several ways: to match fields, to separate fields, or to terminate
fields. The field parsers can be applied to arbitrary strings (one common useis splitting environment variables such as

$PATH at colons into its componentelements).

The general delimited-input procedures described in chapter 7 are also use-ful for reading simple records, such as single lines, paragraphs of text, or
strings terminated by specific characters.

143

@subsection Reading records

(record-reader [delims elide-delims? handle-delim]) -! procedure procedure

Returns a procedure that reads records from a port. The procedure isinvoked as follows:

(reader [port]) -! string or @acronym{eof}
A record is a sequence of characters terminated by one of the charactersin delims or @acronym{eof}. If elide-delims? is true, then a contiguous sequence of

delimiter chars are taken as a single record delimiter. If elide-delims? isfalse, then a delimiter char coming immediately after a delimiter char
produces an empty-string record. The reader consumes the delimitingchar(s) before returning from a read.

The delims set defaults to the set {newline}. It may be a charset, string,character, or character predicate, and is coerced to a charset. The
elide-delims? flag defaults to #f.
The handle-delim argument controls what is done with the record's termi-nating delimiter.

'trim Delimiters are trimmed. (The default)
'split Reader returns delimiter string as asecond argument. If record is terminated by @acronym{eof}, then the @acronym{eof} object isreturned as this second argument.
'concat The record and its delimiter are re-turned as a single string.

The reader procedure returned takes one optional argument, the portfrom which to read, which defaults to the current input port. It returns a
string or @acronym{eof}.

@subsection Parsing fields

(field-splitter [field num-fields]) -! procedure procedure
(infix-splitter [delim num-fields handle-delim]) -! procedure procedure
(suffix-splitter [delim num-fields handle-delim]) -! procedure procedure
(sloppy-suffix-splitter [delim num-fields handle-delim]) -! procedure procedure

These functions return a parser function that can be used as follows:

(parser string [start]) -! string-list

The returned parsers split strings into fields defined by regular expres-sions. You can parse by specifying a pattern that separates fields, a pattern

that terminates fields, or a pattern that matches fields:

144

Procedure Pattern
field-splitter matches fields
infix-splitter separates fields
suffix-splitter terminates fields
sloppy-suffix-splitter terminates fields

These parser generators are controlled by a range of options, so that youcan precisely specify what kind of parsing you want. However, these
options default to reasonable values for general use.
Defaults:delim = (rx (| (+ white) eos)) (suffix delimiter: white space or eos)

(rx (+ white)) (infix delimiter: white space)field =
(rx (+ (~ white))) (non-white-space)num-fields =
#f (as many fields as possible)handle-delim =
'trim (discard delimiter chars). . . which means: break the string at white space, discarding the white

space, and parse as many fields as possible.
The delim parameter is a regular expression matching the text that occursbetween fields. See chapter 6 for information on regular expressions, and

the rx form used to specify them. In the separator case, it defaults to apattern matching white space; in the terminator case, it defaults to white
space or end-of-string.
The field parameter is a regular expression used to match fields. It de-faults to non-white-space.

The delim patterns may also be given as a string, character, or char-set,which are coerced to regular expressions. So the following expressions
are all equivalent, each producing a function that splits strings apart atcolons:

(infix-splitter (rx ":"))
(infix-splitter ":")
(infix-splitter #\:)
(infix-splitter (char-set #\:))

The boolean handle-delim determines what to do with delimiters.'trim Delimiters are thrown away after parsing. (default)

'concat Delimiters are appended to the field preceding them.
'split Delimiters are returned as separate elements in the field list.

The num-fields argument used to create the parser specifies how manyfields to parse. If

#f (the default), the procedure parses them all. If a pos-itive integer
n, exactly that many fields are parsed; it is an error if thereare more or fewer than

n fields in the record. If num-fields is a negativeinteger or zero, then |
n| fields are parsed, and the remainder of the string

145

is returned in the last element of the field list; it is an error if fewer than|

n| fields can be parsed.

The field parser produced is a procedure that can be employed as follows:

(parse string [start]) =) string-list
The optional start argument (default 0) specifies where in the string tobegin the parse. It is an error if start

> (string-length string).

The parsers returned by the four parser generators implement differentkinds of field parsing:

field-splitter The regular expression specifies the actual field.
suffix-splitter Delimiters are interpreted as element terminators. Ifvertical-bar is the the delimiter, then the string

"" is the emptyrecord
(), "foo|" produces a one-field record ("foo"), and "foo"is an error.

The syntax of suffix-delimited records is:h

record i ::= "" (Empty record)| h element i h delim i h record i

It is an error if a non-empty record does not end with a delimiter.To make the last delimiter optional, make sure the delimiter regexp
matches the end-of-string (sre eos).
infix-splitter Delimiters are interpreted as element separators. Ifcomma is the delimiter, then the string

"foo," produces a two-fieldrecord
("foo" "").

The syntax of infix-delimited records is:h

record i ::= "" (Forced to be empty record)| h real-infix-record i

h real-infix-record i ::= h element i h delim i h real-infix-record i| h element i
Note that separator semantics doesn't really allow for emptyrecords--the straightforward grammar (i.e., h real-infix-record i)
parses an empty string as a singleton list whose one field is theempty string,

(""), not as the empty record (). This is unfortunate,since it means that infix string parsing doesn't make

string-appendand
append isomorphic. For example,

((infix-splitter ":") (string-append x ":" y))
doesn't always equal

(append ((infix-splitter ":") x)

((infix-splitter ":") y))

146

Record : suffix :|$ suffix : infix non-: field
"" () () () ()
":" ("") ("") ("" "") ()
"foo:" ("foo") ("foo") ("foo" "") ("foo")
":foo" error ("" "foo") ("" "foo") ("foo")
"foo:bar" error ("foo" "bar") ("foo" "bar") ("foo" "bar")

Figure 8.1: Using different grammars to split records into fields.

It fails when x or y are the empty string. Terminator semantics doespreserve a similar isomorphism.
However, separator semantics is frequently what other Unix soft-ware uses, so to parse their strings, we need to use it. For example,
Unix $PATH lists have separator semantics. The path list "/bin:" isbroken up into

("/bin" ""), not ("/bin"). Comma-separated listsshould also be parsed this way.

sloppy-suffix The same as the suffix case, except that the parser willskip an initial delimiter string if the string begins with one instead

of parsing an initial empty field. This can be used, for example,to field-split a sequence of English text at white-space boundaries,
where the string may begin or end with white space, by using regex

(rx (| (+ white) eos))
(But you would be better off using field-splitter in this case.)

Figure 8.1 shows how the different parser grammars split apart the samestrings. Having to choose between the different grammars requires you to
decide what you want, but at least you can be precise about what you areparsing. Take fifteen seconds and think it out. Say what you mean; mean what
you say.
(join-strings string-list [delimiter grammar]) -! string procedure

This procedure is a simple unparser--it pastes strings together using thedelimiter string.

The grammar argument is one of the symbols infix (the default) or
suffix; it determines whether the delimiter string is used as a separa-tor or as a terminator.

The delimiter is the string used to delimit elements; it defaults to a singlespace

" ".

Example:

147

(join-strings '("foo" "bar" "baz") ":")=)

"foo:bar:baz"

@subsection Field readers

(field-reader [field-parser rec-reader]) -! procedure procedure

This utility returns a procedure that reads records with field structurefrom a port. The reader's interface is designed to make it useful in the

awk loop macro (section @ref{8.2}). The reader is used as follows:

(reader [port]) =) [raw-record parsed-record] or [@acronym{eof} ()]

When the reader is applied to an input port (default: the current inputport), it reads a record using rec-reader. If this record isn't the @acronym{eof} object, it

is parsed with field-parser. These two values--the record, and its parsedrepresentation--are returned as multiple values from the reader.

When called at @acronym{eof}, the reader returns [@acronym{eof}-object ()].
Although the record reader typically returns a string, and the field-parsertypically takes a string argument, this is not required. The record reader

can produce, and the field-parser consume, values of any type. However,the empty list returned as the parsed value on @acronym{eof} is hardwired into the
field reader.
For example, if port p is open on /etc/passwd, then

((field-reader (infix-splitter ":" 7)) p)
returns two values:
"dalbertz:mx3Uaqq0:107:22:David Albertz:/users/dalbertz:/bin/csh"
("dalbertz" "mx3Uaqq0" "107" "22" "David Albertz" "/users/dalbertz"

"/bin/csh")

The field-parser defaults to the value of (field-splitter), a parser thatpicks out sequences of non-white-space strings.

The rec-reader defaults to read-line.
Figure 8.2 shows field-reader being used to read different kinds ofUnix records.

@subsection Forward-progress guarantees and empty-string matches

A loop that pulls text off a string by repeatedly matching a regexp against thatstring can conceivably get stuck in an infinite loop if the regexp matches the
empty string. For example, the SREs bos, eos, (* any), and (| "foo" (*
( "f"))) can all match the empty string.

148

;;; /etc/passwd reader
(field-reader (infix-splitter ":" 7))

; wandy:3xuncWdpKhR.:73:22:Wandy Saetan:/usr/wandy:/bin/csh

;;; Two ls -l output readers
(field-reader (infix-splitter (rx (+ white)) 8))
(field-reader (infix-splitter (rx (+ white)) -7))

; -rw-r--r-- 1 shivers 22880 Sep 24 12:45 scsh.scm

;;; Internet hostname reader
(field-reader (field-splitter (rx (+ (~ ".")))))

; stat.sinica.edu.tw

;;; Internet IP address reader
(field-reader (field-splitter (rx (+ (~ "."))) 4))

; 18.24.0.241

;;; Line of integers
(let ((parser (field-splitter (rx (? ("+-")) (+ digit)))))

(field-reader (* (s) (map string->number (parser s))))

; 18 24 0 241

;;; Same as above.
(let ((reader (field-reader (field-splitter (rx (? ("+-"))

(+ digit))))))
(* maybe-port (map string->number (apply reader maybe-port))))

; Yale beat harvard 26 to 7.

Figure 8.2: Some examples of field-reader

149

The routines in this package that iterate through strings with regular ex-pressions are careful to handle this empty-string case. If a regexp matches the
empty string, the next search starts, not from the end of the match (which inthe empty string case is also the beginning--that's the problem), but from the
next character over. This is the correct behaviour. Regexps match the longestpossible string at a given location, so if the regexp matched the empty string
at location i, then it is guaranteed it could not have matched a longer patternstarting with character

i. So we can safely begin our search for the next matchat char
i + 1.

With this provision, every iteration through the loop makes some forwardprogress, and the loop is guaranteed to terminate.

This has the effect you want with field parsing. For example, if you split astring with the empty pattern, you will explode the string into its individual
characters:

((suffix-splitter (rx)) "foo") =) ("" "f" "o" "o")
However, even though this boundary case is handled correctly, we don't rec-ommend using it. Say what you mean--just use a field splitter:

((field-splitter (rx any)) "foo") =) ("f" "o" "o")
Or, more efficiently,

((* (s) (map string (string->list s))) "foo")

@subsection Reader limitations

Since all of the readers in this package require the ability to peek ahead onechar in the input stream, they cannot be applied to raw integer file descriptors,
only Scheme input ports. This is because Unix doesn't support peeking aheadinto input streams.

@section Awk

Scsh provides a loop macro and a set of field parsers that can be used to per-form text processing very similar to the Awk programming language. The
basic functionality of Awk is factored in scsh into its component parts. Thecontrol structure is provided by the

awk loop macro; the text I/O and parsersare provided by the field-reader subroutine library (section @ref{8.1}). This factoring

allows the programmer to compose the basic loop structure with any parser orinput mechanism at all. If the parsers provided by the field-reader package are
insufficient, the programmer can write a custom parser in Scheme and use itwith equal ease in the awk framework.

Awk-in-scheme is given by a loop macro called awk. It looks like this:

150

(awk h next-record i h record&field-vars i[h counter i] h state-var-decls i

h clause1 i ...)

The body of the loop is a series of clauses, each one representing a kind ofcondition/action pair. The loop repeatedly reads a record, and then executes
each clause whose condition is satisfied by the record.

Here's an example that reads lines from port p and prints the line numberand line of every line containing the string "Church-Rosser":

(awk (read-line) (ln) lineno ()
("Church-Rosser" (format #t "~d: ~s~%" lineno ln)))

This example has just one clause in the loop body, the one that tests for matchesagainst the regular expression "Church-Rosser".

The h next-record i form is an expression that is evaluated each time throughthe loop to produce a record to process. This expression can return multiple

values; these values are bound to the variables given in the h record&field-vars ilist of variables. The first value returned is assumed to be the record; when it
is the end-of-file object, the loop terminates.

For example, let's suppose we want to read items from /etc/password, andwe use the

field-reader procedure to define a record parser for /etc/passwdentries:

(define read-passwd (field-reader (infix-splitter ":" 7)))
binds read-passwd to a procedure that reads in a line of text when it is called,and splits the text at colons. It returns two values: the entire line read,

and a seven-element list of the split-out fields. (See section @ref{8.1} for more on
field-reader and infix-splitter.)

So if the h next-record i form in an awk expression is (read-passwd), thenh record&field-vars i must be a list of two variables, e.g.,

(record field-vec)
since read-passwd returns two values.

Note that awk allows us to use any record reader we want in the loop, re-turning whatever number of values we like. These values don't have to be

strings or string lists. The only requirement is that the record reader return the@acronym{eof} object as its first value when the loop should terminate.

The awk loop allows the programmer to have loop variables. These aredeclared and initialised by the h state-var-decls i form, a

((var init-exp) (var init-exp) ...)

151

list rather like the let form. Whenever a clause in the loop body executes, itevaluates to as many values as there are state variables, updating them.

The optional h counter i variable is an iteration counter. It is bound to 0 whenthe loop starts. The counter is incremented each time a non-@acronym{eof} record is read.
There are several kinds of loop clause. When evaluating the body of theloop,

awk evaluates all the clauses sequentially. Unlike cond, it does not stopafter the first clause is satisfied; it checks them all.

* (test body1 body2 ...)If test is true, execute the body forms. The last body form is the value

of the clause. The test and body forms are evaluated in the scope of therecord and state variables.

The test form can be one of:

integer: The test is true for that iteration of theloop. The first iteration is #1.

sre: A regular expression, in SRE notation(see chapter 6) can be used as a test.

The test is successful if the patternmatches the record. In particular, note
that any string is an SRE.
(when expr): The body of a when test is evaluatedas a Scheme boolean expression in the

inner scope of the awk form.expr: If the form is none of the above, it
is treated as a Scheme expression--in practice, the

when keyword is onlyneeded in cases where SRE/Scheme

expression ambiguity might occur.

* (range start-test stop-test body1 ...)

(:range start-test stop-test body1 ...)
(range: start-test stop-test body1 ...)
(:range: start-test stop-test body1 ...)These clauses become activated when start-test is true; they stay active on

all further iterations until stop-test is true.
So, to print out the first ten lines of a file, we use the clause:

(:range: 1 10 (display record))

The colons control whether or not the start and stop lines are processedby the clause. For example:

152

(range 1 5 ...) Lines 2 3 4
(:range 1 5 ...) Lines 1 2 3 4
(range: 1 5 ...) Lines 2 3 4 5
(:range: 1 5 ...) Lines 1 2 3 4 5

A line can trigger both tests, either simultaneously starting and stoppingan active region, or simultaneously stopping one and starting a new one,
so ranges can abut seamlessly.

* (else body1 body2 ...)If no other clause has executed since the top of the loop, or since the last

else clause, this clause executes.

* (test => exp)If evaluating

test produces a true value, apply exp to that value. If testis a regular expression, then exp is applied to the match data structure

returned by the regexp match routine.

* (after body1 ...)This clause executes when the loop encounters @acronym{eof}. The body forms execute in the scope of the state vars and the record-count var, if there areany. The value of the last body form is the value of the entire awk form.

If there is no after clause, awk returns the loop's state variables as multi-ple values.

@subsection Examples

Here are some examples of awk being used to process various types of inputstream.

(define $ list-ref) ; Saves typing.
;;; Print out the name and home-directory of everyone in /etc/passwd:
(let ((read-passwd (field-reader (infix-splitter ":" 7))))

(call-with-input-file "/etc/passwd"

(lambda (port)

(awk (read-passwd port) (record fields) ()

(#t (format #t "~a's home directory is ~a~%"

($ fields 0)
($ fields 5)))))))

153

;;; Print out the user-name and home-directory of everyone whose
;;; name begins with "S"
(let ((read-passwd (field-reader (infix-splitter ":" 7))))

(call-with-input-file "/etc/passwd"

(lambda (port)

(awk (read-passwd port) (record fields) ()

((: bos "S")

(format #t "~a's home directory is ~a~%"

($ fields 0)
($ fields 5)))))))

;;; Read a series of integers from stdin. This expression evaluates
;;; to the number of positive numbers that were read. Note our
;;; "record-reader" is the standard Scheme READ procedure.
(awk (read) (i) ((npos 0))

((> i 0) (+ npos 1)))

;;; Filter -- pass only lines containing my name.
(awk (read-line) (line) ()

("Olin" (display line) (newline)))

;;; Count the number of non-comment lines of code in my Scheme source.
(awk (read-line) (line) ((nlines 0))

((: bos (* white) ";") nlines) ; A comment line.
(else (+ nlines 1))) ; Not a comment line.

;;; Read numbers, counting the evens and odds.
(awk (read) (val) ((evens 0) (odds 0))

((> val 0) (display "pos ") (values evens odds)) ; Tell me about
((< val 0) (display "neg ") (values evens odds)) ; sign, too.
(else (display "zero ") (values evens odds))

((even? val) (values (+ evens 1) odds))
(else (values evens (+ odds 1))))

;;; Determine the max length of all the lines in the file.
(awk (read-line) (line) ((max-len 0))

(#t (max max-len (string-length line))))

154

;;; (This could also be done with PORT-FOLD:)
(port-fold (current-input-port) read-line

(lambda (line maxlen) (max (string-length line) maxlen))
0)

;;; Print every line longer than 80 chars.
;;; Prefix each line with its line #.
(awk (read-line) (line) lineno ()

((> (string-length line) 80)

(format #t "~d: ~s~%" lineno line)))

;;; Strip blank lines from input.
(awk (read-line) (line) ()

((~ white) (display line) (newline)))

;;; Sort the entries in /etc/passwd by login name.
(for-each (lambda (entry) (display (cdr entry)) (newline)) ; Out

(sort (lambda (x y) (string<? (car x) (car y))) ; Sort

(let ((read (field-reader (infix-splitter ":" 7)))) ; In

(awk (read) (line fields) ((ans '()))

(#t (cons (cons ($ fields 0) line) ans))))))

;;; Prefix line numbers to the input stream.
(awk (read-line) (line) lineno ()

(#t (format #t "~d:\t~a~%" lineno line)))

@section Backwards compatibility

Previous scsh releases provided an awk form with a different syntax, designedaround regular expressions written in Posix notation as strings, rather than
SREs.

This form is still available in a separate module for old code. It'll be docu-mented in the next release of this manual. Dig around in the sources for it.

@node Concurrent system programming
@c    Node name, Next, Previous, Up
@chapter Concurrent system programming

The Scheme Shell provides the user with support for concurrent programming.The interface consists of several parts:

* The thread system

* Synchronization vehicles

* Process state abstractions
Whereas the user deals with threads and synchronization explicitly, the processstate abstractions are built into the rest of the system, almost transparent for the user. Section @ref{9.5} describes the interaction between process state and threads.

@section Threads

A thread can be thought of as a procedure that can run independently of andconcurrent to the rest of the system. The calling procedure fires the thread up
and forgets about it.

The current thread interface is completely taken from Scheme 48. This doc-umentation is an extension of the file

doc/threads.txt.

The thread structure is named threads, it has to be opened explicitly.

(spawn thunk [name]) -! undefined procedure

Create and schedule a new thread that will execute thunk, a procedure withno arguments. Note that Scsh's

spawn does not return a reference to a threadobject. The optional argument name is used when printing the thread.

156

The new thread will not inherit the values for the process state from its par-ent, see the procedure

fork-thread in Section @ref{9.5} for a way to create a threadwith semantics similar to process forking.

(relinquish-timeslice) -! undefined procedure

Let other threads run for a while.

(sleep time) -! undefined procedure

Puts the current thread into sleep for time milliseconds. The time at whichthe thread is run again may be longer of course.

(terminate-current-thread) -! does-not-return procedure

Kill the current thread.
Mainly for debugging purposes, there is also an interface to the internalrepresentation of thread objects:

(current-thread) -! thread-object procedure

Return the object to which the current thread internally corresponds. Notethat this procedure is exported by the package

threads-internal only.

(thread? thing) -! boolean procedure

Returns true iff thing is a thread object.

(thread-name thread) -! name procedure

Name corresponds to the second parameter that was given to spawn whenthread was created.

(thread-uid thread) -! integer procedure

Returns a unique identifier for the current thread.

@section Locks

Locks are a simple mean for mutual exclusion. They implement a concept com-monly known as semaphores. Threads can obtain and release locks. If a thread
tries to obtain a lock which is held by another thread, the first thread is blocked.To access the following procedures, you must open the structure

locks.

(make-lock) -! lock procedure

Creates a lock.

(lock? thing) -! boolean procedure

Returns true iff thing is a lock.

(obtain-lock lock) -! undefined procedure

Obtain lock. Causes the thread to block if the lock is held by a thread.

157

(maybe-obtain-lock lock) -! boolean procedure

Tries to obtain lock, but returns false if the lock cannot be obtained.

(release-lock lock) -! boolean procedure

Releases lock. Returns true if the lock immediately got a new owner, falseotherwise.

(lock-owner-uid lock) -! integer procedure

Returns the uid of the thread that currently holds lock or false if the lock isfree.

@section Placeholders

Placeholders combine synchronization with value delivery. They can be thoughtof as special variables. After creation the value of the placeholder is undefined.
If a thread tries to read the placeholders value this thread is blocked. Multi-ple threads are allowed to block on a single placeholder. They will continue
running after another thread sets the value of the placeholder. Now all read-ing threads receive the value and continue executing. Setting a placeholder to
two different values causes an error. The structure placeholders features thefollowing procedures:

(make-placeholder) -! placeholder procedure

Creates a new placeholder.

(placeholder? thing) -! boolean procedure

Returns true iff thing is a placeholder.

(placeholder-set! placeholder value) -! undefined procedure

Sets the placeholders value to value. If the placeholder is already set to adifferent value an exception is risen.

(placeholder-value placeholder) -! value procedure

Returns the value of the placeholder. If the placeholder is yet unset, thecurrent thread is blocked until another thread sets the value by means of

placeholder-set!.

@section The event interface to interrupts

Scsh provides an synchronous interface to the asynchronous signals deliveredby the operation system1. The key element in this system is an object called

1 Olin's paper "Automatic management of operation-system resources" describes this system in
detail.

158

sigevent which corresponds to the single occurrence of a signal. A sigevent hastwo fields: the Unix signal that occurred and a pointer to the sigevent that
happened or will happen. That is, events are kept in a linked list in increasing-time order. Scsh's structure

sigevents provides various procedures to accessthis list:

(most-recent-sigevent) -! sigevent procedure

Returns the most recent sigevent -- the head of the sigevent list.

(sigevent? object) -! boolean procedure

The predicate for sigevents.

(next-sigevent pre-event type) -! event procedure

Returns the next sigevent of type type after sigevent pre-event. If no suchevent exists, the procedure blocks.

(next-sigevent-set pre-event set) -! event procedure

Returns the next sigevent whose type is in set after pre-event. If no suchevent exists, the procdure blocks.

(next-sigevent/no-wait pre-event type) -! event or #f procedure

Same as next-sigevent, but returns #fif no appropriate event exists.

(next-sigevent-set/no-wait set pre-event) -! event or #f procedure

Same as next-sigevent-set, but returns #fif no appropriate event exists.
As a small example, consider this piece of code that toggles the variable
state by USR1 and USR2:

(define state #t)
(let lp ((sigevent (most-recent-sigevent)))

(let ((next (next-sigevent sigevent interrupt/usr1)))

(set! state #f)
(let ((next (next-sigevent next interrupt/usr2)))

(set! state #t)
(lp next))))

Warning: The current version of scsh also defines asynchronous handlersfor interrupts (See Section @ref{3.9}). The default action of some of these handlers is
to terminate the process in which case you will most likely not see an effect ofthe synchronous event interface described here. It is therefore recommended to
disable the corresponding interrupt handler using (set-interrupt-handler
interrupt #f).

159

@section Interaction between threads and process state

In Unix, a number of resources are global to the process: signal handlers, work-ing directory, umask, environment, user and group ids. Modular programming is difficult in the context of this global state and for concurrent program-ming things get even worse. Section @ref{9.4} presents how scsh turns the global,
asynchronous signals handlers into modular, synchronous sigevents. Concur-rent programming also benefit from sigevents as every thread may chase down
the sigevent chain separately.

Scsh treats the working directory, umask, environment, and the effectiveuser/group ID as thread-local resources. The initial value of the resources is

determined by the way a thread is started: spawn assigns the initial valueswhereas

fork-thread adopts the values of its parent. Here is a detailed de-scription of the whole facility:

* The procedures to access and modify the resources remain as describedin the previous chapters (

cwd and chdir, umask and set-umask, getenvand
putenv).

* Every thread receives its own copy of each resource.

* If spawn is used to start a new thread, the values of the resources are thesame as they where at the start of scsh.

* The procedure
(fork-thread thunk) -! undefined procedure

from the structure thread-fluids starts a thread which inherits the val-ues of all resources from its parent. This behaviour is similar to what

happens at process forking.

* The actual process state is updated only when necessary, i.e. on access ormodification but not on context switch from one thread to another.

(spoon thunk) -! undefined procedure

This is just an alias for fork-thread suggested by Alan Bawden.
For user and group identities arbitrary changing is not possible. There-fore they remain global process state: If a thread changes one of these values, all other threads see the new value. Consequently, scsh does not provide
with-uid and friends.

@node Miscellaneous routines
@c    Node name, Next, Previous, Up
@chapter Miscellaneous routines

@section Integer bitwise ops

(arithmetic-shift i j) -! integer procedure
(bitwise-and i j) -! integer procedure
(bitwise-ior i j) -! integer procedure
(bitwise-not i) -! integer procedure
(bitwise-xor i j) -! integer procedure

These operations operate on integers representing semi-infinite bitstrings, using a 2's-complement encoding.

arithmetic-shift shifts i by j bits. A left shift is j > 0; a right shift is
j < 0.

@section Password encryption

(crypt key salt) -! encrypted value procedure
Decrypts key by directly calling the crypt function using salt to perturb thehashing algorithm. Salt must be a two-character string consisting of digits,

alphabetic characters, "." or "\". The length of key may be at most eight.

@section Dot-Locking

Section @ref{3.2.8} already points out that @acronym{POSIX}'s file locks are almost useless inpractice. To bypass this restriction other advisory locking mechanisms, based
only on standard file operations, where invented. One of them is the so-called

161

dot-locking scheme where the lock of file-name is represented by the file file-name

.lock. Care is taken that only one process may generate the lock for agiven file.

Here is scsh's interface to dot-locking:
(obtain-dot-lock file-name [interval retry-number stale-time]) -! boolean procedure

Tries to obtain the lock for file-name. If the file is already locked, the threadsleeps for interval seconds (default is 1) before it retries. If the lock cannot

be obtained after retry-number attempts, the procedure returns #f, other-wise

#t. The default value of retry-number is #f which corresponds to aninfinite number of retires.

If stale-time is non-#f, it specifies the minimum age a lock may have(in seconds) before it is considered stale.

Obtain-dot-lock attempts todelete stale locks. If it was succcessful obtaining a lock after breaking

it, obtain-dot-lock returns broken. If stale-time is #f, obtain-dot-locknever considers a lock stale. The default for stale-time is 300.

Note that it is possible that obtain-dot-lock breaks a lock but never-theless fails to obtain it otherwise. If it is necessary to handle this case
specially, use break-dot-lock directly (see below) rather than specifyinga non#f stale-time

(break-dot-lock file-name) -! undefined procedure

Breaks the lock for file-name if one exists. Note that breaking a lockdoes not imply a subsequent

obtain-dot-lock will succeed, as an-other party may have acquired the lock between

break-dot-lock and
obtain-dot-lock.

(release-dot-lock file-name) -! boolean procedure

Releases the lock for file-name. On success, release-dot-lock returns #t,otherwise

#f. Note that this procedure can also be used to break the lockfor file-name.

(with-dot-lock* file-name thunk) -! value(s) of thunk procedure
(with-dot-lock file-name body . . . ) -! value(s) of body syntax

The procedure with-dot-lock* obtains the requested lock, and then calls
(thunk). When thunk returns, the lock is released. A non-local exit (e.g.,throwing to a saved continuation or raising an exception) also causes the

lock to be released.
After a normal return from thunk, its return values are returned by
with-dot-lock*. The with-dot-lock special form is equivalent syntac-tic sugar.

162

@section Syslog facility

(Note: the functionality presented in this section is still somewhat experimentaland thus subject to interface changes.)

The procedures in this section provide access to the 4.2BSD syslog facil-ity present in most @acronym{POSIX} systems. The functionality is in a structure called
syslog. There's an additional structure syslog-channels documented below.The scsh interface to the syslog facility differs significantly from that of the
Unix library functionality in order to support multiple simultaneous connec-tions to the syslog facility.

Log messages carry a variety of parameters beside the text of the messageitself, namely a set of options controlling the output format and destination,
the facility identifying the class of programs the message is coming from, anidentifier specifying the conrete program, and the level identifying the importance of the message. Moreover, a log mask can prevent messages at certainlevels to be actually sent to the syslog daemon.

Log options
A log option specifies details of the I/O behavior of the syslog facility. A syslogoption is an element of a finite type (see the Scheme 48 manual) constructed by
the syslog-option macro. The syslog facility works with sets of options whichare represented as enum sets (see the Scheme 48 manual).

(syslog-option option-name) -! option syntax
(syslog-option? x) -! boolean procedure
(make-syslog-options list) -! options procedure
(syslog-options option-name . . . ) -! options syntax
(syslog-options? x) -! boolean procedure

Syslog-option constructs a log option from the name of an option. (Thepossible names are listed below.)

Syslog-option? is a predicate for logoptions. Options are comparable using

eq?. Make-syslog-options con-structs a set of options from a list of options.

Syslog-options is a macrowhich expands into an expression returning a set of options from names.

Syslog-options? is a predicate for sets of options.
Here is a list of possible names of syslog options:

console If syslog cannot pass the message to syslogd it will attempt to writethe message to the console.

163

delay Delay opening the connection to syslogd immediately until the firstmessage is logged.
no-delay Open the connection to syslogd immediately. Normally the open isdelayed until the first message is logged. Useful for programs that need

to manage the order in which file descriptors are allocated.
NOTA BENE: The delay and no-delay options are included for com-pleteness, but do not have the expected effect in the present Scheme interface: Because the Scheme interface has to multiplex multiple simulta-neous connections to the syslog facility over a single one, open and close
operations on that facility happen at unpredictable times.
log-pid Log the process id with each message: useful for identifying instanti-ations of daemons.

Log facilities
A log facility identifies the originator of a log message from a finite set knownto the system. Each originator is identified by a name:

(syslog-facility facility-name) -! facility syntax
(syslog-facility? x) -! boolean procedure

Syslog-facility is macro that expands into an expression returning afacility for a given name.

Syslog-facility? is a predicate for facilities.Facilities are comparable via

eq?.

Here is a list of possible names of syslog facilities:

authorization The authorization system: login, su, getty, etc.
cron The cron daemon.
daemon System daemons, such as routed, that are not provided for explicitlyby other facilities.

kernel Messages generated by the kernel.
lpr The line printer spooling system: lpr, lpc, lpd, etc.
mail The mail system.
news The network news system.
user Messages generated by random user processes.
uucp The uucp system.
local0 local1 local2 local3 local4 local5 local6 local7 Reserved for lo-cal use.

164

Log levels
A log level identifies the importance of a message from a fixed set of possiblelevels.

(syslog-level level-name) -! level syntax
(syslog-level? x) -! boolean procedure

Syslog-level is macro that expands into an expression returning a facil-ity for a given name.

Syslog-level? is a predicate for facilities. Levelsare comparable via
eq?.

Here is a list of possible names of syslog levels:

emergency A panic condition. This is normally broadcast to all users.
alert A condition that should be corrected immediately, such as a corruptedsystem database.

critical Critical conditions, e.g., hard device errors.
error Errors.
warning Warning messages.
notice Conditions that are not error conditions, but should possibly be han-dled specially.

info Informational messages.
debug Messages that contain information normally of use only when debug-ging a program.

Log masks
A log masks can mask out log messages at a set of levels. A log mask is anenum set of log levels.

(make-syslog-mask list) -! mask procedure
(syslog-mask level-name . . . ) -! mask syntax
syslog-mask-all mask
(syslog-mask-upto level) -! mask procedure
(syslog-mask? x) -! boolean procedure

Make-syslog-mask constructs a mask from a list of levels. Syslog-mask isa macro which constructs a mask from names of levels.

Syslog-mask-allis a predefined log mask containing all levels.
Syslog-mask-upto returnsa mask consisting of all levels up to and including a certain level, starting

with emergency.

165

Logging
Scheme 48 dynamically maintains implicit connections to the syslog facilityspecifying a current identifier, current options, a current facility and a current
log mask. This implicit connection is held in a thread fluid (see Section @ref{9.5}).Hence, every thread maintains it own implicit connection to syslog. Note that
the connection is not implicitly preserved across a spawn, but it is preservedacross a

fork-thread:

(with-syslog-destination string options facility mask thunk) -! value procedure
(set-syslog-destination! string options facility mask) -! undefined procedure

With-syslog-destination dynamically binds parameters of the im-plicit connection to the syslog facility and runs thunk within those

parameter bindings, returning what thunk returns. Each of the pa-rameters may be

#f in which case the previous values will be used.
Set-syslog-destination! sets the parameters of the implicit connectionof the current thread.

(syslog level message) -! undefined procedure
(syslog level message [string options syslog-facility]) -! undefined procedure

Syslog actually logs a message. Each of the parameters of the implicitconnection (except for the log mask) can be explicitly specified as well

for the current call to syslog, overriding the parameters of the channel.The parameters revert to their original values after the call.

Syslog channels
The syslog-channels structure allows direct manipulation of syslog channels,the objects that represent connections to the syslog facility. Note that it is not
necessary to explicitly open a syslog channel to do logging.
(open-syslog-channel string options facility mask) -! channel procedure
(close-syslog-channel channel) -! undefined procedure
(syslog level message channel) -! undefined procedure

Open-syslog-channel and close-syslog-channel create and destroy aconnection to the syslog facility, respectively. The specified form of calling syslog logs to the specified channel.

166

@section MD5 interface

Scsh provides a direct interface to the MD5 functions to compute the "finger-print" or "message digest" of a file or string. It uses the C library written by
Colin Plum.
(md5-digest-for-string string) -! md5-digest procedure

Calculates the MD5 digest for the given string.

(md5-digest-for-port port [buffer-size]) -! md5-digest procedure

Reads the contents of the port and calculates the MD5 digest for it.The optional argument buffer-size determines the size of the port's input

buffer in bytes. It defaults to 1024 bytes.
(md5-digest? thing) -! boolean procedure

The type predicate for MD5 digests: md5-digest? returns true if and onlyif thing is a MD5 digest.

(md5-digest->number md5-digest) -! number procedure

Returns the number corresponding to the MD5 digest.

(number->md5-digest number) -! md5-digest procedure

Creates a MD5 digest from a number.

(make-md5-context) -! md5-context procedure
(md5-context? thing) -! boolean procedure
(update-md5-context! md5-context string) -! undefined procedure
(md5-context->md5-digest md5-context) -! md5-digest procedure

These procedures provide a low-level interface to the library. Amd5-context stores the state of a MD5 computation, it is created by

make-md5-context, its type predicate is md5-context?. The pro-cedure

update-md5-context! extends the md5-context by the givenstring. Finally,

md5-context->md5-digest returns the md5-digest for themd5-context. With these procedures it is possible to incrementally add

strings to a md5-context before computing the digest.

@section Configuration variables

This section describes procedures to access the configuration parameters usedto compile scsh and flags needed to build C extensions for scsh.

(host) -! string procedure

167

(machine) -! string procedure
(vendor) -! string procedure
(os) -! string procedure

These procedures return the description of the host, scsh was built on, asdetermined by the script

config.guess.

(prefix) -! string procedure
(exec-prefix) -! string procedure
(bin-dir) -! string procedure
(lib-dir) -! string procedure
(include-dir) -! string procedure
(man-dir) -! string procedure

These procedures return the various directories of the scsh installation.

(lib-dirs-list) -! symbol list procedure

Returns the default list of library directories. See Section @ref{11.1.5} for moreinformation about the library search facility.

(libs) -! string procedure
(defs) -! string procedure
(cflags) -! string procedure
(cppflags) -! string procedure
(ldflags) -! string procedure

The values returned by these procedures correspond to the values makeused to compile scsh's C files.

(compiler-flags) -! string procedure

The procedure compiler-flags returns flags suitable for running the C com-piler when compiling a C file that uses scsh's foreign function interface.

(linker-flags) -! string procedure

Scsh also comes as a library that can be linked into other programs. Theprocedure linker-flags returns the appropriate flags to link the scsh library to another program.

@node Running scsh
@c    Node name, Next, Previous, Up
@chapter Running scsh

Scsh is currently implemented on top of Scheme 48, a freely-available Schemeimplementation written by Jonathan Rees and Richard Kelsey. Scheme 48 uses
a byte-code interpreter for good code density, portability and medium effi-ciency. It is R5RS. It also has a module system designed by Jonathan Rees.

Scsh's design is not Scheme 48 specific, although the current implementa-tion is necessarily so. Scsh is intended to be implementable in other Scheme
implementations. The Scheme 48 virtual machine that scsh uses is a speciallymodified version; standard Scheme 48 virtual machines cannot be used with
the scsh heap image.

There are several different ways to invoke scsh. You can run it as aninteractive Scheme system, with a standard read-eval-print interaction loop.

Scsh can also be invoked as the interpreter for a shell script by putting a"

#!/usr/local/bin/scsh -s" line at the top of the shell script.

Descending a level, it is also possible to invoke the underlying virtual ma-chine byte-code interpreter directly on dumped heap images. Scsh programs

can be pre-compiled to byte-codes and dumped as raw, binary heap images.Writing heap images strips out unused portions of the scsh runtime (such as
the compiler, the debugger, and other complex subsystems), reducing memorydemands and saving loading and compilation times. The heap image format
allows for an initial #!/usr/local/lib/scsh/scshvm trigger on the first lineof the image, making heap images directly executable as another kind of shell
script.

Finally, scsh's static linker system allows dumped heap images to be com-piled to a raw Unix a.out(5) format, which can be linked into the text section of

the vm binary. This produces a true Unix executable binary file. Since the bytecodes comprising the program are in the file's text section, they are not traced
or copied by the garbage collector, do not occupy space in the vm's heap, and

169

do not need to be loaded and linked at startup time. This reduces the program'sstartup time, memory requirements, and paging overhead.

This chapter will cover these various ways of invoking scsh programs.

@section Scsh command-line switches

When the scsh top-level starts up, it scans the command line for switches thatcontrol its behaviour. These arguments are removed from the command line;
the remaining arguments can be accessed as the value of the scsh variable
command-line-arguments.

@subsection Scripts and programs

The scsh command-line switches provide sophisticated support for the authorsof shell scripts and programs; they also allow the programmer to write programs that use the Scheme 48 module system.

There is a difference between a script, which performs its action as it isloaded, and a program, which is loaded/linked, and then performs its action

by having control transferred to an entry point (e.g., the main() function in Cprograms) that was defined by the load/link operation.

A script, by the above definition, cannot be compiled by the simple mecha-nism of loading it into a scsh process and dumping out a heap image--it executes as it loads. It does not have a top-level main()-type entry point.

It is more flexible and useful to implement a system as a program than as ascript. Programs can be compiled straightforwardly; they can also export procedural interfaces for use by other Scheme packages. However, scsh supportsboth the script and the program style of programming.

@subsection Inserting interpreter triggers into scsh programs

When Unix tries to execute an executable file whose first 16 bits are the charac-ter pair "

#!", it treats the file not as machine-code to be directly executed by thenative processor, but as source code to be executed by some interpreter. The

interpreter to use is specified immediately after the "#!" sequence on the firstline of the source file (along with one optional initial argument). The kernel
reads in the name of the interpreter, and executes that instead. The interpreteris passed the source filename as its first argument, with the original arguments
following. Consult the Unix man page for the exec system call for more infor-mation.

170

Scsh allows Scheme programs to have these triggers placed on their firstline. Scsh treats the character sequence "

#!" as a block-comment sequence,1and skips all following characters until it reads the comment-terminating

sequence newline/exclamation-point/sharp-sign/newline (i.e., the sequence"

!#" occurring on its own line).

In this way, the programmer can arrange for an initial

#!/usr/local/bin/scsh -s
!#

header appearing in a Scheme program to be ignored when the program isloaded into scsh.

@subsection Module system

Scsh uses the Scheme 48 module system, which defines packages, structures, andinterfaces.

Package A package is an environment--that is, a set of variable/value bind-ings. You can evaluate Scheme forms inside a package, or load a file into a

package. Packages export sets of bindings; these sets are called structures.
Structure A structure is a named view on a package--a set of bindings. Otherpackages can open the structure, importing its bindings into their environment. Packages can provide more than one structure, revealing differentportions of the package's environment.

Interface An interface is the "type" of a structure. An interface is the set ofnames exported by a structure. These names can also be marked with

other static information (e.g., advisory type declarations, or syntax infor-mation).

More information on the the Scheme 48 module system can be found in the file
module.ps in the doc directory of the Scheme 48 and scsh releases.

Programming Scheme with a module system is different from program-ming in older Scheme implementations, and the associated development problems are consequently different. In Schemes that lack modular abstractionmechanisms, everything is accessible; the major problem is preventing namespace conflicts. In Scheme 48, name-space conflicts vanish; the major problemis that not all bindings are accessible from every place. It takes a little extra
work to specify what packages export which values.

1 Why a block-comment instead of an end-of-line delimited comment? See the section on metaargs.

171

It may take you a little while to get used to the new style of program devel-opment. Although scsh can be used without referring to the module system at
all, we recommend taking the time to learn and use it. The effort will pay offin the construction of modular, factorable programs.

Module warning
Most scsh programs will need to import from the scheme structure as well asfrom the

scsh structure. However, putting both of these structures in the same
open clause is a bad idea because the structures scheme and scsh export somenames of I/O functions in common but with different definitions. The current

implementation of the module system does not recognize this as an error butsilently overwrites the exports of one structure with the exports of the other. If
the scheme structure overwrites the exports of the scsh structures the programwill access the R

5RS definitions of the I/O functions which is not what you

want.

Previous versions of this manual suggested to list scheme and scsh in a spe-cific order in the

open clause of a structure to ensure that the definitions from
scsh overwrite the ones from scheme. This approach is error-prone and frag-ile: A simple change in the implementation of the module system will render

thousands of programs useless. Starting with release 0.6.3 scsh provides a bet-ter means to deal with this problem: the structure

scheme-with-scsh providesall the exports of the modules
scheme and scsh but exports the right denota-tions for the I/O functions in question. To make a long story short:

Scsh programs should open the structure scheme-with-scsh if they needaccess to the exports of

scheme and scsh.

For programs which should run in versions of scsh prior to release 0.6.3,programmers should make sure to always put the

scsh reference first.

@subsection Library directories search facility

Scsh's command line switches allow loading of code not present in the scriptfile or the heap image at startup. To relief the user from specifying full path
names and to improve flexibility, scsh offers the library directories path list.This list contains directories in which scsh searches automatically for a file
name argument of the -ll or -le switch.

This section describes the programmatic interface to the library directoriessearch facility. In addition, various command line switches for scsh modify

the library directories path list. Section @ref{11.1.5} describes these switches and theswitches to actually load files.

172

Another way to change the library directories path list is the environmentvariable

$SCSH LIB DIRS. If this variable is set, scsh uses it to set library direc-tories path list. The value of this environment variable is treated as a sequence

of s-expressions, which are "read" from the string:

* A string is treated as a directory,

* #f is replaced with the default list of directories.

A $SCSH LIB DIRS assignment of this form
SCSH_LIB_DIRS='"." "/usr/contrib/lib/scsh/" #f "/home/shivers/lib/scsh"'
would produce this list of strings for the library-directories list:

("." "/usr/contrib/lib/scsh/"
"/usr/local/lib/scsh/modules/"
"/home/shivers/lib/scsh")

It is a startup error if reading the $SCSH LIB DIRS environment variable causesa read error, or produces a value that isn't a list of strings or

#f.

default-lib-dirs string list

The default list of library directories. The original value of this variableis

("$prefix/lib/scsh/modules/"). starting with version 0.6.5 the op-tion

--with-lib-dirs-list of the configure script changes for a newinstallation.

(find-library-file file lib-dirs script-file) -! undefined procedure

Searches the list of library directories lib-dirs for file and returns the fullpath. The variable script-file is used to resolve references to the directory

of the current script.
When searching for a directory containing a given library module, nonex-istent or read-protected directories are silently ignored; it is not an error

to have them in the library-directories list.
Directory search can be recursive. A directory name that ends with aslash is recursively searched.

(lib-dirs) -! string list procedure

Returns the current library directories path list.

(lib-dirs-prepend-script-dir!) -! undefined procedure
(lib-dirs-append-script-dir!) -! undefined procedure

173

Add the directory of the current script file to the beginning or end of thelibrary-directories path list, respectively.
(lib-dirs-append! dir) -! undefined procedure
(lib-dirs-prepend! dir) -! undefined procedure

Add directory lib-dir to the beginning or end of the library-directories pathlist, respectively.

(clear-lib-dirs!) -! undefined procedure

Set the library-directories path list to the empty list.

(reset-lib-dirs!) -! undefined procedure

Set the library-directories path list to system default, i.e. to the value ofdefault-lib-dirs.

@subsection Switches

The scsh top-level takes command-line switches in the following format:

scsh [meta-arg] [switchi ...] [end-option arg1 ... argn]
where

174

meta-arg: \ script-file-name
switch: -e entry-point Specify top-level entry-point.

-o structure Open structure in current package.
-m structure Switch to package.
-n new-package Switch to new package.

-lm module-file-name Load module into config package.
-le exec-file-name Load module into exec package.
-l file-name Load file into current package.
-ll module-file-name As in -lm, but search the library path list.
-lel exec-file-name As in -le, but search the library path list.
+lp dir Add dir to front of library path list.
lp+ dir Add dir to end of library path list.
+lpe dir +lp, with env var and ~user expansion.
lpe+ dir lp+, with env var and ~user expansion.
+lpsd Add script-file's dir to front of path list.
lpsd+ Add script-file's dir to end of path list.
-lp-clear Clear library path list to ().
-lp-default Reset library path list to system default.
-ds Do script.
-dm Do script module.
-de Do script exec.

end-option: -s script

-sfd num
-c exp
--

These command-line switches essentially provide a little linker language forlinking a shell script or a program together with Scheme 48 modules or Scheme 48 exec programs 2. The command-line processor serially opens structures andloads code into a given package. Switches that side-effect a package operate
on a particular "current" package; there are switches to change this package.(These switches provide functionality equivalent to the interactive

,open ,load
,in and ,new commands.) Except where indicated, switches specify actionsthat are executed in a left-to-right order. The initial current package is the user

package, which is completely empty and opens (imports the bindings of) theR5RS and scsh structures.

If the Scheme process is started up in an interactive mode, then the cur-rent package in force at the end of switch scanning is the one inside which the
2See the Section "Command programs" in the Scheme 48 manual for a description of the exec
language.

175

interactive read-eval-print loop is started.

The command-line switch processor works in two passes: it first parses theswitches, building a list of actions to perform, then the actions are performed

serially. The switch list is terminated by one of the end-option switches. Thearg

i arguments occurring after an end-option switch are passed to the scsh pro-gram as the value of command-line-arguments and the tail of the list returned

by (command-line). That is, an end-option switch separates switches that con-trol the scsh "machine" from the actual arguments being passed to the scsh

program that runs on that machine.

The following switches and end options are defined:

* -o structOpen the structure in the current package.

* -n packageMake and enter a new package. The package has an associated structure

named package with an empty export list. If package is the string "#f", thenew package is anonmyous, with no associated named structure.

The new package initially opens no other structures, not even the R5RSbindings. You must follow a "

-n foo" switch with "-o scheme" to accessthe standard identifiers such as

car and define.

* -m structChange the current package to the package underlying structure struct.

(The -m stands for "module.")

* -lm module-file-nameLoad the specified file into scsh's config package -- the file must contain

source written in the Scheme 48 module language ("load module"). Doesnot alter the current package.

* -le exec-file-nameLoad the specified file into scsh's exec package -- the file must contain

source written in the Scheme 48 exec language ("load exec"). Does notalter the current package.

* -l file-nameLoad the specified file into the current package.

* -c expEvaluate expression exp in the current package and exit. This is called

-c after a common shell convention (see sh and csh). The expression isevaluated in the the current package (and hence is affected by

-m's and
-n's.)

176

When the scsh top-level constructs the scsh command-line in this case, ittakes

"scsh" to be the program name. This switch terminates argumentscanning; following args become the tail of the command-line list.

* -e entry-pointSpecify an entry point for a program. The entry-point is a variable that

is taken from the current package in force at the end of switch evalua-tion. The entry point does not have to be exported by the package in a
structure; it can be internal to the package. The top level passes control tothe entry point by applying it to the command-line list (so programs executing in private packages can reference their command-line argumentswithout opening the

scsh package to access the (command-line) proce-dure). Note that, like the list returned by the

(command-line) procedure,the list passed to the entry point includes the name of the program being

executed (as the first element of the list), not just the arguments to theprogram.

A -e switch can occur anywhere in the switch list, but it is the last actionperformed by switch scanning if it occurs. (We violate ordering here as
the shell-script #! mechanism prevents you from putting the -e switchlast, where it belongs.)

* -s scriptSpecify a file to load. A

-ds (do-script), -dm (do-module), or -de (do-exec)switch occurring earlier in the switch list gives the place where the script

should be loaded. If there is no -ds, -dm, or -de switch, then the script isloaded at the end of switch scanning, into the module that is current at
the end of switch scanning.
We use the -ds switch to violate left-to-right switch execution order as the
-s switch is required to be last (because of the #! machinery), independentof when/where in the switch-processing order it should be loaded.

When the scsh top-level constructs the scsh command-line in this case,it takes script to be the program name. This switch terminates switch
parsing; following args are ignored by the switch-scanner and are passedthrough to the program as the tail of the command-line list.

* -sfd numLoads the script from file descriptor num. This switch is like the

-sswitch, except that the script is loaded from one of the process' open input file descriptors. For example, to have the script loaded from standardinput, specify

-sfd 0.

* --Terminate argument scanning and start up scsh in interactive mode.

If the argument list just runs out, without either a terminating -s or

177

-- arg, then scsh also starts up in interactive mode, with an empty
command-line-arguments list (for example, simply entering scsh at ashell prompt with no args at all).

When the scsh top-level constructs the scsh command-line in this case,it takes

"scsh" to be the program name. This switch terminates switchparsing; following args are ignored by the switch-scanner and are passed

through to the program as the tail of the command-line list.

* -dsSpecify when to load the script ("do-script"). If this switch occurs, the

switch list must be terminated by a -s script switch. The script is loadedinto the package that is current at the

-ds switch.

* -dmAs above, but the current module is ignored. The script is loaded into the

config package ("do-module"), and hence must be written in the Scheme48 module language. This switch doesn't affect the current module--
after executing this switch, the current module is the same as as it wasbefore.

This switch is provided to make it easy to write shell scripts in the Scheme48 module language.

* -deAs above, but the current module is ignored. The script is loaded into the

exec package ("do-exec"), and hence must be written in the Scheme 48exec language.

This switch is provided to make it easy to write shell scripts in the Scheme48 exec language.

* -ll module-file-name

Load library module into config package. This is just like the -lm switch,except that it searches the library-directory path list (see Section @ref{11.1.4})
for the file to load.
Specifically, it means: search through the library-directories list of directo-ries looking for a module file of the given name, and load it in. Scsh uses

the procedure find-library-file from Section @ref{11.1.4} to perform the search.

* -lel exec-file-nameAs above, but load the specified file into scsh's exec package. This is just

like the -le switch, except that it searches the library-directory path listfor the file to load.

178

* +lp lib-dir,lp+ lib-dirAdd directory lib-dir to the beginning or end of the library-directories path

list, respectively.
lib-dir is a single directory. It is not split at colons or otherwise processed.These switches correspond to the procedures

lib-dirs-prepend! and
lib-dirs-append! from Section @ref{11.1.4}.

* +lpe, lpe+As above, except that ~home-directory syntax and environment variables

are expanded out.

* +lpsd,lpsd+Add script-file's directory to the beginning or end of the library-directories

path list, respectively. These switches correspond to the procedures
lib-dirs-prepend-script-dir! and lib-dirs-append-script-dir!from Section @ref{11.1.4}.

* -lp-clear, -lp-defaultSet the library-directories path list to the empty list and the system

default, respectively. These switches correspond to the procedures
clear-lib-dirs! and reset-lib-dirs! from Section @ref{11.1.4}.

The two switches are useful if you would like to protect your script frominfluence by the

$SCSH LIB DIRS variable.

In these cases, the $SCSH LIB DIRS environment variable is never evenparsed, so a bogus value will not affect the script's execution at all.

@subsection The meta argument

The scsh switch parser takes a special command-line switch, a single back-slash called the "meta-argument," which is useful for shell scripts. If the initial
command-line argument is a "\" argument, followed by a filename argumentfname, scsh will open the file fname and read more arguments from the second
line of this file. This list of arguments will then replace the "\" argument--i.e., the new arguments are inserted in front of fname, and the argument parser
resumes argument scanning. This is used to overcome a limitation of the #!feature: the

#! line can only specify a single argument after the interpreter. Forexample, we might hope the following scsh script,

ekko, would implement asimple-minded version of the Unix
echo program:

179

#!/usr/local/bin/scsh -e main -s
!#
(define (main args)

(map (* (arg) (display arg) (display " "))

(cdr args))
(newline))

The idea would be that the command

ekko Hi there.
would by expanded by the exec(2) kernel call into

/usr/local/bin/scsh -e main -s ekko Hi there.
In theory, this would cause scsh to start up, load in file ekko, call the entry pointon the command-line list

(main '("ekko" "Hi" "there."))
and exit.

Unfortunately, the Unix exec(2) syscall's support for scripts is not verygeneral or well-designed. It will not handle multiple arguments; the

#! lineis usually required to contain no more than 32 characters; it is not recursive.

If these restrictions are violated, most Unix systems will not provide accurateerror reporting, but either fail silently, or simply incorrectly implement the desired functionality. These are the facts of Unix life.

In the ekko example above, our #! trigger line has three arguments ("-e","
main", and "-s"), so it will not work. The meta-argument is how we workaround this problem. We must instead invoke the scsh interpreter with the single \ argument, and put the rest of the arguments on line two of the program.Here's the correct program:

#!/usr/local/bin/scsh \
-e main -s
!#
(define (main args)

(map (* (arg) (display arg) (display " "))

(cdr args))
(newline))

Now, the invocation starts as

ekko Hi there.
and is expanded by exec(2) into

/usr/local/bin/scsh \ ekko Hi there.

180

When scsh starts up, it expands the "\" argument into the arguments read fromline two of

ekko, producing this argument list:

-e main -s ekko Hi there."
Expanded from \ ekko
With this argument list, processing proceeds as we intended.

Secondary argument syntax
Scsh uses a very simple grammar to encode the extra arguments on the secondline of the scsh script. The only special characters are space, tab, newline, and
backslash.

* Each space character terminates an argument. This means that twospaces in a row introduce an empty-string argument.

* The tab character is not permitted (unless you quote it with the backslashcharacter described below). This is to prevent the insidious bug where

you believe you have six space characters, but you really have a tab char-acter, and vice-versa.

* The newline character terminates an argument, like the space character,and also terminates the argument sequence. This means that an empty

line parses to the singleton list whose one element is the empty string:
(""). The grammar doesn't admit the empty list.

* The backslash character is the escape character. It escapes backslash,space, tab, and newline, turning off their special functions, and allowing them to be included in arguments. The @acronym{ANSI} C escape sequences(

\b, \n, \r and \t) are also supported; these also produce argument-constituents--

\n doesn't act like a terminating newline. The escape se-quence
\nnn for exactly three octal digits reads as the character whoseA
SCII code is nnn. It is an error if backslash is followed by just one or twooctal digits:

\3Q is an error. Octal escapes are always constituent chars.Backslash followed by other chars is not allowed (so we can extend the

escape-code space later if we like).
You have to construct these line-two argument lines carefully. In particular,beware of trailing spaces at the end of the line--they'll give you extra trailing
empty-string arguments. Here's an example:

#!/bin/interpreter \
foo bar quux\ yow

181

would produce the arguments

("foo" "bar" "" "quux yow")

@subsection Examples

* scsh -dm -m myprog -e top -s myprog.scmLoad

myprog.scm into the config package, then shift to the myprog pack-age and call

(top '("myprog.scm")), then exit. This sort of invocationis typically used in

#! script lines (see below).

* scsh -c '(display "Hello, world.")'A simple program.

* scsh -o bigschemeStart up interactively in the user package after opening structure

bigscheme.

* scsh -o bigscheme -- Three args passedStart up interactively in the user package after opening

bigscheme. The
command-line-args variable in the scsh package is bound to the list
("Three" "args" "passed"), and the (command-line) procedure re-turns the list

("scsh" "Three" "args" "passed").

* Program ekkoThis shell script, called

ekko, implements a version of the Unix echo pro-gram:

#!/usr/local/bin/scsh -s
!#
(for-each (* (arg) (display arg) (display " "))

command-line-args)

Note this short program is an example of a script--it executes as it loads.The Unix rule for executing

#! shell scripts causes

ekko Hello, world.
to expand as

/usr/local/bin/scsh -s ekko Hello, world.

* Program ekkoThis is the same program, not as a script. Writing it this way makes it

possible to compile the program (and then, for instance, dump it out as aheap image).

182

#!/usr/local/bin/scsh \
-e top -s
!#
(define (top args)

(for-each (* (arg) (display arg) (display " "))

(cdr args)))

The exec(2) expansion of the #! line together with the scsh expansionof the "

\ ekko" meta-argument (see section @ref{11.1.6}) gives the followingcommand-line expansion:

ekko Hello, world.=)

/usr/local/bin/scsh \ ekko Hello, world.=)
/usr/local/bin/scsh -e top -s ekko Hello, world.

* Program sortThis is a program to replace the Unix

sort utility--sorting lines read fromstdin, and printing the results on stdout. Note that the source code defines a general sorting package, which is useful (1) as a Scheme moduleexporting sort procedures to other Scheme code, and (2) as a standalone
program invoked from the top procedure.

#!/usr/local/bin/scsh \
-dm -m sort-toplevel -e top -s
!#

;;; This is a sorting module. TOP procedure exports
;;; the functionality as a Unix program akin to sort(1).
(define-structures ((sort-struct (export sort-list

sort-vector!))
(sort-toplevel (export top)))
(open scheme)

(begin (define (sort-list elts <=) ...)

(define (sort-vec! vec <=) ...)

;; Parse the command line and
;; sort stdin to stdout.
(define (top args)

...)))

The expansion below shows how the command-line scanner (1) loads theconfig file

sort (written in the Scheme 48 module language), (2) switchesto the package underlying the

sort-toplevel structure, (3) calls (top
'("sort" "foo" "bar")) in the package, and finally (4) exits.

183

sort foo bar
=) /usr/local/bin/scsh \ sort foo bar
=) /usr/local/bin/scsh -dm -m sort-toplevel -e top -s sort foo bar

An alternate method would have used a

-n #f -o sort-toplevel
sequence of switches to specify a top-level package.

Note that the sort example can be compiled into a Unix program by loadingthe file into an scsh process, and dumping a heap with top-level

top. Even ifwe don't want to export the sort's functionality as a subroutine library, it is still

useful to write the sort program with the module language. The command linedesign allows us to run this program as either an interpreted script (given the
#! args in the header) or as a compiled heap image.

@subsection Process exit values

Scsh ignores the value produced by its top-level computation when determin-ing its exit status code. If the top-level computation completed with no errors,
scsh dies with exit code 0. For example, a scsh process whose top-level is spec-ified by a

-c exp or a -e entry entry point ignores the value produced by eval-uating exp and calling entry, respectively. If these computations terminate with

no errors, the scsh process exits with an exit code of 0.

To return a specific exit status, use the exit procedure explicitly, e.g.,

scsh -c \

"(exit (status:exit-val (run (| (fmt) (mail shivers)))))"

@section The scsh virtual machine

To run the Scheme 48 implementation of scsh, you run a specially modifiedcopy of the Scheme 48 virtual machine with a scsh heap image. The scsh binary is actually nothing but a small cover program that invokes the byte-codeinterpreter on the scsh heap image for you. This allows you to simply start
up an interactive scsh from a command line, as well as write shell scripts thatbegin with the simple trigger

#!/usr/local/bin/scsh -s
You can also directly execute the virtual machine, which takes its own setof command-line switches.. For example, this command starts the vm up with

a 1 Mword heap (split into two semispaces):

184

scshvm -o scshvm -h 1000000 -i scsh.image arg1 arg2 ...
The vm peels off initial vm arguments up to the -i heap image argument,which terminates vm argument parsing. The rest of the arguments are

passed off to the scsh top-level. Scsh's top-level removes scsh switches,as discussed in the previous section; the rest show up as the value of
command-line-arguments.

Directly executing the vm can be useful to specify non-standard switches,or invoke the virtual machine on special heap images, which can contain precompiled scsh programs with their own top-level procedures.

@subsection VM arguments

The vm takes arguments in the following form:

scshvm [meta-arg] [vm-options+] [end-option scheme-args]
where

meta-arg: \ filename

vm-option: -h heap-size-in-words

-s stack-size-in-words
-o object-file-name

end-option: -i image-file-name

--

The vm's meta-switch "\ filename" is handled the same as scsh's meta-switch, and serves the same purpose.

VM options
The -o object-file-name switch tells the vm where to find relocation informationfor its foreign-function calls. Scsh will use a pre-compiled default if it is not
specified. Scsh must have this information to run, since scsh's syscall interfacesare done with foreign-function calls.

The -h and -s options tell the vm how much space to allocate for the heapand stack. The heap size value is the total number of words allocated for the
heap; this space is then split into two semi-spaces for Scheme 48's stop-and-copy collector.

185

End options
End options terminate argument parsing. The -i switch is followed by thename of a heap image for the vm to execute. The image-file-name string is also
taken to be the name of the program being executed by the VM; this name be-comes the head of the argument list passed to the heap image's top-level entry
point. The tail of the argument list is constructed from all following arguments.

The -- switch terminates argument parsing without giving a specific heapimage; the vm will start up using a default heap (whose location is compiled

into the vm). All the following arguments comprise the tail of the list passedoff to the heap image's top-level procedure.

Notice that you are not allowed to pass arguments to the heap image's top-level procedure (e.g., scsh) without delimiting them with

-i or -- flags.

@subsection Stripped image

Besides the standard image scsh.image scsh also ships with the muchsmaller image

stripped-scsh.image. This image contains the same codeas the standard image but has almost all debugging information removed.

stripped-scsh.image is intended to be used with standalone programs wherestartup time and memory consumption count but debugging the scheme code
is not that important. To use the image the VM has to be called directly and thepath to the image must be given after the

-i argument.

@subsection Inserting interpreter triggers into heap images

Scheme 48's heap image format allows for an informational header: when thevm loads in a heap image, it ignores all data occurring before the first control-L
character (ASCII 12). This means that you can insert a "#!" trigger line into aheap image, making it a form of executable "shell script." Since the vm requires
multiple arguments to be given on the command line, you must use the meta-switch. Here's an example heap-image header:

#!/usr/local/lib/scsh/scshvm \
-o /usr/local/lib/scsh/scshvm -i
... Your heap image goes here ...

@subsection Inserting a double-level trigger into Scheme programs

If you're a nerd, you may enjoy doing a double-level machine shift in the trig-ger line of your Scheme programs with the following magic:

186

#!/usr/local/lib/scsh/scshvm \
-o /usr/local/lib/scsh/scshvm -i /usr/local/lib/scsh/scsh.image -s
!#
... Your Scheme program goes here ...

@section Compiling scsh programs

Scsh allows you to create a heap image with your own top-level procedure.Adding the pair of lines

#!/usr/local/lib/scsh/scshvm \
-o /usr/local/lib/scsh/scshvm -i

to the top of the heap image will turn it into an executable Unix file.

You can create heap images with the following two procedures.

(dump-scsh-program main fname) -! undefined procedure

This procedure writes out a scsh heap image. When the heap image isexecuted by the Scheme 48 vm, it will call the main procedure, passing

it the vm's argument list. When main returns an integer value i, the vmexits with exit status

i. The Scheme vm will parse command-line switchesas described in section @ref{11.2.1}; remaining arguments form the tail of the

command-line list that is passed to main. (The head of the list is the nameof the program being executed by the vm.) Further argument parsing (as
described for scsh in section @ref{11.1.5}) is not performed.
The heap image created by dump-scsh-program has unused code anddata pruned out, so small programs compile to much smaller heap images.
(dump-scsh fname) -! undefined procedure

This procedure writes out a heap image with the standard scsh top-level.When the image is resumed by the vm, it will parse and execute scsh

command-line switches as described in section @ref{11.1.5}.
You can use this procedure to write out custom scsh heap images thathave specific packages preloaded and start up in specific packages.

Unfortunately, Scheme 48 does not support separate compilation of Schemefiles or Scheme modules. The only way to compile is to load source and then
dump out a heap image. One occasionally hears rumours that this is beingaddressed by the Scheme 48 development team.

187

@section Standard file locations

Because the scshvm binary is intended to be used for writing shell scripts, it isimportant that the binary be installed in a standard place, so that shell scripts
can dependably refer to it. The standard directory for the scsh tree should be
/usr/local/lib/scsh/. Whenever possible, the vm should be located in

/usr/local/lib/scsh/scshvm
and a scsh heap image should be located in

/usr/local/lib/scsh/scsh.image
The top-level scsh program should be located in

/usr/local/lib/scsh/scsh
with a symbolic link to it from

/usr/local/bin/scsh

The Scheme 48 image format allows heap images to have #! triggers, so
scsh.image should have a #! trigger of the following form:

#!/usr/local/lib/scsh/scshvm \
-o /usr/local/lib/scsh/scshvm -i
... heap image goes here ...

@node Index
@c    Node name, Next, Previous, Up
@unnumbered Index

@printindex cp

@c The below procedures will presumably be moved to a separate index
@c file. Or perhaps they need to be moved back into the document? That'll
@c be a pain in the ass.

@c *temp-file-template*, 52
@c ->uid, 64
@c ->username, 64
@c %exec, 55
@c %exit, 55
@c %fork, 56
@c %fork/pipe, 56
@c %fork/pipe+, 57
@c %read-delimited!, 141&, 13

@c &, 13
@c &&, 20

@c reduce-port , 16
@c absolute-file-name, 109
@c accept-connection, 99
@c add-after, 80
@c add-before, 80
@c alist->env, 78
@c alist-compress, 79
@c alist-delete, 78
@c alist-update, 78
@c arg, 65
@c arg*, 65
@c argv, 65
@c arithmetic-shift, 161
@c ascii->char, 110
@c autoreap-policy, 59awk, 151

@c become-session-leader, 87
@c bin-dir, 168
@c bind-listen-accept-loop, 95
@c bind-prepare-listen-accept-loop,95

@c bind-socket, 98
@c bitwise-and, 161
@c bitwise-ior, 161
@c bitwise-not, 161
@c bitwise-xor, 161
@c break-dot-lock, 162
@c bufpol/block, 38
@c bufpol/line, 38
@c bufpol/none, 38

@c call-terminally, 55
@c call-with-string-output-port,26

@c call/fdes, 30
@c cflags, 168
@c char->ascii, 110
@c char-ascii?, 110
@c char-blank?, 110
@c char-digit?, 110
@c char-graphic?, 110
@c char-hex-digit?, 110
@c char-iso-control?, 110
@c char-letter+digit?, 110
@c char-letter?, 110
@c char-lower-case?, 110
@c char-printing?, 110
@c char-punctuation?, 110
@c char-title-case?, 110
@c char-upper-case?, 110
@c char-whitespace?, 110
@c chdir, 62
@c clean-up-cres, 137
@c close, 25
@c close-after, 24
@c close-directory-stream, 47

@c 189

@c close-socket, 95
@c close-syslog-channel, 166
@c command-line, 64command-line-arguments, 64

@c compiler-flags, 168
@c connect-socket, 98
@c connect-socket-no-wait, 98
@c connect-socket-successful?, 98
@c control-tty-file-name, 87
@c copy-tty-info, 84
@c cppflags, 168
@c cpu-ticks/sec, 64
@c create-directory, 41
@c create-fifo, 41
@c create-hard-link, 41
@c create-socket, 95
@c create-socket-pair, 95
@c create-symlink, 41
@c create-temp-file, 51
@c crypt, 161
@c current-thread, 157
@c cwd, 62

@c date, 72
@c date, 74
@c date->string, 75default-lib-dirs, 173

@c define-record, 7
@c defs, 168
@c delete-directory, 42
@c delete-file, 42
@c delete-filesys-object, 42
@c directory-as-file-name, 106
@c directory-files, 46
@c disable-tty-char, 83
@c drain-tty, 85
@c dump-scsh, 187
@c dump-scsh-program, 187
@c dup, 31
@c dup->fdes, 31
@c dup->inport, 31
@c dup->outport, 31

@c enabled-interrupts, 70

@c env->alist, 78
@c errno-error, 21
@c error-output-port, 24
@c exec, 54exec-epf, 13

@c exec-epf, 13
@c exec-path, 54exec-path-list, 81

@c exec-path-search, 55
@c exec-path/env, 54
@c exec-prefix, 168
@c exec/env, 54
@c exit, 55
@c expand-file-name, 109

@c fdes->inport, 30
@c fdes->outport, 30
@c fdes-flags, 32
@c fdes-status, 33
@c field-reader, 148
@c field-splitter, 144
@c file-directory?, 44
@c file-executable?, 46
@c file-exists?, 46
@c file-fifo?, 44
@c file-group, 44
@c file-info, 43
@c file-info-directory?, 45
@c file-info-executable?, 46
@c file-info-fifo?, 45
@c file-info-not-executable?, 46
@c file-info-not-readable?, 46
@c file-info-not-writable?, 46
@c file-info-readable?, 46
@c file-info-regular?, 45
@c file-info-socket?, 45
@c file-info-special?, 45
@c file-info-symlink?, 45
@c file-info-writable?, 46
@c file-info:atime, 43
@c file-info:ctime, 43
@c file-info:device, 43
@c file-info:gid, 43
@c file-info:inode, 43

@c 190

@c file-info:mode, 43
@c file-info:mtime, 43
@c file-info:nlinks, 43
@c file-info:size, 43
@c file-info:type, 43
@c file-info:uid, 43
@c file-inode, 44
@c file-last-access, 44
@c file-last-mod, 44
@c file-last-status-change, 44
@c file-match, 49
@c file-mode, 44
@c file-name-absolute?, 106
@c file-name-as-directory, 105
@c file-name-directory, 106
@c file-name-directory?, 105
@c file-name-extension, 107
@c file-name-non-directory?, 105
@c file-name-nondirectory, 106
@c file-name-sans-extension, 108
@c file-nlinks, 44
@c file-not-executable?, 45
@c file-not-exists?, 46
@c file-not-readable?, 45
@c file-not-writable?, 45
@c file-owner, 44
@c file-readable?, 46
@c file-regular?, 44
@c file-size, 44
@c file-socket?, 44
@c file-special?, 44
@c file-symlink?, 44
@c file-type, 44
@c file-writable?, 46
@c fill-in-date!, 75
@c find-library-file, 173
@c flush-all-ports, 39
@c flush-submatches, 134
@c flush-tty/both, 86
@c flush-tty/input, 86
@c flush-tty/output, 86
@c force-output, 38
@c fork, 56
@c fork-pty-session, 87

@c fork-thread, 160
@c fork/pipe, 56
@c fork/pipe+, 57
@c format-date, 75

@c get-lock-region, 40
@c getenv, 77
@c glob, 47
@c glob-quote, 49
@c group-info, 64
@c group-info:gid, 64
@c group-info:members, 64
@c group-info:name, 64

@c handle-signal-default, 71
@c home-dir, 109home-directory, 81

@c home-file, 109
@c host, 167
@c host-info, 101

@c if-match, 133
@c if-sre-form, 138
@c ignore-signal, 71
@c include-dir, 168
@c infix-splitter, 144
@c internet-address->socket-address,97

@c interrupt-handler, 71
@c interrupt-set, 70
@c interrupt/alarm, 68
@c interrupt/alrm, 68
@c interrupt/chld, 68
@c interrupt/cont, 68
@c interrupt/hup, 68
@c interrupt/info, 68
@c interrupt/int, 68
@c interrupt/io, 68
@c interrupt/keyboard, 68
@c interrupt/memory-shortage, 68
@c interrupt/poll, 68
@c interrupt/prof, 68
@c interrupt/pwr, 68
@c interrupt/quit, 68

@c 191

@c interrupt/term, 68
@c interrupt/tstp, 68
@c interrupt/urg, 68
@c interrupt/usr1, 68
@c interrupt/usr2, 68
@c interrupt/vtalrm, 68
@c interrupt/winch, 68
@c interrupt/xcpu, 68
@c interrupt/xfsz, 68
@c itimer, 67

@c join-strings, 147
@c ldflags, 168
@c let-match, 133
@c lib-dir, 168
@c lib-dirs, 173
@c lib-dirs-list, 168
@c libs, 168
@c linker-flags, 168
@c listen-socket, 99
@c lock-owner-uid, 158
@c lock-region, 40
@c lock-region/no-block, 40
@c lock-region:end, 39
@c lock-region:exclusive?, 39
@c lock-region:len, 39
@c lock-region:proc, 39
@c lock-region:start, 39
@c lock-region:whence, 39
@c lock-region?, 39
@c lock?, 157

@c machine, 168
@c make-char-port-filter, 20
@c make-date, 73
@c make-lock, 157
@c make-lock-region, 40
@c make-md5-context, 167
@c make-placeholder, 158
@c make-pty-generator, 88
@c make-re-char-set, 136
@c make-re-choice, 136
@c make-re-dsm, 136

@c make-re-repeat, 136
@c make-re-seq, 135
@c make-re-string, 136
@c make-re-submatch, 136
@c make-regexp, 129
@c make-string-input-port, 26
@c make-string-output-port, 26
@c make-string-port-filter, 20
@c make-syslog-mask, 165
@c make-syslog-options, 163
@c make-tty-info, 84
@c man-dir, 168
@c match-cond, 133
@c match:end, 130
@c match:start, 130
@c match:substring, 130
@c maybe-obtain-lock, 158
@c md5-context->md5-digest, 167
@c md5-context?, 167
@c md5-digest->number, 167
@c md5-digest-for-port, 167
@c md5-digest-for-string, 167
@c md5-digest?, 167
@c most-recent-sigevent, 159
@c move->fdes, 30

@c network-info, 101
@c next-sigevent, 159
@c next-sigevent-set, 159
@c next-sigevent-set/no-wait, 159
@c next-sigevent/no-wait, 159
@c nice, 63
@c number->md5-digest, 167

@c obtain-dot-lock, 162
@c obtain-lock, 157
@c open-control-tty, 86
@c open-directory-stream, 47
@c open-fdes, 32
@c open-file, 32
@c open-input-file, 32
@c open-output-file, 32
@c open-pty, 88
@c open-syslog-channel, 166

@c 192

@c os, 168
@c parent-pid, 62
@c parse-file-name, 108
@c parse-sre, 138
@c parse-sres, 138
@c path-list->file-name, 107
@c pid, 62
@c pid->proc, 58
@c pipe, 33
@c placeholder-value, 158
@c placeholder?, 158
@c port->fdes, 30
@c port->list, 15
@c port->sexp-list, 15
@c port->socket, 96
@c port->string, 15
@c port->string-list, 15
@c port-fold, 16
@c port-revealed, 30
@c posix-string->regexp, 135
@c prefix, 168
@c priority, 63proc, 58

@c proc:pid, 58proc?, 58
@c process-group, 62
@c process-sleep, 67
@c process-sleep-until, 67
@c process-times, 63
@c protocol-info, 101
@c pty-name->tty-name, 88

@c re-any, 137
@c re-any?, 137re-bol, 136

@c re-bol?, 136re-bos, 136
@c re-bos?, 136
@c re-char-set, 136
@c re-char-set:cset, 136
@c re-char-set?, 136
@c re-choice, 136
@c re-choice:elts, 136

@c re-choice:tsm, 136
@c re-choice?, 136
@c re-dsm, 136
@c re-dsm:body, 136
@c re-dsm:post-dsm, 136
@c re-dsm:pre-dsm, 136
@c re-dsm:tsm, 136
@c re-dsm?, 136re-empty, 137

@c re-empty?, 137re-eol, 136
@c re-eol?, 136re-eos, 136
@c re-eos?, 136re-nonl, 137
@c re-repeat:from, 136
@c re-repeat:to, 136
@c re-repeat:tsm, 136
@c re-repeat?, 136
@c re-seq, 135
@c re-seq:elts, 135
@c re-seq:tsm, 136
@c re-seq?, 135
@c re-string, 136
@c re-string:chars, 136
@c re-string?, 136
@c re-submatch:post-dsm, 136
@c re-submatch:pre-dsm, 136
@c re-submatch:tsm, 136
@c re-submatch?, 136re-trivial, 137

@c re-trivial?, 137
@c re-tsm, 137
@c read-delimited, 141
@c read-delimited!, 141
@c read-directory-stream, 47
@c read-line, 140
@c read-paragraph, 141
@c read-string, 33
@c read-string!, 33
@c read-string!/partial, 34
@c read-string/partial, 34
@c read-symlink, 42
@c reap-zombies, 59

@c 193

@c receive-message, 99
@c receive-message!, 99
@c receive-message!/partial, 99
@c receive-message/partial, 99
@c record-reader, 144
@c regexp->posix-string, 135
@c regexp->scheme, 138
@c regexp->sre, 134
@c regexp-fold, 131
@c regexp-fold-right, 132
@c regexp-for-each, 133
@c regexp-search, 129
@c regexp-search?, 129
@c regexp-substitute, 130
@c regexp-substitute/global, 130
@c regexp?, 129, 137
@c release-dot-lock, 162
@c release-lock, 158
@c release-port-handle, 30
@c relinquish-timeslice, 157
@c rename-file, 42
@c replace-extension, 108
@c resolve-file-name, 109run, 13

@c run, 13
@c run/collecting, 17
@c run/collecting*, 17
@c run/file, 14
@c run/file*, 15
@c run/port, 14
@c run/port*, 15
@c run/port+proc, 17
@c run/port+proc*, 17
@c run/sexp, 14
@c run/sexp*, 15
@c run/sexps, 14
@c run/sexps*, 15
@c run/string, 14
@c run/string*, 15
@c run/strings, 14
@c run/strings*, 15
@c rx, 129

@c seek, 31

@c select , 35
@c select-port-channels, 36
@c select-ports, 36
@c send-message, 99
@c send-message/partial, 99
@c send-tty-break, 85
@c service-info, 101
@c set-enabled-interrupts, 70
@c set-fdes-flags, 32
@c set-fdes-status, 33
@c set-file-group, 42
@c set-file-mode, 42
@c set-file-owner, 42
@c set-file-times, 42
@c set-gid, 63
@c set-interrupt-handler, 70
@c set-port-buffering, 38
@c set-priority, 63
@c set-process-group, 62
@c set-socket-option, 100
@c set-tty-info/drain, 85
@c set-tty-info/flush, 85
@c set-tty-info/now, 85
@c set-tty-process-group, 87
@c set-uid, 63
@c set-umask, 62
@c set-user-effective-gid, 63
@c set-user-effective-uid, 63
@c setenv, 77
@c shutdown-socket, 99
@c sigevent?, 159
@c signal->interrupt, 67
@c signal-process, 67
@c signal-process-group, 67
@c signal/abrt, 69
@c signal/alrm, 68
@c signal/bus, 69
@c signal/chld, 68
@c signal/cont, 68
@c signal/emt, 69
@c signal/fpe, 69
@c signal/hup, 68
@c signal/ill, 69
@c signal/info, 68

@c 194

@c signal/int, 68
@c signal/io, 68
@c signal/iot, 69
@c signal/kill, 69
@c signal/pipe, 69
@c signal/poll, 68
@c signal/prof, 68
@c signal/pwr, 68
@c signal/quit, 68
@c signal/segv, 69
@c signal/stop, 69
@c signal/sys, 69
@c signal/term, 68
@c signal/trap, 69
@c signal/tstp, 68
@c signal/ttin, 69
@c signal/ttou, 69
@c signal/urg, 68
@c signal/usr1, 68
@c signal/usr2, 68
@c signal/vtalrm, 68
@c signal/winch, 68
@c signal/xcpu, 68
@c signal/xfsz, 68
@c simplify-file-name, 109
@c simplify-regexp, 134
@c skip-char-set, 142
@c sleep, 157
@c sloppy-suffix-splitter, 144
@c socket-address->internet-address,97

@c socket-address->unix-address,97
@c socket-connect, 94
@c socket-local-address, 99
@c socket-option, 100
@c socket-remote-address, 99
@c spawn, 156
@c split-file-name, 107
@c spoon, 160
@c sre->regexp, 134
@c sre-form?, 138
@c start-tty-input, 86
@c start-tty-output, 86

@c static-regexp?, 139
@c status:exit-val, 61
@c status:stop-sig, 61
@c status:term-sig, 61
@c stdio->stdports, 25
@c stdports->stdio, 25
@c stop-tty-input, 86
@c stop-tty-output, 86
@c string-match, 129
@c string-output-port-output, 26
@c substitute-env-vars, 110
@c suffix-splitter, 144
@c suspend, 56
@c sync-file, 43
@c sync-file-system, 43
@c syslog, 166
@c syslog-facility, 164
@c syslog-facility?, 164
@c syslog-level, 165
@c syslog-level?, 165
@c syslog-mask, 165syslog-mask-all, 165

@c syslog-mask-upto, 165
@c syslog-mask?, 165
@c syslog-option, 163
@c syslog-option?, 163
@c syslog-options, 163
@c syslog-options?, 163
@c system-name, 66

@c tell, 32
@c temp-file-channel, 53
@c temp-file-iterate, 52
@c terminate-current-thread, 157
@c thread-name, 157
@c thread-uid, 157
@c thread?, 157
@c ticks/sec, 74time, 72

@c time, 75
@c time+ticks, 74
@c truncate-file, 43
@c tty-file-name, 82
@c tty-info, 85

@c 195

@c tty-info record type, 82
@c tty-info:control-chars, 82
@c tty-info:control-flags, 82
@c tty-info:input-flags, 82
@c tty-info:input-speed, 82
@c tty-info:local-flags, 82
@c tty-info:min, 82
@c tty-info:output-flags, 82
@c tty-info:output-speed, 82
@c tty-info:time, 82
@c tty-info?, 82
@c tty-name->pty-name, 88
@c tty-process-group, 87
@c tty?, 82
@c ttyc/2-stop-bits, 92
@c ttyc/carrier-flow-ctl, 92
@c ttyc/char-size, 92
@c ttyc/char-size5, 92
@c ttyc/char-size6, 92
@c ttyc/char-size7, 92
@c ttyc/char-size8, 92
@c ttyc/CTS-output-flow-ctl, 92
@c ttyc/enable-parity, 92
@c ttyc/enable-read, 92
@c ttyc/hup-on-close, 92
@c ttyc/ignore-flags, 92
@c ttyc/no-modem-sync, 92
@c ttyc/odd-parity, 92
@c ttyc/RTS-input-flow-ctl, 92
@c ttychar/delayed-suspend, 89
@c ttychar/delete-char, 89
@c ttychar/delete-line, 89
@c ttychar/delete-word, 89
@c ttychar/discard, 89
@c ttychar/eof, 89
@c ttychar/eol, 89
@c ttychar/eol2, 89
@c ttychar/interrupt, 89
@c ttychar/literal-next, 89
@c ttychar/quit, 89
@c ttychar/reprint, 89
@c ttychar/start, 89
@c ttychar/status, 89
@c ttychar/stop, 89

@c ttychar/suspend, 89
@c ttyin/7bits, 90
@c ttyin/beep-on-overflow, 90
@c ttyin/check-parity, 90
@c ttyin/cr->nl, 90
@c ttyin/ignore-bad-parity-chars,90

@c ttyin/ignore-break, 90
@c ttyin/ignore-cr, 90
@c ttyin/input-flow-ctl, 90
@c ttyin/interrupt-on-break, 90
@c ttyin/lowercase, 90
@c ttyin/mark-parity-errors, 90
@c ttyin/nl->cr, 90
@c ttyin/output-flow-ctl, 90
@c ttyin/xon-any, 90
@c ttyl/alt-delete-word, 93
@c ttyl/canonical, 93
@c ttyl/case-map, 93
@c ttyl/echo, 93
@c ttyl/echo-ctl, 93
@c ttyl/echo-delete-line, 93
@c ttyl/echo-nl, 93
@c ttyl/enable-signals, 93
@c ttyl/extended, 93
@c ttyl/flush-output, 93
@c ttyl/hardcopy-delete, 93
@c ttyl/no-flush-on-interrupt, 93
@c ttyl/no-kernel-status, 93
@c ttyl/reprint-unread-chars, 93
@c ttyl/ttou-signal, 93
@c ttyl/visual-delete, 93
@c ttyl/visual-delete-line, 93
@c ttyout/all-delay, 91
@c ttyout/bs-delay, 91
@c ttyout/bs-delay0, 91
@c ttyout/bs-delay1, 91
@c ttyout/cr->nl, 90
@c ttyout/cr-delay, 91
@c ttyout/cr-delay0, 91
@c ttyout/cr-delay1, 91
@c ttyout/cr-delay2, 91
@c ttyout/cr-delay3, 91
@c ttyout/delay-w/fill-char, 90

@c 196

@c ttyout/discard-eot, 90
@c ttyout/enable, 90
@c ttyout/expand-tabs, 90
@c ttyout/ff-delay, 91
@c ttyout/ff-delay0, 91
@c ttyout/ff-delay1, 91
@c ttyout/fill-w/del, 90
@c ttyout/nl->crnl, 90
@c ttyout/nl-delay, 91
@c ttyout/nl-delay0, 91
@c ttyout/nl-delay1, 91
@c ttyout/nl-does-cr, 90
@c ttyout/no-col0-cr, 90
@c ttyout/tab-delay, 91
@c ttyout/tab-delay0, 91
@c ttyout/tab-delay1, 91
@c ttyout/tab-delay2, 91
@c ttyout/tab-delayx, 91
@c ttyout/uppercase, 90
@c ttyout/vtab-delay, 91
@c ttyout/vtab-delay0, 91
@c ttyout/vtab-delay1, 91

@c umask, 62
@c uname, 66
@c uncase, 134
@c uncase-char-set, 134
@c uncase-string, 134
@c unix-address->socket-address,97

@c unlock-region, 41
@c user-effective-gid, 63
@c user-effective-uid, 63
@c user-gid, 63
@c user-info, 64
@c user-info:gid, 64
@c user-info:home-dir, 64
@c user-info:name, 64
@c user-info:shell, 64
@c user-info:uid, 64
@c user-login-name, 63
@c user-supplementary-gids, 63
@c user-uid, 63

@c vendor, 168
@c wait, 60
@c wait-any, 60
@c wait-process-group, 61
@c with-current-input-port, 24
@c with-current-input-port*, 24
@c with-current-output-port, 24
@c with-current-output-port*, 24
@c with-cwd, 62
@c with-cwd*, 62
@c with-dot-lock, 162
@c with-dot-lock*, 162
@c with-enabled-interrupts, 70
@c with-enabled-interrupts*, 70
@c with-env, 79
@c with-env*, 79
@c with-errno-handler, 22
@c with-errno-handler*, 22
@c with-error-output-port, 24
@c with-error-output-port*, 24
@c with-region-lock, 41
@c with-region-lock*, 41
@c with-stdio-ports, 26
@c with-stdio-ports*, 26
@c with-syslog-destination, 166
@c with-total-env, 79
@c with-total-env*, 79
@c with-umask, 62
@c with-umask*, 62
@c with-user-effective-gid, 63
@c with-user-effective-gid*, 63
@c with-user-effective-uid, 63
@c with-user-effective-uid*, 63
@c write-string, 36
@c write-string/partial, 37

@bye
